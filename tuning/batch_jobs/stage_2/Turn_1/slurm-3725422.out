Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_11S_500x.png
	num_instances: 25
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_02_SE1_500X71.png
	num_instances: 104
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_02_SE1_1000X99.png
	num_instances: 93
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[09/20 14:26:38 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[09/20 14:26:38 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[09/20 14:26:38 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[09/20 14:26:38 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[09/20 14:26:38 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[09/20 14:26:38 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[09/20 14:26:38 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[09/20 14:26:38 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[09/20 14:26:38 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[09/20 14:26:38 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[09/20 14:26:38 d2.engine.train_loop]: [0mStarting training from iteration 0
/jet/home/sprice/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[32m[09/20 14:26:43 d2.utils.events]: [0m eta: 0:35:02  iter: 19  total_loss: 3.066  loss_cls: 0.5303  loss_box_reg: 0.05032  loss_mask: 0.6243  loss_rpn_cls: 0.6386  loss_rpn_loc: 0.9223  time: 0.1397  data_time: 0.1082  lr: 0.00099905  max_mem: 1774M
[32m[09/20 14:26:46 d2.utils.events]: [0m eta: 0:34:31  iter: 39  total_loss: 2.139  loss_cls: 0.2634  loss_box_reg: 0.03555  loss_mask: 0.5827  loss_rpn_cls: 0.5888  loss_rpn_loc: 0.6567  time: 0.1423  data_time: 0.0157  lr: 0.001998  max_mem: 1774M
[32m[09/20 14:26:49 d2.utils.events]: [0m eta: 0:34:47  iter: 59  total_loss: 2.27  loss_cls: 0.3674  loss_box_reg: 0.2212  loss_mask: 0.5649  loss_rpn_cls: 0.5035  loss_rpn_loc: 0.6182  time: 0.1420  data_time: 0.0151  lr: 0.002997  max_mem: 1823M
[32m[09/20 14:26:52 d2.utils.events]: [0m eta: 0:35:21  iter: 79  total_loss: 1.995  loss_cls: 0.2827  loss_box_reg: 0.1989  loss_mask: 0.5068  loss_rpn_cls: 0.3874  loss_rpn_loc: 0.6055  time: 0.1422  data_time: 0.0156  lr: 0.0039961  max_mem: 1823M
[32m[09/20 14:26:55 d2.utils.events]: [0m eta: 0:35:41  iter: 99  total_loss: 1.934  loss_cls: 0.2451  loss_box_reg: 0.3709  loss_mask: 0.4464  loss_rpn_cls: 0.3076  loss_rpn_loc: 0.4907  time: 0.1431  data_time: 0.0158  lr: 0.0049951  max_mem: 1823M
[32m[09/20 14:26:57 d2.utils.events]: [0m eta: 0:35:40  iter: 119  total_loss: 1.867  loss_cls: 0.2578  loss_box_reg: 0.3661  loss_mask: 0.4  loss_rpn_cls: 0.298  loss_rpn_loc: 0.4993  time: 0.1436  data_time: 0.0152  lr: 0.0059941  max_mem: 1823M
[32m[09/20 14:27:00 d2.utils.events]: [0m eta: 0:35:38  iter: 139  total_loss: 1.878  loss_cls: 0.267  loss_box_reg: 0.3841  loss_mask: 0.3807  loss_rpn_cls: 0.297  loss_rpn_loc: 0.5182  time: 0.1439  data_time: 0.0153  lr: 0.006993  max_mem: 1823M
[32m[09/20 14:27:03 d2.utils.events]: [0m eta: 0:35:38  iter: 159  total_loss: 1.852  loss_cls: 0.2576  loss_box_reg: 0.4264  loss_mask: 0.3384  loss_rpn_cls: 0.294  loss_rpn_loc: 0.5393  time: 0.1446  data_time: 0.0156  lr: 0.0079921  max_mem: 1823M
[32m[09/20 14:27:06 d2.utils.events]: [0m eta: 0:35:36  iter: 179  total_loss: 1.791  loss_cls: 0.2618  loss_box_reg: 0.4279  loss_mask: 0.353  loss_rpn_cls: 0.2715  loss_rpn_loc: 0.4763  time: 0.1448  data_time: 0.0153  lr: 0.0089911  max_mem: 1823M
[32m[09/20 14:27:09 d2.utils.events]: [0m eta: 0:35:32  iter: 199  total_loss: 1.67  loss_cls: 0.1899  loss_box_reg: 0.3786  loss_mask: 0.3261  loss_rpn_cls: 0.2443  loss_rpn_loc: 0.4743  time: 0.1447  data_time: 0.0156  lr: 0.0099901  max_mem: 1823M
[32m[09/20 14:27:12 d2.utils.events]: [0m eta: 0:35:30  iter: 219  total_loss: 1.715  loss_cls: 0.2252  loss_box_reg: 0.3684  loss_mask: 0.3271  loss_rpn_cls: 0.2527  loss_rpn_loc: 0.5052  time: 0.1449  data_time: 0.0155  lr: 0.010989  max_mem: 1823M
[32m[09/20 14:27:15 d2.utils.events]: [0m eta: 0:35:30  iter: 239  total_loss: 1.6  loss_cls: 0.2077  loss_box_reg: 0.428  loss_mask: 0.2974  loss_rpn_cls: 0.2567  loss_rpn_loc: 0.4681  time: 0.1451  data_time: 0.0153  lr: 0.011988  max_mem: 1823M
[32m[09/20 14:27:18 d2.utils.events]: [0m eta: 0:35:28  iter: 259  total_loss: 1.672  loss_cls: 0.2302  loss_box_reg: 0.3766  loss_mask: 0.3215  loss_rpn_cls: 0.238  loss_rpn_loc: 0.5176  time: 0.1450  data_time: 0.0149  lr: 0.012987  max_mem: 1823M
[32m[09/20 14:27:21 d2.utils.events]: [0m eta: 0:35:25  iter: 279  total_loss: 1.607  loss_cls: 0.1868  loss_box_reg: 0.2523  loss_mask: 0.3012  loss_rpn_cls: 0.2847  loss_rpn_loc: 0.5667  time: 0.1454  data_time: 0.0154  lr: 0.013986  max_mem: 1823M
[32m[09/20 14:27:24 d2.utils.events]: [0m eta: 0:35:23  iter: 299  total_loss: 1.575  loss_cls: 0.2018  loss_box_reg: 0.2935  loss_mask: 0.2833  loss_rpn_cls: 0.2756  loss_rpn_loc: 0.5789  time: 0.1459  data_time: 0.0156  lr: 0.014985  max_mem: 1823M
[32m[09/20 14:27:27 d2.utils.events]: [0m eta: 0:35:23  iter: 319  total_loss: 1.563  loss_cls: 0.1743  loss_box_reg: 0.3086  loss_mask: 0.3069  loss_rpn_cls: 0.2325  loss_rpn_loc: 0.5091  time: 0.1459  data_time: 0.0155  lr: 0.015984  max_mem: 1823M
[32m[09/20 14:27:30 d2.utils.events]: [0m eta: 0:35:20  iter: 339  total_loss: 1.442  loss_cls: 0.1883  loss_box_reg: 0.2959  loss_mask: 0.2895  loss_rpn_cls: 0.2498  loss_rpn_loc: 0.4774  time: 0.1458  data_time: 0.0159  lr: 0.016983  max_mem: 1823M
[32m[09/20 14:27:33 d2.utils.events]: [0m eta: 0:35:17  iter: 359  total_loss: 1.562  loss_cls: 0.2091  loss_box_reg: 0.314  loss_mask: 0.2553  loss_rpn_cls: 0.2541  loss_rpn_loc: 0.4868  time: 0.1459  data_time: 0.0149  lr: 0.017982  max_mem: 1823M
[32m[09/20 14:27:36 d2.utils.events]: [0m eta: 0:35:16  iter: 379  total_loss: 1.515  loss_cls: 0.1871  loss_box_reg: 0.3165  loss_mask: 0.266  loss_rpn_cls: 0.219  loss_rpn_loc: 0.5071  time: 0.1464  data_time: 0.0164  lr: 0.018981  max_mem: 1823M
[32m[09/20 14:27:39 d2.utils.events]: [0m eta: 0:35:13  iter: 399  total_loss: 1.449  loss_cls: 0.1674  loss_box_reg: 0.2262  loss_mask: 0.2874  loss_rpn_cls: 0.229  loss_rpn_loc: 0.5488  time: 0.1464  data_time: 0.0160  lr: 0.01998  max_mem: 1823M
[32m[09/20 14:27:42 d2.utils.events]: [0m eta: 0:35:14  iter: 419  total_loss: 1.535  loss_cls: 0.2038  loss_box_reg: 0.3491  loss_mask: 0.2544  loss_rpn_cls: 0.2248  loss_rpn_loc: 0.5121  time: 0.1467  data_time: 0.0159  lr: 0.020979  max_mem: 1823M
[32m[09/20 14:27:45 d2.utils.events]: [0m eta: 0:35:15  iter: 439  total_loss: 1.465  loss_cls: 0.1895  loss_box_reg: 0.3046  loss_mask: 0.25  loss_rpn_cls: 0.2678  loss_rpn_loc: 0.5164  time: 0.1472  data_time: 0.0176  lr: 0.021978  max_mem: 1823M
[32m[09/20 14:27:48 d2.utils.events]: [0m eta: 0:35:16  iter: 459  total_loss: 1.407  loss_cls: 0.1771  loss_box_reg: 0.2272  loss_mask: 0.2652  loss_rpn_cls: 0.2224  loss_rpn_loc: 0.5006  time: 0.1473  data_time: 0.0160  lr: 0.022977  max_mem: 1823M
[32m[09/20 14:27:51 d2.utils.events]: [0m eta: 0:35:17  iter: 479  total_loss: 1.527  loss_cls: 0.1821  loss_box_reg: 0.3  loss_mask: 0.253  loss_rpn_cls: 0.214  loss_rpn_loc: 0.502  time: 0.1475  data_time: 0.0166  lr: 0.023976  max_mem: 1823M
[32m[09/20 14:27:54 d2.utils.events]: [0m eta: 0:35:18  iter: 499  total_loss: 1.401  loss_cls: 0.1182  loss_box_reg: 0.1806  loss_mask: 0.2629  loss_rpn_cls: 0.2325  loss_rpn_loc: 0.5462  time: 0.1474  data_time: 0.0162  lr: 0.024975  max_mem: 1823M
[32m[09/20 14:27:57 d2.utils.events]: [0m eta: 0:35:19  iter: 519  total_loss: 1.454  loss_cls: 0.1554  loss_box_reg: 0.2459  loss_mask: 0.2584  loss_rpn_cls: 0.217  loss_rpn_loc: 0.5447  time: 0.1475  data_time: 0.0165  lr: 0.025974  max_mem: 1823M
[32m[09/20 14:28:00 d2.utils.events]: [0m eta: 0:35:19  iter: 539  total_loss: 1.363  loss_cls: 0.1404  loss_box_reg: 0.2497  loss_mask: 0.2444  loss_rpn_cls: 0.2208  loss_rpn_loc: 0.5428  time: 0.1475  data_time: 0.0166  lr: 0.026973  max_mem: 1823M
[32m[09/20 14:28:03 d2.utils.events]: [0m eta: 0:35:12  iter: 559  total_loss: 1.445  loss_cls: 0.1547  loss_box_reg: 0.2206  loss_mask: 0.2549  loss_rpn_cls: 0.2644  loss_rpn_loc: 0.5186  time: 0.1475  data_time: 0.0153  lr: 0.027972  max_mem: 1823M
[32m[09/20 14:28:06 d2.utils.events]: [0m eta: 0:35:11  iter: 579  total_loss: 1.508  loss_cls: 0.1789  loss_box_reg: 0.2921  loss_mask: 0.2446  loss_rpn_cls: 0.2974  loss_rpn_loc: 0.5061  time: 0.1474  data_time: 0.0158  lr: 0.028971  max_mem: 1823M
[32m[09/20 14:28:09 d2.utils.events]: [0m eta: 0:35:10  iter: 599  total_loss: 1.542  loss_cls: 0.2093  loss_box_reg: 0.3092  loss_mask: 0.2368  loss_rpn_cls: 0.229  loss_rpn_loc: 0.5002  time: 0.1476  data_time: 0.0168  lr: 0.02997  max_mem: 1823M
[32m[09/20 14:28:12 d2.utils.events]: [0m eta: 0:35:07  iter: 619  total_loss: 1.429  loss_cls: 0.1391  loss_box_reg: 0.1808  loss_mask: 0.2494  loss_rpn_cls: 0.2397  loss_rpn_loc: 0.5782  time: 0.1475  data_time: 0.0153  lr: 0.030969  max_mem: 1823M
[32m[09/20 14:28:15 d2.utils.events]: [0m eta: 0:35:04  iter: 639  total_loss: 1.473  loss_cls: 0.1727  loss_box_reg: 0.2328  loss_mask: 0.2513  loss_rpn_cls: 0.2865  loss_rpn_loc: 0.5138  time: 0.1475  data_time: 0.0159  lr: 0.031968  max_mem: 1823M
[32m[09/20 14:28:18 d2.utils.events]: [0m eta: 0:35:01  iter: 659  total_loss: 1.473  loss_cls: 0.1173  loss_box_reg: 0.1383  loss_mask: 0.2667  loss_rpn_cls: 0.2841  loss_rpn_loc: 0.6538  time: 0.1475  data_time: 0.0168  lr: 0.032967  max_mem: 1823M
[32m[09/20 14:28:21 d2.utils.events]: [0m eta: 0:34:59  iter: 679  total_loss: 1.368  loss_cls: 0.1345  loss_box_reg: 0.1675  loss_mask: 0.2708  loss_rpn_cls: 0.2484  loss_rpn_loc: 0.5771  time: 0.1475  data_time: 0.0157  lr: 0.033966  max_mem: 1823M
[32m[09/20 14:28:24 d2.utils.events]: [0m eta: 0:34:56  iter: 699  total_loss: 1.476  loss_cls: 0.1553  loss_box_reg: 0.2412  loss_mask: 0.2414  loss_rpn_cls: 0.2831  loss_rpn_loc: 0.5545  time: 0.1475  data_time: 0.0160  lr: 0.034965  max_mem: 1823M
[4m[5m[31mERROR[0m [32m[09/20 14:28:26 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 138, in train
    self.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 441, in run_step
    self._trainer.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 242, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 284, in _write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=709!
loss_dict = {'loss_cls': nan, 'loss_box_reg': nan, 'loss_mask': 0.7658007740974426, 'loss_rpn_cls': 0.5991454124450684, 'loss_rpn_loc': 0.5270600914955139}
[32m[09/20 14:28:26 d2.engine.hooks]: [0mOverall training speed: 707 iterations in 0:01:44 (0.1477 s / it)
[32m[09/20 14:28:26 d2.engine.hooks]: [0mTotal training time: 0:01:45 (0:00:00 on hooks)
[32m[09/20 14:28:26 d2.utils.events]: [0m eta: 0:34:54  iter: 709  total_loss: 1.641  loss_cls: 0.1637  loss_box_reg: 0.1891  loss_mask: 0.2503  loss_rpn_cls: 0.4336  loss_rpn_loc: 0.6436  time: 0.1475  data_time: 0.0170  lr: 0.035415  max_mem: 1823M
Traceback (most recent call last):
  File "train_powder_LR-0_05_T1.py", line 126, in <module>
    trainer.train()  # train the model!
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 431, in train
    super().train(self.start_iter, self.max_iter)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 138, in train
    self.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 441, in run_step
    self._trainer.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 242, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 284, in _write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=709!
loss_dict = {'loss_cls': nan, 'loss_box_reg': nan, 'loss_mask': 0.7658007740974426, 'loss_rpn_cls': 0.5991454124450684, 'loss_rpn_loc': 0.5270600914955139}
/var/spool/slurm/d/job3725422/slurm_script: line 9: ./gpua.out: No such file or directory
