Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_5S_500x.png
	num_instances: 65
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_10S_500x.png
	num_instances: 32
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_01_SE1_1250X28.png
	num_instances: 123
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[09/20 14:18:36 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[09/20 14:18:36 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[09/20 14:18:36 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[09/20 14:18:36 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[09/20 14:18:36 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[09/20 14:18:36 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[09/20 14:18:36 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[09/20 14:18:36 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[09/20 14:18:36 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[09/20 14:18:36 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[09/20 14:18:36 d2.engine.train_loop]: [0mStarting training from iteration 0
/jet/home/sprice/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[32m[09/20 14:18:41 d2.utils.events]: [0m eta: 0:35:36  iter: 19  total_loss: 2.788  loss_cls: 0.5034  loss_box_reg: 0.03858  loss_mask: 0.6481  loss_rpn_cls: 0.6389  loss_rpn_loc: 1.154  time: 0.1490  data_time: 0.1091  lr: 0.00059943  max_mem: 1604M
[32m[09/20 14:18:44 d2.utils.events]: [0m eta: 0:35:10  iter: 39  total_loss: 2.161  loss_cls: 0.2711  loss_box_reg: 0.06368  loss_mask: 0.5955  loss_rpn_cls: 0.5792  loss_rpn_loc: 0.641  time: 0.1452  data_time: 0.0157  lr: 0.0011988  max_mem: 1703M
[32m[09/20 14:18:47 d2.utils.events]: [0m eta: 0:35:38  iter: 59  total_loss: 2.073  loss_cls: 0.2508  loss_box_reg: 0.1601  loss_mask: 0.5657  loss_rpn_cls: 0.5284  loss_rpn_loc: 0.5577  time: 0.1453  data_time: 0.0151  lr: 0.0017982  max_mem: 1703M
[32m[09/20 14:18:50 d2.utils.events]: [0m eta: 0:36:21  iter: 79  total_loss: 2.125  loss_cls: 0.3452  loss_box_reg: 0.3575  loss_mask: 0.5182  loss_rpn_cls: 0.418  loss_rpn_loc: 0.5282  time: 0.1489  data_time: 0.0106  lr: 0.0023976  max_mem: 1715M
[32m[09/20 14:18:53 d2.utils.events]: [0m eta: 0:36:32  iter: 99  total_loss: 2.098  loss_cls: 0.2727  loss_box_reg: 0.3215  loss_mask: 0.4943  loss_rpn_cls: 0.363  loss_rpn_loc: 0.5743  time: 0.1500  data_time: 0.0072  lr: 0.002997  max_mem: 1778M
[32m[09/20 14:18:57 d2.utils.events]: [0m eta: 0:36:50  iter: 119  total_loss: 1.892  loss_cls: 0.2545  loss_box_reg: 0.32  loss_mask: 0.4484  loss_rpn_cls: 0.3056  loss_rpn_loc: 0.5084  time: 0.1509  data_time: 0.0067  lr: 0.0035964  max_mem: 1778M
[32m[09/20 14:19:00 d2.utils.events]: [0m eta: 0:37:09  iter: 139  total_loss: 1.839  loss_cls: 0.2446  loss_box_reg: 0.363  loss_mask: 0.4058  loss_rpn_cls: 0.2953  loss_rpn_loc: 0.5178  time: 0.1514  data_time: 0.0063  lr: 0.0041958  max_mem: 1778M
[32m[09/20 14:19:03 d2.utils.events]: [0m eta: 0:37:19  iter: 159  total_loss: 1.787  loss_cls: 0.2526  loss_box_reg: 0.3861  loss_mask: 0.4148  loss_rpn_cls: 0.2677  loss_rpn_loc: 0.4819  time: 0.1525  data_time: 0.0086  lr: 0.0047952  max_mem: 1778M
[32m[09/20 14:19:06 d2.utils.events]: [0m eta: 0:37:34  iter: 179  total_loss: 1.775  loss_cls: 0.2455  loss_box_reg: 0.428  loss_mask: 0.3681  loss_rpn_cls: 0.2734  loss_rpn_loc: 0.4977  time: 0.1532  data_time: 0.0080  lr: 0.0053946  max_mem: 1778M
[32m[09/20 14:19:09 d2.utils.events]: [0m eta: 0:37:45  iter: 199  total_loss: 1.901  loss_cls: 0.2888  loss_box_reg: 0.4923  loss_mask: 0.3711  loss_rpn_cls: 0.2748  loss_rpn_loc: 0.4896  time: 0.1542  data_time: 0.0081  lr: 0.005994  max_mem: 1778M
[32m[09/20 14:19:13 d2.utils.events]: [0m eta: 0:37:46  iter: 219  total_loss: 1.684  loss_cls: 0.2115  loss_box_reg: 0.4031  loss_mask: 0.332  loss_rpn_cls: 0.224  loss_rpn_loc: 0.4962  time: 0.1546  data_time: 0.0066  lr: 0.0065934  max_mem: 1778M
[32m[09/20 14:19:16 d2.utils.events]: [0m eta: 0:37:47  iter: 239  total_loss: 1.75  loss_cls: 0.2659  loss_box_reg: 0.4128  loss_mask: 0.335  loss_rpn_cls: 0.2826  loss_rpn_loc: 0.4852  time: 0.1554  data_time: 0.0078  lr: 0.0071928  max_mem: 1827M
[32m[09/20 14:19:19 d2.utils.events]: [0m eta: 0:37:51  iter: 259  total_loss: 1.474  loss_cls: 0.1725  loss_box_reg: 0.2972  loss_mask: 0.3151  loss_rpn_cls: 0.2667  loss_rpn_loc: 0.5173  time: 0.1568  data_time: 0.0086  lr: 0.0077922  max_mem: 1827M
[32m[09/20 14:19:23 d2.utils.events]: [0m eta: 0:37:59  iter: 279  total_loss: 1.675  loss_cls: 0.2282  loss_box_reg: 0.4134  loss_mask: 0.3245  loss_rpn_cls: 0.2459  loss_rpn_loc: 0.4706  time: 0.1579  data_time: 0.0083  lr: 0.0083916  max_mem: 1827M
[32m[09/20 14:19:27 d2.utils.events]: [0m eta: 0:38:01  iter: 299  total_loss: 1.604  loss_cls: 0.227  loss_box_reg: 0.4661  loss_mask: 0.3024  loss_rpn_cls: 0.2299  loss_rpn_loc: 0.456  time: 0.1598  data_time: 0.0096  lr: 0.008991  max_mem: 1827M
[32m[09/20 14:19:32 d2.utils.events]: [0m eta: 0:38:22  iter: 319  total_loss: 1.644  loss_cls: 0.2337  loss_box_reg: 0.3667  loss_mask: 0.2929  loss_rpn_cls: 0.2571  loss_rpn_loc: 0.45  time: 0.1657  data_time: 0.0104  lr: 0.0095904  max_mem: 1827M
[32m[09/20 14:19:37 d2.utils.events]: [0m eta: 0:38:34  iter: 339  total_loss: 1.688  loss_cls: 0.2497  loss_box_reg: 0.4638  loss_mask: 0.2863  loss_rpn_cls: 0.2267  loss_rpn_loc: 0.4409  time: 0.1703  data_time: 0.0096  lr: 0.01019  max_mem: 1827M
[32m[09/20 14:19:42 d2.utils.events]: [0m eta: 0:38:49  iter: 359  total_loss: 1.51  loss_cls: 0.1941  loss_box_reg: 0.3767  loss_mask: 0.2727  loss_rpn_cls: 0.2125  loss_rpn_loc: 0.498  time: 0.1751  data_time: 0.0112  lr: 0.010789  max_mem: 1827M
[32m[09/20 14:19:46 d2.utils.events]: [0m eta: 0:38:52  iter: 379  total_loss: 1.58  loss_cls: 0.2411  loss_box_reg: 0.3504  loss_mask: 0.2929  loss_rpn_cls: 0.2631  loss_rpn_loc: 0.4942  time: 0.1777  data_time: 0.0112  lr: 0.011389  max_mem: 1827M
[32m[09/20 14:19:51 d2.utils.events]: [0m eta: 0:39:00  iter: 399  total_loss: 1.669  loss_cls: 0.2625  loss_box_reg: 0.4826  loss_mask: 0.2647  loss_rpn_cls: 0.2104  loss_rpn_loc: 0.4308  time: 0.1794  data_time: 0.0105  lr: 0.011988  max_mem: 1827M
[32m[09/20 14:19:55 d2.utils.events]: [0m eta: 0:38:58  iter: 419  total_loss: 1.549  loss_cls: 0.2018  loss_box_reg: 0.4012  loss_mask: 0.2877  loss_rpn_cls: 0.2168  loss_rpn_loc: 0.4503  time: 0.1813  data_time: 0.0122  lr: 0.012587  max_mem: 1827M
[32m[09/20 14:19:59 d2.utils.events]: [0m eta: 0:38:55  iter: 439  total_loss: 1.63  loss_cls: 0.2455  loss_box_reg: 0.4113  loss_mask: 0.2841  loss_rpn_cls: 0.2046  loss_rpn_loc: 0.4811  time: 0.1814  data_time: 0.0089  lr: 0.013187  max_mem: 1827M
[32m[09/20 14:20:03 d2.utils.events]: [0m eta: 0:39:09  iter: 459  total_loss: 1.576  loss_cls: 0.2  loss_box_reg: 0.3784  loss_mask: 0.2833  loss_rpn_cls: 0.1948  loss_rpn_loc: 0.4761  time: 0.1826  data_time: 0.0111  lr: 0.013786  max_mem: 1827M
[32m[09/20 14:20:07 d2.utils.events]: [0m eta: 0:39:06  iter: 479  total_loss: 1.595  loss_cls: 0.2249  loss_box_reg: 0.3841  loss_mask: 0.273  loss_rpn_cls: 0.2216  loss_rpn_loc: 0.4848  time: 0.1836  data_time: 0.0096  lr: 0.014386  max_mem: 1827M
[32m[09/20 14:20:11 d2.utils.events]: [0m eta: 0:39:03  iter: 499  total_loss: 1.497  loss_cls: 0.1895  loss_box_reg: 0.3794  loss_mask: 0.256  loss_rpn_cls: 0.2252  loss_rpn_loc: 0.4419  time: 0.1846  data_time: 0.0093  lr: 0.014985  max_mem: 1827M
[32m[09/20 14:20:16 d2.utils.events]: [0m eta: 0:39:02  iter: 519  total_loss: 1.544  loss_cls: 0.244  loss_box_reg: 0.4246  loss_mask: 0.251  loss_rpn_cls: 0.176  loss_rpn_loc: 0.428  time: 0.1859  data_time: 0.0103  lr: 0.015584  max_mem: 1827M
[32m[09/20 14:20:20 d2.utils.events]: [0m eta: 0:38:59  iter: 539  total_loss: 1.642  loss_cls: 0.2194  loss_box_reg: 0.335  loss_mask: 0.2793  loss_rpn_cls: 0.2471  loss_rpn_loc: 0.5456  time: 0.1866  data_time: 0.0139  lr: 0.016184  max_mem: 1827M
[32m[09/20 14:20:25 d2.utils.events]: [0m eta: 0:39:01  iter: 559  total_loss: 1.44  loss_cls: 0.1447  loss_box_reg: 0.2494  loss_mask: 0.2662  loss_rpn_cls: 0.244  loss_rpn_loc: 0.5093  time: 0.1877  data_time: 0.0120  lr: 0.016783  max_mem: 1827M
[32m[09/20 14:20:29 d2.utils.events]: [0m eta: 0:39:03  iter: 579  total_loss: 1.477  loss_cls: 0.1571  loss_box_reg: 0.316  loss_mask: 0.2768  loss_rpn_cls: 0.2009  loss_rpn_loc: 0.5102  time: 0.1889  data_time: 0.0117  lr: 0.017383  max_mem: 1827M
[32m[09/20 14:20:34 d2.utils.events]: [0m eta: 0:39:05  iter: 599  total_loss: 1.561  loss_cls: 0.217  loss_box_reg: 0.3571  loss_mask: 0.2484  loss_rpn_cls: 0.2313  loss_rpn_loc: 0.5112  time: 0.1898  data_time: 0.0104  lr: 0.017982  max_mem: 1827M
[32m[09/20 14:20:38 d2.utils.events]: [0m eta: 0:39:01  iter: 619  total_loss: 1.509  loss_cls: 0.232  loss_box_reg: 0.3836  loss_mask: 0.2473  loss_rpn_cls: 0.2002  loss_rpn_loc: 0.4382  time: 0.1902  data_time: 0.0116  lr: 0.018581  max_mem: 1827M
[32m[09/20 14:20:42 d2.utils.events]: [0m eta: 0:38:58  iter: 639  total_loss: 1.573  loss_cls: 0.2102  loss_box_reg: 0.3983  loss_mask: 0.2441  loss_rpn_cls: 0.2202  loss_rpn_loc: 0.4758  time: 0.1907  data_time: 0.0092  lr: 0.019181  max_mem: 1827M
[32m[09/20 14:20:46 d2.utils.events]: [0m eta: 0:38:54  iter: 659  total_loss: 1.508  loss_cls: 0.2018  loss_box_reg: 0.3438  loss_mask: 0.2689  loss_rpn_cls: 0.215  loss_rpn_loc: 0.5175  time: 0.1908  data_time: 0.0114  lr: 0.01978  max_mem: 1827M
[32m[09/20 14:20:50 d2.utils.events]: [0m eta: 0:38:52  iter: 679  total_loss: 1.52  loss_cls: 0.1848  loss_box_reg: 0.3214  loss_mask: 0.2442  loss_rpn_cls: 0.2244  loss_rpn_loc: 0.5  time: 0.1910  data_time: 0.0106  lr: 0.02038  max_mem: 1827M
[32m[09/20 14:20:54 d2.utils.events]: [0m eta: 0:39:00  iter: 699  total_loss: 1.492  loss_cls: 0.1942  loss_box_reg: 0.4028  loss_mask: 0.2401  loss_rpn_cls: 0.2026  loss_rpn_loc: 0.4416  time: 0.1915  data_time: 0.0087  lr: 0.020979  max_mem: 1827M
[32m[09/20 14:20:58 d2.utils.events]: [0m eta: 0:39:04  iter: 719  total_loss: 1.539  loss_cls: 0.2062  loss_box_reg: 0.3565  loss_mask: 0.2404  loss_rpn_cls: 0.1779  loss_rpn_loc: 0.4966  time: 0.1921  data_time: 0.0099  lr: 0.021578  max_mem: 1827M
[32m[09/20 14:21:03 d2.utils.events]: [0m eta: 0:39:05  iter: 739  total_loss: 1.564  loss_cls: 0.1875  loss_box_reg: 0.2925  loss_mask: 0.2578  loss_rpn_cls: 0.226  loss_rpn_loc: 0.5267  time: 0.1928  data_time: 0.0109  lr: 0.022178  max_mem: 1827M
[32m[09/20 14:21:07 d2.utils.events]: [0m eta: 0:39:01  iter: 759  total_loss: 1.488  loss_cls: 0.136  loss_box_reg: 0.1664  loss_mask: 0.2573  loss_rpn_cls: 0.228  loss_rpn_loc: 0.5786  time: 0.1933  data_time: 0.0081  lr: 0.022777  max_mem: 1827M
[32m[09/20 14:21:11 d2.utils.events]: [0m eta: 0:38:58  iter: 779  total_loss: 1.408  loss_cls: 0.1537  loss_box_reg: 0.2141  loss_mask: 0.2484  loss_rpn_cls: 0.2375  loss_rpn_loc: 0.5878  time: 0.1937  data_time: 0.0110  lr: 0.023377  max_mem: 1827M
[32m[09/20 14:21:16 d2.utils.events]: [0m eta: 0:38:55  iter: 799  total_loss: 1.459  loss_cls: 0.18  loss_box_reg: 0.2869  loss_mask: 0.244  loss_rpn_cls: 0.2681  loss_rpn_loc: 0.5239  time: 0.1942  data_time: 0.0088  lr: 0.023976  max_mem: 1827M
[32m[09/20 14:21:20 d2.utils.events]: [0m eta: 0:38:52  iter: 819  total_loss: 1.487  loss_cls: 0.1908  loss_box_reg: 0.2956  loss_mask: 0.2503  loss_rpn_cls: 0.1839  loss_rpn_loc: 0.4965  time: 0.1943  data_time: 0.0107  lr: 0.024575  max_mem: 1827M
[32m[09/20 14:21:24 d2.utils.events]: [0m eta: 0:38:48  iter: 839  total_loss: 1.483  loss_cls: 0.1792  loss_box_reg: 0.2778  loss_mask: 0.2294  loss_rpn_cls: 0.2279  loss_rpn_loc: 0.538  time: 0.1944  data_time: 0.0104  lr: 0.025175  max_mem: 1827M
[32m[09/20 14:21:28 d2.utils.events]: [0m eta: 0:38:45  iter: 859  total_loss: 1.36  loss_cls: 0.1631  loss_box_reg: 0.2281  loss_mask: 0.2559  loss_rpn_cls: 0.2132  loss_rpn_loc: 0.4994  time: 0.1949  data_time: 0.0090  lr: 0.025774  max_mem: 1827M
[32m[09/20 14:21:32 d2.utils.events]: [0m eta: 0:38:41  iter: 879  total_loss: 1.315  loss_cls: 0.1177  loss_box_reg: 0.1761  loss_mask: 0.2556  loss_rpn_cls: 0.2486  loss_rpn_loc: 0.5375  time: 0.1945  data_time: 0.0106  lr: 0.026374  max_mem: 1827M
[32m[09/20 14:21:36 d2.utils.events]: [0m eta: 0:38:38  iter: 899  total_loss: 1.402  loss_cls: 0.1581  loss_box_reg: 0.2661  loss_mask: 0.2366  loss_rpn_cls: 0.2217  loss_rpn_loc: 0.5285  time: 0.1950  data_time: 0.0107  lr: 0.026973  max_mem: 1827M
[32m[09/20 14:21:41 d2.utils.events]: [0m eta: 0:38:37  iter: 919  total_loss: 1.406  loss_cls: 0.1612  loss_box_reg: 0.2859  loss_mask: 0.227  loss_rpn_cls: 0.1951  loss_rpn_loc: 0.5057  time: 0.1957  data_time: 0.0114  lr: 0.027572  max_mem: 1827M
[32m[09/20 14:21:45 d2.utils.events]: [0m eta: 0:38:35  iter: 939  total_loss: 1.376  loss_cls: 0.1356  loss_box_reg: 0.217  loss_mask: 0.2271  loss_rpn_cls: 0.2221  loss_rpn_loc: 0.5097  time: 0.1960  data_time: 0.0108  lr: 0.028172  max_mem: 1827M
[32m[09/20 14:21:49 d2.utils.events]: [0m eta: 0:38:33  iter: 959  total_loss: 1.511  loss_cls: 0.1775  loss_box_reg: 0.3356  loss_mask: 0.232  loss_rpn_cls: 0.2272  loss_rpn_loc: 0.4789  time: 0.1965  data_time: 0.0101  lr: 0.028771  max_mem: 1827M
[32m[09/20 14:21:53 d2.utils.events]: [0m eta: 0:38:30  iter: 979  total_loss: 1.366  loss_cls: 0.1585  loss_box_reg: 0.2718  loss_mask: 0.2305  loss_rpn_cls: 0.2051  loss_rpn_loc: 0.4942  time: 0.1964  data_time: 0.0093  lr: 0.029371  max_mem: 1827M
[32m[09/20 14:21:58 d2.utils.events]: [0m eta: 0:38:32  iter: 999  total_loss: 1.481  loss_cls: 0.1931  loss_box_reg: 0.3424  loss_mask: 0.2299  loss_rpn_cls: 0.1927  loss_rpn_loc: 0.499  time: 0.1967  data_time: 0.0140  lr: 0.02997  max_mem: 1827M
[32m[09/20 14:22:03 d2.utils.events]: [0m eta: 0:38:37  iter: 1019  total_loss: 1.426  loss_cls: 0.2063  loss_box_reg: 0.3806  loss_mask: 0.2199  loss_rpn_cls: 0.2124  loss_rpn_loc: 0.4577  time: 0.1972  data_time: 0.0084  lr: 0.03  max_mem: 1827M
[32m[09/20 14:22:07 d2.utils.events]: [0m eta: 0:38:41  iter: 1039  total_loss: 1.603  loss_cls: 0.1751  loss_box_reg: 0.2254  loss_mask: 0.2689  loss_rpn_cls: 0.433  loss_rpn_loc: 0.5651  time: 0.1976  data_time: 0.0123  lr: 0.03  max_mem: 1827M
[32m[09/20 14:22:11 d2.utils.events]: [0m eta: 0:38:50  iter: 1059  total_loss: 1.64  loss_cls: 0.1574  loss_box_reg: 0.1255  loss_mask: 0.2581  loss_rpn_cls: 0.4848  loss_rpn_loc: 0.5814  time: 0.1972  data_time: 0.0082  lr: 0.03  max_mem: 1827M
[32m[09/20 14:22:14 d2.utils.events]: [0m eta: 0:38:39  iter: 1079  total_loss: 1.512  loss_cls: 0.09482  loss_box_reg: 0.0799  loss_mask: 0.2576  loss_rpn_cls: 0.4916  loss_rpn_loc: 0.6258  time: 0.1962  data_time: 0.0098  lr: 0.03  max_mem: 1827M
[32m[09/20 14:22:17 d2.utils.events]: [0m eta: 0:38:33  iter: 1099  total_loss: 1.568  loss_cls: 0.1132  loss_box_reg: 0.1182  loss_mask: 0.2467  loss_rpn_cls: 0.4669  loss_rpn_loc: 0.5945  time: 0.1953  data_time: 0.0155  lr: 0.03  max_mem: 1827M
[32m[09/20 14:22:20 d2.utils.events]: [0m eta: 0:38:27  iter: 1119  total_loss: 1.372  loss_cls: 0.09968  loss_box_reg: 0.08854  loss_mask: 0.2196  loss_rpn_cls: 0.3106  loss_rpn_loc: 0.6124  time: 0.1945  data_time: 0.0146  lr: 0.03  max_mem: 1827M
[4m[5m[31mERROR[0m [32m[09/20 14:22:22 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 138, in train
    self.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 441, in run_step
    self._trainer.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 242, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 284, in _write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=1133!
loss_dict = {'loss_cls': nan, 'loss_box_reg': nan, 'loss_mask': nan, 'loss_rpn_cls': 0.5327228307723999, 'loss_rpn_loc': 0.675285816192627}
[32m[09/20 14:22:22 d2.engine.hooks]: [0mOverall training speed: 1131 iterations in 0:03:39 (0.1941 s / it)
[32m[09/20 14:22:22 d2.engine.hooks]: [0mTotal training time: 0:03:43 (0:00:03 on hooks)
[32m[09/20 14:22:22 d2.utils.events]: [0m eta: 0:38:21  iter: 1133  total_loss: 1.497  loss_cls: 0.1068  loss_box_reg: 0.07933  loss_mask: 0.2414  loss_rpn_cls: 0.4643  loss_rpn_loc: 0.6403  time: 0.1940  data_time: 0.0094  lr: 0.03  max_mem: 1827M
Traceback (most recent call last):
  File "train_powder_LR-0_03_T1.py", line 126, in <module>
    trainer.train()  # train the model!
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 431, in train
    super().train(self.start_iter, self.max_iter)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 138, in train
    self.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 441, in run_step
    self._trainer.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 242, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 284, in _write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=1133!
loss_dict = {'loss_cls': nan, 'loss_box_reg': nan, 'loss_mask': nan, 'loss_rpn_cls': 0.5327228307723999, 'loss_rpn_loc': 0.675285816192627}
/var/spool/slurm/d/job3725419/slurm_script: line 9: ./gpua.out: No such file or directory
