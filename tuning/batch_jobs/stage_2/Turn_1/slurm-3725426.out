Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_01_SE1_1000X45.png
	num_instances: 41
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_03_SE1_1000X53.png
	num_instances: 40
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_6S_250x.png
	num_instances: 102
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[09/20 14:34:11 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[09/20 14:34:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[09/20 14:34:12 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[09/20 14:34:12 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[09/20 14:34:12 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[09/20 14:34:12 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[09/20 14:34:12 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[09/20 14:34:12 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[09/20 14:34:12 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[09/20 14:34:12 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[09/20 14:34:12 d2.engine.train_loop]: [0mStarting training from iteration 0
/jet/home/sprice/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[32m[09/20 14:34:17 d2.utils.events]: [0m eta: 0:33:03  iter: 19  total_loss: 2.919  loss_cls: 0.587  loss_box_reg: 0.04068  loss_mask: 0.6291  loss_rpn_cls: 0.6572  loss_rpn_loc: 0.9848  time: 0.1356  data_time: 0.1205  lr: 0.0013987  max_mem: 1799M
[32m[09/20 14:34:20 d2.utils.events]: [0m eta: 0:33:28  iter: 39  total_loss: 2.073  loss_cls: 0.2552  loss_box_reg: 0.04811  loss_mask: 0.5902  loss_rpn_cls: 0.5774  loss_rpn_loc: 0.6091  time: 0.1377  data_time: 0.0140  lr: 0.0027973  max_mem: 1799M
[32m[09/20 14:34:23 d2.utils.events]: [0m eta: 0:33:25  iter: 59  total_loss: 2.231  loss_cls: 0.3016  loss_box_reg: 0.2206  loss_mask: 0.5408  loss_rpn_cls: 0.4927  loss_rpn_loc: 0.5871  time: 0.1370  data_time: 0.0146  lr: 0.0041959  max_mem: 1799M
[32m[09/20 14:34:25 d2.utils.events]: [0m eta: 0:33:30  iter: 79  total_loss: 2.083  loss_cls: 0.2652  loss_box_reg: 0.4058  loss_mask: 0.4874  loss_rpn_cls: 0.372  loss_rpn_loc: 0.5323  time: 0.1368  data_time: 0.0146  lr: 0.0055945  max_mem: 1824M
[32m[09/20 14:34:28 d2.utils.events]: [0m eta: 0:33:36  iter: 99  total_loss: 1.606  loss_cls: 0.1718  loss_box_reg: 0.1696  loss_mask: 0.4085  loss_rpn_cls: 0.3271  loss_rpn_loc: 0.5694  time: 0.1370  data_time: 0.0152  lr: 0.0069931  max_mem: 1824M
[32m[09/20 14:34:31 d2.utils.events]: [0m eta: 0:33:52  iter: 119  total_loss: 1.754  loss_cls: 0.2519  loss_box_reg: 0.2624  loss_mask: 0.3694  loss_rpn_cls: 0.2837  loss_rpn_loc: 0.5302  time: 0.1371  data_time: 0.0152  lr: 0.0083917  max_mem: 1824M
[32m[09/20 14:34:34 d2.utils.events]: [0m eta: 0:34:20  iter: 139  total_loss: 1.641  loss_cls: 0.2037  loss_box_reg: 0.2865  loss_mask: 0.3333  loss_rpn_cls: 0.2521  loss_rpn_loc: 0.48  time: 0.1383  data_time: 0.0152  lr: 0.0097903  max_mem: 1824M
[32m[09/20 14:34:37 d2.utils.events]: [0m eta: 0:34:11  iter: 159  total_loss: 1.703  loss_cls: 0.2058  loss_box_reg: 0.3055  loss_mask: 0.338  loss_rpn_cls: 0.2446  loss_rpn_loc: 0.5651  time: 0.1383  data_time: 0.0151  lr: 0.011189  max_mem: 1824M
[32m[09/20 14:34:39 d2.utils.events]: [0m eta: 0:34:12  iter: 179  total_loss: 1.642  loss_cls: 0.197  loss_box_reg: 0.362  loss_mask: 0.3412  loss_rpn_cls: 0.2467  loss_rpn_loc: 0.4727  time: 0.1385  data_time: 0.0148  lr: 0.012587  max_mem: 1824M
[32m[09/20 14:34:42 d2.utils.events]: [0m eta: 0:34:09  iter: 199  total_loss: 1.633  loss_cls: 0.1889  loss_box_reg: 0.3303  loss_mask: 0.3133  loss_rpn_cls: 0.2914  loss_rpn_loc: 0.5162  time: 0.1386  data_time: 0.0153  lr: 0.013986  max_mem: 1824M
[32m[09/20 14:34:45 d2.utils.events]: [0m eta: 0:34:04  iter: 219  total_loss: 1.726  loss_cls: 0.2048  loss_box_reg: 0.372  loss_mask: 0.3105  loss_rpn_cls: 0.2873  loss_rpn_loc: 0.5265  time: 0.1386  data_time: 0.0152  lr: 0.015385  max_mem: 1824M
[32m[09/20 14:34:48 d2.utils.events]: [0m eta: 0:34:13  iter: 239  total_loss: 1.56  loss_cls: 0.1656  loss_box_reg: 0.3012  loss_mask: 0.3009  loss_rpn_cls: 0.2728  loss_rpn_loc: 0.5226  time: 0.1389  data_time: 0.0145  lr: 0.016783  max_mem: 1824M
[32m[09/20 14:34:51 d2.utils.events]: [0m eta: 0:34:13  iter: 259  total_loss: 1.721  loss_cls: 0.201  loss_box_reg: 0.3409  loss_mask: 0.3072  loss_rpn_cls: 0.3041  loss_rpn_loc: 0.5251  time: 0.1390  data_time: 0.0148  lr: 0.018182  max_mem: 1824M
[32m[09/20 14:34:53 d2.utils.events]: [0m eta: 0:34:10  iter: 279  total_loss: 1.628  loss_cls: 0.1529  loss_box_reg: 0.239  loss_mask: 0.2866  loss_rpn_cls: 0.2594  loss_rpn_loc: 0.5996  time: 0.1388  data_time: 0.0155  lr: 0.01958  max_mem: 1824M
[32m[09/20 14:34:56 d2.utils.events]: [0m eta: 0:34:05  iter: 299  total_loss: 1.525  loss_cls: 0.1477  loss_box_reg: 0.2118  loss_mask: 0.2801  loss_rpn_cls: 0.3246  loss_rpn_loc: 0.561  time: 0.1387  data_time: 0.0149  lr: 0.020979  max_mem: 1824M
[32m[09/20 14:34:59 d2.utils.events]: [0m eta: 0:33:57  iter: 319  total_loss: 1.55  loss_cls: 0.1643  loss_box_reg: 0.2285  loss_mask: 0.2704  loss_rpn_cls: 0.3312  loss_rpn_loc: 0.5767  time: 0.1386  data_time: 0.0149  lr: 0.022378  max_mem: 1824M
[32m[09/20 14:35:02 d2.utils.events]: [0m eta: 0:33:57  iter: 339  total_loss: 1.51  loss_cls: 0.1613  loss_box_reg: 0.1884  loss_mask: 0.273  loss_rpn_cls: 0.28  loss_rpn_loc: 0.5923  time: 0.1387  data_time: 0.0151  lr: 0.023776  max_mem: 1824M
[32m[09/20 14:35:05 d2.utils.events]: [0m eta: 0:33:54  iter: 359  total_loss: 1.581  loss_cls: 0.1692  loss_box_reg: 0.2156  loss_mask: 0.299  loss_rpn_cls: 0.3039  loss_rpn_loc: 0.5963  time: 0.1385  data_time: 0.0151  lr: 0.025175  max_mem: 1824M
[32m[09/20 14:35:08 d2.utils.events]: [0m eta: 0:33:51  iter: 379  total_loss: 1.451  loss_cls: 0.1568  loss_box_reg: 0.2189  loss_mask: 0.2726  loss_rpn_cls: 0.2695  loss_rpn_loc: 0.5295  time: 0.1386  data_time: 0.0147  lr: 0.026573  max_mem: 1824M
[32m[09/20 14:35:10 d2.utils.events]: [0m eta: 0:33:43  iter: 399  total_loss: 1.441  loss_cls: 0.145  loss_box_reg: 0.2409  loss_mask: 0.2654  loss_rpn_cls: 0.2686  loss_rpn_loc: 0.5373  time: 0.1386  data_time: 0.0150  lr: 0.027972  max_mem: 1824M
[32m[09/20 14:35:13 d2.utils.events]: [0m eta: 0:33:44  iter: 419  total_loss: 1.492  loss_cls: 0.141  loss_box_reg: 0.1935  loss_mask: 0.254  loss_rpn_cls: 0.2689  loss_rpn_loc: 0.5602  time: 0.1386  data_time: 0.0154  lr: 0.029371  max_mem: 1824M
[32m[09/20 14:35:16 d2.utils.events]: [0m eta: 0:33:37  iter: 439  total_loss: 1.515  loss_cls: 0.1261  loss_box_reg: 0.1574  loss_mask: 0.2547  loss_rpn_cls: 0.3491  loss_rpn_loc: 0.618  time: 0.1385  data_time: 0.0149  lr: 0.030769  max_mem: 1824M
[32m[09/20 14:35:19 d2.utils.events]: [0m eta: 0:33:32  iter: 459  total_loss: 1.716  loss_cls: 0.1803  loss_box_reg: 0.1743  loss_mask: 0.3044  loss_rpn_cls: 0.3894  loss_rpn_loc: 0.6752  time: 0.1383  data_time: 0.0155  lr: 0.032168  max_mem: 1824M
[4m[5m[31mERROR[0m [32m[09/20 14:35:19 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 138, in train
    self.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 441, in run_step
    self._trainer.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 242, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 284, in _write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=461!
loss_dict = {'loss_cls': nan, 'loss_box_reg': nan, 'loss_mask': 5309176741888.0, 'loss_rpn_cls': 0.6482962369918823, 'loss_rpn_loc': 0.7124565839767456}
[32m[09/20 14:35:19 d2.engine.hooks]: [0mOverall training speed: 459 iterations in 0:01:03 (0.1386 s / it)
[32m[09/20 14:35:19 d2.engine.hooks]: [0mTotal training time: 0:01:04 (0:00:00 on hooks)
[32m[09/20 14:35:19 d2.utils.events]: [0m eta: 0:33:31  iter: 461  total_loss: 1.77  loss_cls: 0.1803  loss_box_reg: 0.1989  loss_mask: 0.3098  loss_rpn_cls: 0.4101  loss_rpn_loc: 0.6943  time: 0.1383  data_time: 0.0156  lr: 0.032238  max_mem: 1824M
Traceback (most recent call last):
  File "train_powder_LR-0_07_T1.py", line 126, in <module>
    trainer.train()  # train the model!
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 431, in train
    super().train(self.start_iter, self.max_iter)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 138, in train
    self.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 441, in run_step
    self._trainer.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 242, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 284, in _write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=461!
loss_dict = {'loss_cls': nan, 'loss_box_reg': nan, 'loss_mask': 5309176741888.0, 'loss_rpn_cls': 0.6482962369918823, 'loss_rpn_loc': 0.7124565839767456}
/var/spool/slurm/d/job3725426/slurm_script: line 9: ./gpua.out: No such file or directory
