Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_01_SE1_1000X45.png
	num_instances: 41
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_10S_500x.png
	num_instances: 32
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_03_SE1_1000X53.png
	num_instances: 40
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../../SALAS_Rep/../../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[10/27 12:55:47 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[10/27 12:55:48 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[10/27 12:55:48 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[10/27 12:55:48 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[10/27 12:55:48 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[10/27 12:55:48 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[10/27 12:55:48 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[10/27 12:55:48 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[10/27 12:55:48 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[10/27 12:55:48 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[10/27 12:55:48 d2.engine.train_loop]: [0mStarting training from iteration 0
/jet/home/sprice/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[32m[10/27 12:55:53 d2.utils.events]: [0m eta: 0:34:12  iter: 19  total_loss: 3.128  loss_cls: 0.5009  loss_box_reg: 0.02833  loss_mask: 0.682  loss_rpn_cls: 0.6728  loss_rpn_loc: 1.197  time: 0.1363  data_time: 0.1069  lr: 0.00013987  max_mem: 1700M
[32m[10/27 12:55:56 d2.utils.events]: [0m eta: 0:34:09  iter: 39  total_loss: 2.426  loss_cls: 0.2945  loss_box_reg: 0.018  loss_mask: 0.6131  loss_rpn_cls: 0.6032  loss_rpn_loc: 0.8292  time: 0.1368  data_time: 0.0149  lr: 0.00027973  max_mem: 1700M
[32m[10/27 12:55:58 d2.utils.events]: [0m eta: 0:34:17  iter: 59  total_loss: 2.029  loss_cls: 0.1988  loss_box_reg: 0.02937  loss_mask: 0.6024  loss_rpn_cls: 0.5781  loss_rpn_loc: 0.6409  time: 0.1370  data_time: 0.0149  lr: 0.00041959  max_mem: 1700M
[32m[10/27 12:56:01 d2.utils.events]: [0m eta: 0:34:04  iter: 79  total_loss: 1.929  loss_cls: 0.1422  loss_box_reg: 0.06126  loss_mask: 0.5584  loss_rpn_cls: 0.5769  loss_rpn_loc: 0.5637  time: 0.1361  data_time: 0.0147  lr: 0.00055945  max_mem: 1700M
[32m[10/27 12:56:04 d2.utils.events]: [0m eta: 0:34:07  iter: 99  total_loss: 1.923  loss_cls: 0.1567  loss_box_reg: 0.1364  loss_mask: 0.558  loss_rpn_cls: 0.5194  loss_rpn_loc: 0.5352  time: 0.1366  data_time: 0.0148  lr: 0.00069931  max_mem: 1700M
[32m[10/27 12:56:07 d2.utils.events]: [0m eta: 0:34:12  iter: 119  total_loss: 2.098  loss_cls: 0.2502  loss_box_reg: 0.2825  loss_mask: 0.5434  loss_rpn_cls: 0.4793  loss_rpn_loc: 0.5011  time: 0.1377  data_time: 0.0155  lr: 0.00083917  max_mem: 1710M
[32m[10/27 12:56:10 d2.utils.events]: [0m eta: 0:34:19  iter: 139  total_loss: 2.176  loss_cls: 0.2885  loss_box_reg: 0.406  loss_mask: 0.528  loss_rpn_cls: 0.393  loss_rpn_loc: 0.493  time: 0.1382  data_time: 0.0146  lr: 0.00097903  max_mem: 1819M
[32m[10/27 12:56:12 d2.utils.events]: [0m eta: 0:34:30  iter: 159  total_loss: 1.972  loss_cls: 0.2825  loss_box_reg: 0.3945  loss_mask: 0.5038  loss_rpn_cls: 0.3288  loss_rpn_loc: 0.4978  time: 0.1387  data_time: 0.0150  lr: 0.0011189  max_mem: 1819M
[32m[10/27 12:56:15 d2.utils.events]: [0m eta: 0:34:23  iter: 179  total_loss: 2.132  loss_cls: 0.2962  loss_box_reg: 0.3954  loss_mask: 0.4847  loss_rpn_cls: 0.3806  loss_rpn_loc: 0.5067  time: 0.1396  data_time: 0.0154  lr: 0.0012587  max_mem: 1819M
[32m[10/27 12:56:18 d2.utils.events]: [0m eta: 0:34:30  iter: 199  total_loss: 1.906  loss_cls: 0.2617  loss_box_reg: 0.3914  loss_mask: 0.4575  loss_rpn_cls: 0.3289  loss_rpn_loc: 0.4828  time: 0.1398  data_time: 0.0149  lr: 0.0013986  max_mem: 1819M
[32m[10/27 12:56:21 d2.utils.events]: [0m eta: 0:34:33  iter: 219  total_loss: 1.903  loss_cls: 0.2499  loss_box_reg: 0.4546  loss_mask: 0.4275  loss_rpn_cls: 0.3025  loss_rpn_loc: 0.4423  time: 0.1403  data_time: 0.0152  lr: 0.0015385  max_mem: 1819M
[32m[10/27 12:56:24 d2.utils.events]: [0m eta: 0:34:42  iter: 239  total_loss: 1.806  loss_cls: 0.2633  loss_box_reg: 0.4327  loss_mask: 0.4052  loss_rpn_cls: 0.3165  loss_rpn_loc: 0.4487  time: 0.1407  data_time: 0.0157  lr: 0.0016783  max_mem: 1819M
[32m[10/27 12:56:27 d2.utils.events]: [0m eta: 0:34:54  iter: 259  total_loss: 1.74  loss_cls: 0.2279  loss_box_reg: 0.3431  loss_mask: 0.3932  loss_rpn_cls: 0.2587  loss_rpn_loc: 0.4763  time: 0.1413  data_time: 0.0155  lr: 0.0018182  max_mem: 1819M
[32m[10/27 12:56:30 d2.utils.events]: [0m eta: 0:34:49  iter: 279  total_loss: 1.694  loss_cls: 0.2419  loss_box_reg: 0.3601  loss_mask: 0.3646  loss_rpn_cls: 0.2417  loss_rpn_loc: 0.4342  time: 0.1413  data_time: 0.0150  lr: 0.001958  max_mem: 1819M
[32m[10/27 12:56:33 d2.utils.events]: [0m eta: 0:34:46  iter: 299  total_loss: 1.716  loss_cls: 0.2268  loss_box_reg: 0.3699  loss_mask: 0.3675  loss_rpn_cls: 0.2803  loss_rpn_loc: 0.4347  time: 0.1414  data_time: 0.0155  lr: 0.0020979  max_mem: 1819M
[32m[10/27 12:56:36 d2.utils.events]: [0m eta: 0:34:48  iter: 319  total_loss: 1.793  loss_cls: 0.2714  loss_box_reg: 0.478  loss_mask: 0.3689  loss_rpn_cls: 0.2249  loss_rpn_loc: 0.4283  time: 0.1417  data_time: 0.0149  lr: 0.0022378  max_mem: 1819M
[32m[10/27 12:56:39 d2.utils.events]: [0m eta: 0:34:47  iter: 339  total_loss: 1.708  loss_cls: 0.2357  loss_box_reg: 0.4509  loss_mask: 0.3411  loss_rpn_cls: 0.258  loss_rpn_loc: 0.4345  time: 0.1419  data_time: 0.0154  lr: 0.0023776  max_mem: 1819M
[32m[10/27 12:56:42 d2.utils.events]: [0m eta: 0:34:51  iter: 359  total_loss: 1.873  loss_cls: 0.2785  loss_box_reg: 0.4763  loss_mask: 0.3672  loss_rpn_cls: 0.2663  loss_rpn_loc: 0.477  time: 0.1422  data_time: 0.0151  lr: 0.0025175  max_mem: 1819M
[32m[10/27 12:56:45 d2.utils.events]: [0m eta: 0:34:49  iter: 379  total_loss: 1.779  loss_cls: 0.2696  loss_box_reg: 0.4594  loss_mask: 0.3243  loss_rpn_cls: 0.2632  loss_rpn_loc: 0.4122  time: 0.1425  data_time: 0.0154  lr: 0.0026573  max_mem: 1819M
[32m[10/27 12:56:48 d2.utils.events]: [0m eta: 0:34:47  iter: 399  total_loss: 1.797  loss_cls: 0.255  loss_box_reg: 0.4997  loss_mask: 0.3572  loss_rpn_cls: 0.233  loss_rpn_loc: 0.4303  time: 0.1427  data_time: 0.0160  lr: 0.0027972  max_mem: 1819M
[32m[10/27 12:56:51 d2.utils.events]: [0m eta: 0:34:46  iter: 419  total_loss: 1.727  loss_cls: 0.2624  loss_box_reg: 0.4854  loss_mask: 0.3263  loss_rpn_cls: 0.2435  loss_rpn_loc: 0.423  time: 0.1429  data_time: 0.0152  lr: 0.0029371  max_mem: 1819M
[32m[10/27 12:56:54 d2.utils.events]: [0m eta: 0:34:44  iter: 439  total_loss: 1.698  loss_cls: 0.2503  loss_box_reg: 0.4563  loss_mask: 0.3143  loss_rpn_cls: 0.2518  loss_rpn_loc: 0.4241  time: 0.1430  data_time: 0.0154  lr: 0.0030769  max_mem: 1819M
[32m[10/27 12:56:57 d2.utils.events]: [0m eta: 0:34:45  iter: 459  total_loss: 1.712  loss_cls: 0.2651  loss_box_reg: 0.5057  loss_mask: 0.2957  loss_rpn_cls: 0.2213  loss_rpn_loc: 0.4163  time: 0.1434  data_time: 0.0144  lr: 0.0032168  max_mem: 1819M
[32m[10/27 12:57:00 d2.utils.events]: [0m eta: 0:34:44  iter: 479  total_loss: 1.559  loss_cls: 0.2288  loss_box_reg: 0.4308  loss_mask: 0.3034  loss_rpn_cls: 0.2203  loss_rpn_loc: 0.3744  time: 0.1434  data_time: 0.0151  lr: 0.0033566  max_mem: 1819M
[32m[10/27 12:57:03 d2.utils.events]: [0m eta: 0:34:44  iter: 499  total_loss: 1.618  loss_cls: 0.2422  loss_box_reg: 0.4978  loss_mask: 0.3168  loss_rpn_cls: 0.2213  loss_rpn_loc: 0.3876  time: 0.1436  data_time: 0.0152  lr: 0.0034965  max_mem: 1819M
[32m[10/27 12:57:06 d2.utils.events]: [0m eta: 0:34:45  iter: 519  total_loss: 1.685  loss_cls: 0.264  loss_box_reg: 0.5111  loss_mask: 0.2886  loss_rpn_cls: 0.2245  loss_rpn_loc: 0.3831  time: 0.1437  data_time: 0.0155  lr: 0.0036364  max_mem: 1819M
[32m[10/27 12:57:09 d2.utils.events]: [0m eta: 0:34:44  iter: 539  total_loss: 1.661  loss_cls: 0.2491  loss_box_reg: 0.5293  loss_mask: 0.301  loss_rpn_cls: 0.1886  loss_rpn_loc: 0.3609  time: 0.1438  data_time: 0.0145  lr: 0.0037762  max_mem: 1819M
[32m[10/27 12:57:12 d2.utils.events]: [0m eta: 0:34:46  iter: 559  total_loss: 1.61  loss_cls: 0.2397  loss_box_reg: 0.5031  loss_mask: 0.2775  loss_rpn_cls: 0.1793  loss_rpn_loc: 0.3965  time: 0.1440  data_time: 0.0149  lr: 0.0039161  max_mem: 1819M
[32m[10/27 12:57:15 d2.utils.events]: [0m eta: 0:34:43  iter: 579  total_loss: 1.629  loss_cls: 0.2174  loss_box_reg: 0.4588  loss_mask: 0.2624  loss_rpn_cls: 0.2225  loss_rpn_loc: 0.4164  time: 0.1441  data_time: 0.0153  lr: 0.0040559  max_mem: 1819M
[32m[10/27 12:57:18 d2.utils.events]: [0m eta: 0:34:38  iter: 599  total_loss: 1.63  loss_cls: 0.2459  loss_box_reg: 0.4503  loss_mask: 0.2788  loss_rpn_cls: 0.2494  loss_rpn_loc: 0.3997  time: 0.1441  data_time: 0.0147  lr: 0.0041958  max_mem: 1819M
[32m[10/27 12:57:21 d2.utils.events]: [0m eta: 0:34:35  iter: 619  total_loss: 1.614  loss_cls: 0.2317  loss_box_reg: 0.4733  loss_mask: 0.27  loss_rpn_cls: 0.1943  loss_rpn_loc: 0.4023  time: 0.1441  data_time: 0.0148  lr: 0.0043357  max_mem: 1819M
[32m[10/27 12:57:24 d2.utils.events]: [0m eta: 0:34:34  iter: 639  total_loss: 1.61  loss_cls: 0.2557  loss_box_reg: 0.4686  loss_mask: 0.2706  loss_rpn_cls: 0.2198  loss_rpn_loc: 0.3819  time: 0.1442  data_time: 0.0153  lr: 0.0044755  max_mem: 1819M
[32m[10/27 12:57:27 d2.utils.events]: [0m eta: 0:34:31  iter: 659  total_loss: 1.606  loss_cls: 0.2389  loss_box_reg: 0.4888  loss_mask: 0.2771  loss_rpn_cls: 0.2245  loss_rpn_loc: 0.399  time: 0.1442  data_time: 0.0151  lr: 0.0046154  max_mem: 1819M
[32m[10/27 12:57:30 d2.utils.events]: [0m eta: 0:34:28  iter: 679  total_loss: 1.572  loss_cls: 0.2535  loss_box_reg: 0.4828  loss_mask: 0.2705  loss_rpn_cls: 0.1955  loss_rpn_loc: 0.3786  time: 0.1442  data_time: 0.0148  lr: 0.0047552  max_mem: 1819M
[32m[10/27 12:57:33 d2.utils.events]: [0m eta: 0:34:25  iter: 699  total_loss: 1.598  loss_cls: 0.2272  loss_box_reg: 0.4815  loss_mask: 0.2659  loss_rpn_cls: 0.1687  loss_rpn_loc: 0.4058  time: 0.1443  data_time: 0.0153  lr: 0.0048951  max_mem: 1819M
[32m[10/27 12:57:36 d2.utils.events]: [0m eta: 0:34:25  iter: 719  total_loss: 1.625  loss_cls: 0.2711  loss_box_reg: 0.5211  loss_mask: 0.2674  loss_rpn_cls: 0.1763  loss_rpn_loc: 0.3627  time: 0.1444  data_time: 0.0154  lr: 0.005035  max_mem: 1819M
[32m[10/27 12:57:39 d2.utils.events]: [0m eta: 0:34:23  iter: 739  total_loss: 1.589  loss_cls: 0.264  loss_box_reg: 0.491  loss_mask: 0.2637  loss_rpn_cls: 0.1768  loss_rpn_loc: 0.3899  time: 0.1444  data_time: 0.0149  lr: 0.0051748  max_mem: 1819M
[32m[10/27 12:57:42 d2.utils.events]: [0m eta: 0:34:20  iter: 759  total_loss: 1.546  loss_cls: 0.2472  loss_box_reg: 0.4897  loss_mask: 0.2524  loss_rpn_cls: 0.1417  loss_rpn_loc: 0.3468  time: 0.1445  data_time: 0.0152  lr: 0.0053147  max_mem: 1819M
[32m[10/27 12:57:45 d2.utils.events]: [0m eta: 0:34:18  iter: 779  total_loss: 1.571  loss_cls: 0.2341  loss_box_reg: 0.503  loss_mask: 0.2567  loss_rpn_cls: 0.2049  loss_rpn_loc: 0.395  time: 0.1446  data_time: 0.0157  lr: 0.0054545  max_mem: 1819M
[32m[10/27 12:57:48 d2.utils.events]: [0m eta: 0:34:16  iter: 799  total_loss: 1.541  loss_cls: 0.2558  loss_box_reg: 0.4691  loss_mask: 0.2404  loss_rpn_cls: 0.1868  loss_rpn_loc: 0.3944  time: 0.1447  data_time: 0.0145  lr: 0.0055944  max_mem: 1819M
[32m[10/27 12:57:52 d2.utils.events]: [0m eta: 0:34:15  iter: 819  total_loss: 1.403  loss_cls: 0.2076  loss_box_reg: 0.4152  loss_mask: 0.2496  loss_rpn_cls: 0.1572  loss_rpn_loc: 0.394  time: 0.1449  data_time: 0.0157  lr: 0.0057343  max_mem: 1819M
[32m[10/27 12:57:54 d2.utils.events]: [0m eta: 0:34:14  iter: 839  total_loss: 1.584  loss_cls: 0.2697  loss_box_reg: 0.4973  loss_mask: 0.279  loss_rpn_cls: 0.205  loss_rpn_loc: 0.3639  time: 0.1449  data_time: 0.0148  lr: 0.0058741  max_mem: 1819M
[32m[10/27 12:57:57 d2.utils.events]: [0m eta: 0:34:12  iter: 859  total_loss: 1.564  loss_cls: 0.2516  loss_box_reg: 0.4903  loss_mask: 0.2413  loss_rpn_cls: 0.1334  loss_rpn_loc: 0.375  time: 0.1450  data_time: 0.0145  lr: 0.006014  max_mem: 1819M
[32m[10/27 12:58:00 d2.utils.events]: [0m eta: 0:34:10  iter: 879  total_loss: 1.518  loss_cls: 0.2301  loss_box_reg: 0.5018  loss_mask: 0.2628  loss_rpn_cls: 0.1638  loss_rpn_loc: 0.3846  time: 0.1451  data_time: 0.0160  lr: 0.0061538  max_mem: 1819M
[32m[10/27 12:58:03 d2.utils.events]: [0m eta: 0:34:07  iter: 899  total_loss: 1.512  loss_cls: 0.2183  loss_box_reg: 0.4562  loss_mask: 0.2471  loss_rpn_cls: 0.1816  loss_rpn_loc: 0.3898  time: 0.1451  data_time: 0.0150  lr: 0.0062937  max_mem: 1819M
[32m[10/27 12:58:06 d2.utils.events]: [0m eta: 0:34:03  iter: 919  total_loss: 1.441  loss_cls: 0.2341  loss_box_reg: 0.4591  loss_mask: 0.2363  loss_rpn_cls: 0.16  loss_rpn_loc: 0.3518  time: 0.1451  data_time: 0.0153  lr: 0.0064336  max_mem: 1819M
[32m[10/27 12:58:09 d2.utils.events]: [0m eta: 0:34:02  iter: 939  total_loss: 1.471  loss_cls: 0.2235  loss_box_reg: 0.5023  loss_mask: 0.2437  loss_rpn_cls: 0.1439  loss_rpn_loc: 0.3338  time: 0.1452  data_time: 0.0161  lr: 0.0065734  max_mem: 1819M
[32m[10/27 12:58:12 d2.utils.events]: [0m eta: 0:34:01  iter: 959  total_loss: 1.515  loss_cls: 0.2448  loss_box_reg: 0.4439  loss_mask: 0.2448  loss_rpn_cls: 0.1524  loss_rpn_loc: 0.3891  time: 0.1452  data_time: 0.0151  lr: 0.0067133  max_mem: 1819M
[32m[10/27 12:58:15 d2.utils.events]: [0m eta: 0:33:57  iter: 979  total_loss: 1.527  loss_cls: 0.2472  loss_box_reg: 0.4895  loss_mask: 0.2574  loss_rpn_cls: 0.1609  loss_rpn_loc: 0.3945  time: 0.1452  data_time: 0.0144  lr: 0.0068531  max_mem: 1819M
[32m[10/27 12:58:19 d2.utils.events]: [0m eta: 0:33:55  iter: 999  total_loss: 1.491  loss_cls: 0.2384  loss_box_reg: 0.4992  loss_mask: 0.2487  loss_rpn_cls: 0.1541  loss_rpn_loc: 0.3448  time: 0.1453  data_time: 0.0157  lr: 0.006993  max_mem: 1819M
[32m[10/27 12:58:22 d2.utils.events]: [0m eta: 0:33:53  iter: 1019  total_loss: 1.623  loss_cls: 0.2478  loss_box_reg: 0.4927  loss_mask: 0.2529  loss_rpn_cls: 0.1874  loss_rpn_loc: 0.3861  time: 0.1453  data_time: 0.0151  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:25 d2.utils.events]: [0m eta: 0:33:53  iter: 1039  total_loss: 1.471  loss_cls: 0.2021  loss_box_reg: 0.4115  loss_mask: 0.2432  loss_rpn_cls: 0.1488  loss_rpn_loc: 0.3769  time: 0.1454  data_time: 0.0154  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:28 d2.utils.events]: [0m eta: 0:33:53  iter: 1059  total_loss: 1.44  loss_cls: 0.1985  loss_box_reg: 0.4546  loss_mask: 0.2348  loss_rpn_cls: 0.1725  loss_rpn_loc: 0.3518  time: 0.1454  data_time: 0.0158  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:31 d2.utils.events]: [0m eta: 0:33:52  iter: 1079  total_loss: 1.465  loss_cls: 0.2244  loss_box_reg: 0.4317  loss_mask: 0.2321  loss_rpn_cls: 0.1937  loss_rpn_loc: 0.3676  time: 0.1455  data_time: 0.0147  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:34 d2.utils.events]: [0m eta: 0:33:52  iter: 1099  total_loss: 1.407  loss_cls: 0.2168  loss_box_reg: 0.4567  loss_mask: 0.2381  loss_rpn_cls: 0.1127  loss_rpn_loc: 0.3709  time: 0.1455  data_time: 0.0154  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:37 d2.utils.events]: [0m eta: 0:33:49  iter: 1119  total_loss: 1.402  loss_cls: 0.2072  loss_box_reg: 0.4197  loss_mask: 0.2367  loss_rpn_cls: 0.1457  loss_rpn_loc: 0.3821  time: 0.1455  data_time: 0.0150  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:40 d2.utils.events]: [0m eta: 0:33:46  iter: 1139  total_loss: 1.41  loss_cls: 0.2005  loss_box_reg: 0.4371  loss_mask: 0.2373  loss_rpn_cls: 0.1474  loss_rpn_loc: 0.3519  time: 0.1455  data_time: 0.0152  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:43 d2.utils.events]: [0m eta: 0:33:46  iter: 1159  total_loss: 1.323  loss_cls: 0.1998  loss_box_reg: 0.4448  loss_mask: 0.243  loss_rpn_cls: 0.121  loss_rpn_loc: 0.3193  time: 0.1456  data_time: 0.0156  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:46 d2.utils.events]: [0m eta: 0:33:45  iter: 1179  total_loss: 1.474  loss_cls: 0.2215  loss_box_reg: 0.4609  loss_mask: 0.2344  loss_rpn_cls: 0.141  loss_rpn_loc: 0.345  time: 0.1456  data_time: 0.0144  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:49 d2.utils.events]: [0m eta: 0:33:43  iter: 1199  total_loss: 1.328  loss_cls: 0.1826  loss_box_reg: 0.3981  loss_mask: 0.234  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.3767  time: 0.1457  data_time: 0.0154  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:52 d2.utils.events]: [0m eta: 0:33:41  iter: 1219  total_loss: 1.342  loss_cls: 0.1968  loss_box_reg: 0.4212  loss_mask: 0.2212  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.334  time: 0.1457  data_time: 0.0150  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:55 d2.utils.events]: [0m eta: 0:33:39  iter: 1239  total_loss: 1.328  loss_cls: 0.1897  loss_box_reg: 0.4201  loss_mask: 0.2237  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.3625  time: 0.1458  data_time: 0.0154  lr: 0.007  max_mem: 1819M
[32m[10/27 12:58:58 d2.utils.events]: [0m eta: 0:33:36  iter: 1259  total_loss: 1.435  loss_cls: 0.2386  loss_box_reg: 0.4546  loss_mask: 0.2264  loss_rpn_cls: 0.1276  loss_rpn_loc: 0.3313  time: 0.1458  data_time: 0.0153  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:01 d2.utils.events]: [0m eta: 0:33:35  iter: 1279  total_loss: 1.446  loss_cls: 0.243  loss_box_reg: 0.4787  loss_mask: 0.2202  loss_rpn_cls: 0.1384  loss_rpn_loc: 0.3665  time: 0.1458  data_time: 0.0152  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:04 d2.utils.events]: [0m eta: 0:33:33  iter: 1299  total_loss: 1.395  loss_cls: 0.2074  loss_box_reg: 0.417  loss_mask: 0.2187  loss_rpn_cls: 0.1489  loss_rpn_loc: 0.4005  time: 0.1458  data_time: 0.0143  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:07 d2.utils.events]: [0m eta: 0:33:31  iter: 1319  total_loss: 1.353  loss_cls: 0.194  loss_box_reg: 0.4554  loss_mask: 0.2345  loss_rpn_cls: 0.1558  loss_rpn_loc: 0.3505  time: 0.1459  data_time: 0.0157  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:10 d2.utils.events]: [0m eta: 0:33:28  iter: 1339  total_loss: 1.374  loss_cls: 0.2058  loss_box_reg: 0.4663  loss_mask: 0.2197  loss_rpn_cls: 0.1387  loss_rpn_loc: 0.3472  time: 0.1459  data_time: 0.0153  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:13 d2.utils.events]: [0m eta: 0:33:25  iter: 1359  total_loss: 1.323  loss_cls: 0.2098  loss_box_reg: 0.4526  loss_mask: 0.2205  loss_rpn_cls: 0.1269  loss_rpn_loc: 0.3273  time: 0.1459  data_time: 0.0150  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:16 d2.utils.events]: [0m eta: 0:33:22  iter: 1379  total_loss: 1.285  loss_cls: 0.1741  loss_box_reg: 0.4055  loss_mask: 0.211  loss_rpn_cls: 0.134  loss_rpn_loc: 0.3437  time: 0.1460  data_time: 0.0154  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:19 d2.utils.events]: [0m eta: 0:33:19  iter: 1399  total_loss: 1.295  loss_cls: 0.1781  loss_box_reg: 0.4166  loss_mask: 0.2177  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.3406  time: 0.1460  data_time: 0.0145  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:22 d2.utils.events]: [0m eta: 0:33:16  iter: 1419  total_loss: 1.271  loss_cls: 0.2038  loss_box_reg: 0.4415  loss_mask: 0.2122  loss_rpn_cls: 0.1324  loss_rpn_loc: 0.312  time: 0.1460  data_time: 0.0151  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:25 d2.utils.events]: [0m eta: 0:33:14  iter: 1439  total_loss: 1.297  loss_cls: 0.1946  loss_box_reg: 0.4457  loss_mask: 0.2281  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.3495  time: 0.1461  data_time: 0.0147  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:28 d2.utils.events]: [0m eta: 0:33:10  iter: 1459  total_loss: 1.255  loss_cls: 0.1791  loss_box_reg: 0.3598  loss_mask: 0.2093  loss_rpn_cls: 0.138  loss_rpn_loc: 0.3339  time: 0.1462  data_time: 0.0151  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:31 d2.utils.events]: [0m eta: 0:33:07  iter: 1479  total_loss: 1.346  loss_cls: 0.1998  loss_box_reg: 0.4256  loss_mask: 0.2124  loss_rpn_cls: 0.1544  loss_rpn_loc: 0.3402  time: 0.1462  data_time: 0.0154  lr: 0.007  max_mem: 1819M
[32m[10/27 12:59:34 d2.utils.events]: [0m eta: 0:33:04  iter: 1499  total_loss: 1.263  loss_cls: 0.2084  loss_box_reg: 0.4387  loss_mask: 0.214  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.3042  time: 0.1462  data_time: 0.0144  lr: 0.007  max_mem: 1819M
