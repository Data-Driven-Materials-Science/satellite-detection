Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/S04_01_SE1_1000X45.png
	num_instances: 41
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/S06_02_SE1_500X71.png
	num_instances: 104
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/HP743_11S_500x.png
	num_instances: 25
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../../../../../../../ocean/projects/dmr200021p/sprice/tuning/images/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[09/14 23:39:05 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[09/14 23:39:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[09/14 23:39:05 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[09/14 23:39:05 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[09/14 23:39:05 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[09/14 23:39:05 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[09/14 23:39:05 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[09/14 23:39:05 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[09/14 23:39:05 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[09/14 23:39:05 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[09/14 23:39:05 d2.engine.train_loop]: [0mStarting training from iteration 0
/jet/home/sprice/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[32m[09/14 23:39:10 d2.utils.events]: [0m eta: 0:34:41  iter: 19  total_loss: 2.702  loss_cls: 0.4893  loss_box_reg: 0.0446  loss_mask: 0.6198  loss_rpn_cls: 0.6244  loss_rpn_loc: 0.925  time: 0.1370  data_time: 0.1152  lr: 0.0019981  max_mem: 1668M
[32m[09/14 23:39:13 d2.utils.events]: [0m eta: 0:35:04  iter: 39  total_loss: 2.313  loss_cls: 0.2995  loss_box_reg: 0.2991  loss_mask: 0.5633  loss_rpn_cls: 0.5359  loss_rpn_loc: 0.5858  time: 0.1416  data_time: 0.0148  lr: 0.0039961  max_mem: 1677M
[32m[09/14 23:39:16 d2.utils.events]: [0m eta: 0:35:15  iter: 59  total_loss: 2.307  loss_cls: 0.3404  loss_box_reg: 0.4655  loss_mask: 0.5174  loss_rpn_cls: 0.4214  loss_rpn_loc: 0.5257  time: 0.1423  data_time: 0.0153  lr: 0.0059941  max_mem: 1715M
[32m[09/14 23:39:19 d2.utils.events]: [0m eta: 0:35:07  iter: 79  total_loss: 1.882  loss_cls: 0.2413  loss_box_reg: 0.356  loss_mask: 0.4439  loss_rpn_cls: 0.3363  loss_rpn_loc: 0.5251  time: 0.1424  data_time: 0.0152  lr: 0.0079921  max_mem: 1715M
[32m[09/14 23:39:22 d2.utils.events]: [0m eta: 0:35:06  iter: 99  total_loss: 1.75  loss_cls: 0.2458  loss_box_reg: 0.2438  loss_mask: 0.3811  loss_rpn_cls: 0.2679  loss_rpn_loc: 0.5507  time: 0.1421  data_time: 0.0153  lr: 0.0099901  max_mem: 1776M
[32m[09/14 23:39:24 d2.utils.events]: [0m eta: 0:34:58  iter: 119  total_loss: 1.672  loss_cls: 0.1402  loss_box_reg: 0.1325  loss_mask: 0.3676  loss_rpn_cls: 0.3149  loss_rpn_loc: 0.6835  time: 0.1413  data_time: 0.0152  lr: 0.011988  max_mem: 1825M
[32m[09/14 23:39:27 d2.utils.events]: [0m eta: 0:35:00  iter: 139  total_loss: 1.885  loss_cls: 0.201  loss_box_reg: 0.301  loss_mask: 0.3522  loss_rpn_cls: 0.3517  loss_rpn_loc: 0.6147  time: 0.1415  data_time: 0.0156  lr: 0.013986  max_mem: 1825M
[32m[09/14 23:39:30 d2.utils.events]: [0m eta: 0:34:59  iter: 159  total_loss: 1.835  loss_cls: 0.2379  loss_box_reg: 0.2702  loss_mask: 0.3304  loss_rpn_cls: 0.3393  loss_rpn_loc: 0.6243  time: 0.1415  data_time: 0.0158  lr: 0.015984  max_mem: 1825M
[32m[09/14 23:39:33 d2.utils.events]: [0m eta: 0:34:54  iter: 179  total_loss: 1.554  loss_cls: 0.2093  loss_box_reg: 0.2853  loss_mask: 0.3023  loss_rpn_cls: 0.2525  loss_rpn_loc: 0.5628  time: 0.1411  data_time: 0.0142  lr: 0.017982  max_mem: 1825M
[32m[09/14 23:39:36 d2.utils.events]: [0m eta: 0:34:51  iter: 199  total_loss: 1.565  loss_cls: 0.1886  loss_box_reg: 0.2135  loss_mask: 0.3056  loss_rpn_cls: 0.3081  loss_rpn_loc: 0.5767  time: 0.1412  data_time: 0.0156  lr: 0.01998  max_mem: 1825M
[32m[09/14 23:39:39 d2.utils.events]: [0m eta: 0:34:46  iter: 219  total_loss: 1.582  loss_cls: 0.158  loss_box_reg: 0.2385  loss_mask: 0.3047  loss_rpn_cls: 0.3418  loss_rpn_loc: 0.5275  time: 0.1412  data_time: 0.0150  lr: 0.021978  max_mem: 1825M
[32m[09/14 23:39:42 d2.utils.events]: [0m eta: 0:34:43  iter: 239  total_loss: 1.444  loss_cls: 0.1563  loss_box_reg: 0.216  loss_mask: 0.2982  loss_rpn_cls: 0.271  loss_rpn_loc: 0.5387  time: 0.1414  data_time: 0.0152  lr: 0.023976  max_mem: 1825M
[32m[09/14 23:39:44 d2.utils.events]: [0m eta: 0:34:37  iter: 259  total_loss: 1.662  loss_cls: 0.2086  loss_box_reg: 0.2711  loss_mask: 0.2823  loss_rpn_cls: 0.2699  loss_rpn_loc: 0.5383  time: 0.1411  data_time: 0.0148  lr: 0.025974  max_mem: 1825M
[32m[09/14 23:39:47 d2.utils.events]: [0m eta: 0:34:36  iter: 279  total_loss: 1.49  loss_cls: 0.1868  loss_box_reg: 0.2738  loss_mask: 0.2838  loss_rpn_cls: 0.2222  loss_rpn_loc: 0.5226  time: 0.1413  data_time: 0.0151  lr: 0.027972  max_mem: 1825M
[32m[09/14 23:39:50 d2.utils.events]: [0m eta: 0:34:29  iter: 299  total_loss: 1.437  loss_cls: 0.1717  loss_box_reg: 0.229  loss_mask: 0.2897  loss_rpn_cls: 0.2544  loss_rpn_loc: 0.5693  time: 0.1411  data_time: 0.0151  lr: 0.02997  max_mem: 1825M
[32m[09/14 23:39:53 d2.utils.events]: [0m eta: 0:34:26  iter: 319  total_loss: 1.381  loss_cls: 0.1253  loss_box_reg: 0.1575  loss_mask: 0.2728  loss_rpn_cls: 0.2495  loss_rpn_loc: 0.6315  time: 0.1409  data_time: 0.0156  lr: 0.031968  max_mem: 1825M
[32m[09/14 23:39:56 d2.utils.events]: [0m eta: 0:34:21  iter: 339  total_loss: 1.568  loss_cls: 0.1505  loss_box_reg: 0.1894  loss_mask: 0.2656  loss_rpn_cls: 0.3624  loss_rpn_loc: 0.6171  time: 0.1409  data_time: 0.0167  lr: 0.033966  max_mem: 1825M
[32m[09/14 23:39:58 d2.utils.events]: [0m eta: 0:34:16  iter: 359  total_loss: 1.389  loss_cls: 0.1104  loss_box_reg: 0.07745  loss_mask: 0.2959  loss_rpn_cls: 0.3224  loss_rpn_loc: 0.6075  time: 0.1406  data_time: 0.0142  lr: 0.035964  max_mem: 1825M
[32m[09/14 23:40:01 d2.utils.events]: [0m eta: 0:34:05  iter: 379  total_loss: 1.722  loss_cls: 0.1291  loss_box_reg: 0.1145  loss_mask: 0.2905  loss_rpn_cls: 0.3943  loss_rpn_loc: 0.6779  time: 0.1403  data_time: 0.0152  lr: 0.037962  max_mem: 1825M
[4m[5m[31mERROR[0m [32m[09/14 23:40:02 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 138, in train
    self.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 441, in run_step
    self._trainer.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 242, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 284, in _write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=385!
loss_dict = {'loss_cls': nan, 'loss_box_reg': nan, 'loss_mask': 0.7618722319602966, 'loss_rpn_cls': 0.6261377334594727, 'loss_rpn_loc': 0.6678214073181152}
[32m[09/14 23:40:02 d2.engine.hooks]: [0mOverall training speed: 383 iterations in 0:00:53 (0.1406 s / it)
[32m[09/14 23:40:02 d2.engine.hooks]: [0mTotal training time: 0:00:54 (0:00:00 on hooks)
[32m[09/14 23:40:02 d2.utils.events]: [0m eta: 0:34:03  iter: 385  total_loss: 1.811  loss_cls: 0.1903  loss_box_reg: 0.1244  loss_mask: 0.3185  loss_rpn_cls: 0.4352  loss_rpn_loc: 0.736  time: 0.1402  data_time: 0.0156  lr: 0.038462  max_mem: 1825M
Traceback (most recent call last):
  File "train_powder_LR-0_1B.py", line 125, in <module>
    trainer.train()  # train the model!
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 431, in train
    super().train(self.start_iter, self.max_iter)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 138, in train
    self.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 441, in run_step
    self._trainer.run_step()
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 242, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/jet/home/sprice/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 284, in _write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=385!
loss_dict = {'loss_cls': nan, 'loss_box_reg': nan, 'loss_mask': 0.7618722319602966, 'loss_rpn_cls': 0.6261377334594727, 'loss_rpn_loc': 0.6678214073181152}
/var/spool/slurm/d/job3617959/slurm_script: line 9: ./gpua.out: No such file or directory
