{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies\n",
    "\n",
    "### Instance Segmentation of Powder Particles and Satellites\n",
    "\n",
    "This example is used to generate a visualization of an individual image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regular module imports\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import skimage.io\n",
    "import sys\n",
    "\n",
    "## detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import (\n",
    "    DatasetCatalog,\n",
    "    MetadataCatalog,\n",
    ")\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.structures import BoxMode\n",
    "#from detectron2.evaluation import coco_evaluation\n",
    "from detectron2.data.datasets.coco import convert_to_coco_json\n",
    "from detectron2.evaluation.coco_evaluation import instances_to_coco_json\n",
    "from detectron2.utils.visualizer import GenericMask\n",
    "import pycocotools.mask as mask_util\n",
    "from skimage import measure\n",
    "from imantics import Polygons, Mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting System Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ampis\n",
    "root = '../../'\n",
    "sys.path.append(root)\n",
    "from ampis import data_utils, visualize, export_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'satellite' # can be 'particles' or 'satellite'\n",
    "#json_path_train = Path('..', 'data','via_2.0.8/', f'via_powder_{EXPERIMENT_NAME}_masks_training.json')  # path to training data\n",
    "#json_path_val = Path('..','data','via_2.0.8/', f'via_powder_{EXPERIMENT_NAME}_masks_validation.json')  # path to training data\n",
    "\n",
    "#assert json_path_train.is_file(), 'training file not found!'\n",
    "#assert json_path_val.is_file(), 'validation file not found!'\n",
    "\n",
    "cfg = get_cfg() # initialize cfg object\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'))  # load default parameters for Mask R-CNN\n",
    "cfg.MODEL.DEVICE='cuda'  # 'cpu' to force model to run on cpu, 'cuda' if you have a compatible gpu\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 # Since we are training separate models for particles and satellites there is only one class output\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 400 if EXPERIMENT_NAME == 'particle' else 150  # maximum number of instances that can be detected in an image (this is fixed in mask r-cnn)\n",
    "                        # Increasing this may improve the training results, but will take longer to run (especially without a gpu!) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model weights will be downloaded if they are not present\n",
    "\n",
    "'''weights_path = Path(root,'examples','powder','satellite_output','model_final.pth')\n",
    "if weights_path.is_file():\n",
    "    print('Using locally stored weights: {}'.format(weights_path))\n",
    "else:\n",
    "    weights_path = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    print('Weights not found, weights will be downloaded from source: {}'.format(weights_path))\n",
    "cfg.MODEL.WEIGHTs = str(weights_path)\n",
    "'''\n",
    "cfg.OUTPUT_DIR = str(Path(f'{EXPERIMENT_NAME}_output_img_transformation'))\n",
    "# make the output directory\n",
    "os.makedirs(Path(cfg.OUTPUT_DIR), exist_ok=True)\n",
    "model_checkpoints = sorted(Path(root, 'models', 'satellite_output_auto_W3.4').glob('*.pth'))  # paths to weights saved druing training\n",
    "#cfg.DATASETS.TEST = (dataset_train, dataset_valid)  # predictor requires this field to not be empty\n",
    "cfg.MODEL.WEIGHTS = str(model_checkpoints[-1])  # use the last model checkpoint saved during training. If you want to see the performance of other checkpoints you can select a different index from model_checkpoints.\n",
    "predictor = DefaultPredictor(cfg)  # create predictor object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing image, converting to polygon, and exporting detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def flip_save_image(name, horizontally, vertically, save=True):\n",
    "    new_name = name\n",
    "    img_path = Path('Auto_annotate_images', image_name +'.png')\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if horizontally:\n",
    "        new_name += 'x'\n",
    "        img = cv2.flip(img, 1)\n",
    "    if vertically:\n",
    "        new_name += 'y'\n",
    "        img = cv2.flip(img, 0)\n",
    "    new_img_path = Path('Auto_annotate_images', new_name +'.png')\n",
    "    if save:\n",
    "        cv2.imwrite(str(new_img_path), img)\n",
    "    return new_name\n",
    "\n",
    "def invert_list(input_list, list_range):\n",
    "    output_list = []\n",
    "    for i in input_list:\n",
    "        output_list.append(i)\n",
    "    for i in range(len(output_list)):\n",
    "        output_list[i] = list_range - output_list[i]\n",
    "    return output_list\n",
    "\n",
    "\n",
    "\n",
    "def invert_shape(input_dict, img_width, img_height, horizontal, vertical):\n",
    "    if horizontal: \n",
    "        input_dict['shape_attributes']['all_points_x'] = invert_list(input_dict['shape_attributes']['all_points_x'], img_width)\n",
    "    if vertical: \n",
    "        input_dict['shape_attributes']['all_points_y'] = invert_list(input_dict['shape_attributes']['all_points_y'], img_height)\n",
    "    return input_dict\n",
    "\n",
    "\n",
    "def invert_x_y_regions(input_list, img_width, img_height, horizontal, vertical):\n",
    "    output_list = []\n",
    "    for i in input_list:\n",
    "        output_list.append(invert_shape(i, img_width, img_height, horizontal, vertical))\n",
    "    return output_list\n",
    "'''\n",
    "###TODO: Finish up this method. The name of the image must be changed, including the additional image size\n",
    "###Then these methods must be created for both horizontal and verticle shifts\n",
    "###Create an automated program to create all of the neccesary images and test http://www.learningaboutelectronics.com/Articles/How-to-flip-an-image-horizontally-vertically-in-Python-OpenCV.php#:~:text=To%20horizontally%20flip%20an%20image,1%20(for%20horizontal%20flipping).\n",
    "###Import new docs into VIA and see how they look\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468823\n",
      "1024 768\n"
     ]
    }
   ],
   "source": [
    "image_name = \"S02_02_SE1_500X19\"\n",
    "img_path = Path('Auto_annotate_images', image_name +'.png')\n",
    "image_size = os.path.getsize(img_path)\n",
    "print(image_size)\n",
    "import PIL\n",
    "image = PIL.Image.open(img_path)\n",
    "width, height = image.size\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"export1 = export_anno.make_VIA_file(image_name +'.png', img_path, outs)\\ninverted_export_XY = export_anno.invert_x_y_via(export1, True, True, 1024, 768)\\nfor i in inverted_export_XY:\\n    title = i.split('.')[0]\\n    export_anno.save_to_json('Auto_annotate_images/annotations/'+title+'_anno.json', inverted_export_XY)\\nouts = predictor(img)\\nexport1 = export_anno.make_VIA_file(image_name +'.png', img_path, outs)\\ninverted_export_X = export_anno.invert_x_y_via(export1, True, False, 1024, 768)\\nfor i in inverted_export_X:\\n    title = i.split('.')[0]\\n    export_anno.save_to_json('Auto_annotate_images/annotations/'+title+'_anno.json', inverted_export_X)\\nouts = predictor(img)\\nexport1 = export_anno.make_VIA_file(image_name +'.png', img_path, outs)\\ninverted_export_Y = export_anno.invert_x_y_via(export1, False, True, 1024, 768)\\nfor i in inverted_export_Y:\\n    title = i.split('.')[0]\\n    export_anno.save_to_json('Auto_annotate_images/annotations/'+title+'_anno.json', inverted_export_Y)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def invert_x_y_via(input_dict, horizontal, vertical, width, height):\n",
    "    inverted_dict = {}\n",
    "    modifier = ''\n",
    "    if horizontal:\n",
    "        modifier += 'x'\n",
    "    if vertical:\n",
    "        modifier += 'y'\n",
    "    print(modifier)\n",
    "    for i in input_dict:\n",
    "        split_name = i.split('.png')\n",
    "        flip_save_image(split_name[0], horizontal, vertical)\n",
    "        size = os.path.getsize('Auto_annotate_images/' + split_name[0] + modifier + '.png')\n",
    "        input_dict[i]['filename'] = split_name[0] + modifier + '.png'\n",
    "        input_dict[i]['size'] = size\n",
    "        input_dict[i]['regions'] = invert_x_y_regions(input_dict[i]['regions'], width, height, horizontal, vertical)\n",
    "        inverted_dict[split_name[0]+modifier+'.png'+str(size)] = input_dict[i]\n",
    "    return inverted_dict\n",
    "'''  \n",
    "    \n",
    "img = cv2.imread(str(img_path))\n",
    "outs = predictor(img)\n",
    "'''export1 = export_anno.make_VIA_file(image_name +'.png', img_path, outs)\n",
    "inverted_export_XY = export_anno.invert_x_y_via(export1, True, True, 1024, 768)\n",
    "for i in inverted_export_XY:\n",
    "    title = i.split('.')[0]\n",
    "    export_anno.save_to_json('Auto_annotate_images/annotations/'+title+'_anno.json', inverted_export_XY)\n",
    "outs = predictor(img)\n",
    "export1 = export_anno.make_VIA_file(image_name +'.png', img_path, outs)\n",
    "inverted_export_X = export_anno.invert_x_y_via(export1, True, False, 1024, 768)\n",
    "for i in inverted_export_X:\n",
    "    title = i.split('.')[0]\n",
    "    export_anno.save_to_json('Auto_annotate_images/annotations/'+title+'_anno.json', inverted_export_X)\n",
    "outs = predictor(img)\n",
    "export1 = export_anno.make_VIA_file(image_name +'.png', img_path, outs)\n",
    "inverted_export_Y = export_anno.invert_x_y_via(export1, False, True, 1024, 768)\n",
    "for i in inverted_export_Y:\n",
    "    title = i.split('.')[0]\n",
    "    export_anno.save_to_json('Auto_annotate_images/annotations/'+title+'_anno.json', inverted_export_Y)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Visualizing detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-309b49ac32dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m visualize.display_ddicts(ddict=outs,  # predictions to display\n\u001b[1;32m      4\u001b[0m                                  \u001b[0moutpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# don't save fi$\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  \u001b[0mgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# specifies format as model predict$\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "outs = predictor(img)\n",
    "data_utils.format_outputs(img_path, dataset='test', pred=outs)\n",
    "visualize.display_ddicts(ddict=outs,  # predictions to display\n",
    "                                 outpath=None, dataset='Test',  # don't save fi$\n",
    "                                 gt=False,  # specifies format as model predict$\n",
    "                                 img_path=img_path, # path to image\n",
    "                                 suppress_labels=True, #hides class images\n",
    "                                 summary=False)  #hides the end print statement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
