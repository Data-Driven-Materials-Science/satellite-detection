Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_4S_500x.png
	num_instances: 103
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_01_SE1_1000X94.png
	num_instances: 68
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_6S_250x.png
	num_instances: 102
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[11/12 18:43:11 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[11/12 18:43:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/12 18:43:12 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[11/12 18:43:12 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]
[32m[11/12 18:43:12 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[11/12 18:43:12 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[11/12 18:43:12 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[11/12 18:43:12 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[11/12 18:43:12 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[11/12 18:43:12 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[11/12 18:43:12 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[11/12 18:43:15 d2.utils.events]: [0m eta: 0:16:56  iter: 19  total_loss: 3.302  loss_cls: 0.5152  loss_box_reg: 0.02805  loss_mask: 0.6728  loss_rpn_cls: 0.6589  loss_rpn_loc: 1.292  time: 0.1031  data_time: 0.0169  lr: 0.00019981  max_mem: 1618M
[32m[11/12 18:43:17 d2.utils.events]: [0m eta: 0:16:54  iter: 39  total_loss: 2.368  loss_cls: 0.3474  loss_box_reg: 0.03981  loss_mask: 0.596  loss_rpn_cls: 0.5985  loss_rpn_loc: 0.7602  time: 0.1052  data_time: 0.0016  lr: 0.00039961  max_mem: 1706M
[32m[11/12 18:43:20 d2.utils.events]: [0m eta: 0:16:54  iter: 59  total_loss: 2.163  loss_cls: 0.2629  loss_box_reg: 0.1031  loss_mask: 0.5856  loss_rpn_cls: 0.583  loss_rpn_loc: 0.6629  time: 0.1041  data_time: 0.0017  lr: 0.00059941  max_mem: 1706M
[32m[11/12 18:43:22 d2.utils.events]: [0m eta: 0:16:52  iter: 79  total_loss: 2.171  loss_cls: 0.2644  loss_box_reg: 0.1726  loss_mask: 0.5625  loss_rpn_cls: 0.5416  loss_rpn_loc: 0.5524  time: 0.1041  data_time: 0.0016  lr: 0.00079921  max_mem: 1781M
[32m[11/12 18:43:24 d2.utils.events]: [0m eta: 0:17:06  iter: 99  total_loss: 2.145  loss_cls: 0.2626  loss_box_reg: 0.3305  loss_mask: 0.54  loss_rpn_cls: 0.4593  loss_rpn_loc: 0.5098  time: 0.1053  data_time: 0.0018  lr: 0.00099901  max_mem: 1781M
[32m[11/12 18:43:26 d2.utils.events]: [0m eta: 0:17:06  iter: 119  total_loss: 2.066  loss_cls: 0.2807  loss_box_reg: 0.4052  loss_mask: 0.5028  loss_rpn_cls: 0.3849  loss_rpn_loc: 0.5254  time: 0.1060  data_time: 0.0017  lr: 0.0011988  max_mem: 1781M
[32m[11/12 18:43:28 d2.utils.events]: [0m eta: 0:17:11  iter: 139  total_loss: 2.094  loss_cls: 0.2758  loss_box_reg: 0.4994  loss_mask: 0.4701  loss_rpn_cls: 0.3429  loss_rpn_loc: 0.4745  time: 0.1064  data_time: 0.0017  lr: 0.0013986  max_mem: 1781M
[32m[11/12 18:43:31 d2.utils.events]: [0m eta: 0:17:12  iter: 159  total_loss: 2  loss_cls: 0.2674  loss_box_reg: 0.4736  loss_mask: 0.4365  loss_rpn_cls: 0.3468  loss_rpn_loc: 0.4799  time: 0.1070  data_time: 0.0017  lr: 0.0015984  max_mem: 1781M
[32m[11/12 18:43:33 d2.utils.events]: [0m eta: 0:17:12  iter: 179  total_loss: 1.878  loss_cls: 0.2428  loss_box_reg: 0.4873  loss_mask: 0.4143  loss_rpn_cls: 0.28  loss_rpn_loc: 0.4527  time: 0.1074  data_time: 0.0018  lr: 0.0017982  max_mem: 1781M
[32m[11/12 18:43:35 d2.utils.events]: [0m eta: 0:17:17  iter: 199  total_loss: 1.85  loss_cls: 0.274  loss_box_reg: 0.4235  loss_mask: 0.3874  loss_rpn_cls: 0.2742  loss_rpn_loc: 0.4506  time: 0.1078  data_time: 0.0017  lr: 0.001998  max_mem: 1781M
[32m[11/12 18:43:37 d2.utils.events]: [0m eta: 0:17:16  iter: 219  total_loss: 1.734  loss_cls: 0.2258  loss_box_reg: 0.3785  loss_mask: 0.3503  loss_rpn_cls: 0.2508  loss_rpn_loc: 0.4744  time: 0.1079  data_time: 0.0017  lr: 0.0021978  max_mem: 1781M
[32m[11/12 18:43:40 d2.utils.events]: [0m eta: 0:17:24  iter: 239  total_loss: 1.752  loss_cls: 0.2422  loss_box_reg: 0.4536  loss_mask: 0.3423  loss_rpn_cls: 0.274  loss_rpn_loc: 0.4461  time: 0.1083  data_time: 0.0017  lr: 0.0023976  max_mem: 1781M
[32m[11/12 18:43:42 d2.utils.events]: [0m eta: 0:17:23  iter: 259  total_loss: 1.856  loss_cls: 0.2737  loss_box_reg: 0.4872  loss_mask: 0.3259  loss_rpn_cls: 0.2302  loss_rpn_loc: 0.4656  time: 0.1086  data_time: 0.0018  lr: 0.0025974  max_mem: 1781M
[32m[11/12 18:43:44 d2.utils.events]: [0m eta: 0:17:25  iter: 279  total_loss: 1.666  loss_cls: 0.2318  loss_box_reg: 0.4753  loss_mask: 0.3186  loss_rpn_cls: 0.2026  loss_rpn_loc: 0.3983  time: 0.1091  data_time: 0.0017  lr: 0.0027972  max_mem: 1831M
[32m[11/12 18:43:47 d2.utils.events]: [0m eta: 0:17:25  iter: 299  total_loss: 1.616  loss_cls: 0.2307  loss_box_reg: 0.489  loss_mask: 0.3076  loss_rpn_cls: 0.2218  loss_rpn_loc: 0.3974  time: 0.1095  data_time: 0.0018  lr: 0.002997  max_mem: 1831M
[32m[11/12 18:43:49 d2.utils.events]: [0m eta: 0:17:25  iter: 319  total_loss: 1.68  loss_cls: 0.2244  loss_box_reg: 0.5194  loss_mask: 0.3215  loss_rpn_cls: 0.2248  loss_rpn_loc: 0.4415  time: 0.1096  data_time: 0.0016  lr: 0.0031968  max_mem: 1831M
[32m[11/12 18:43:51 d2.utils.events]: [0m eta: 0:17:34  iter: 339  total_loss: 1.692  loss_cls: 0.2338  loss_box_reg: 0.4943  loss_mask: 0.2999  loss_rpn_cls: 0.22  loss_rpn_loc: 0.4155  time: 0.1099  data_time: 0.0017  lr: 0.0033966  max_mem: 1831M
[32m[11/12 18:43:53 d2.utils.events]: [0m eta: 0:17:37  iter: 359  total_loss: 1.622  loss_cls: 0.2447  loss_box_reg: 0.4944  loss_mask: 0.2775  loss_rpn_cls: 0.207  loss_rpn_loc: 0.3797  time: 0.1102  data_time: 0.0017  lr: 0.0035964  max_mem: 1831M
[32m[11/12 18:43:56 d2.utils.events]: [0m eta: 0:17:36  iter: 379  total_loss: 1.617  loss_cls: 0.2243  loss_box_reg: 0.4555  loss_mask: 0.2912  loss_rpn_cls: 0.2091  loss_rpn_loc: 0.4341  time: 0.1102  data_time: 0.0019  lr: 0.0037962  max_mem: 1831M
[32m[11/12 18:43:58 d2.utils.events]: [0m eta: 0:17:36  iter: 399  total_loss: 1.58  loss_cls: 0.1973  loss_box_reg: 0.4178  loss_mask: 0.2845  loss_rpn_cls: 0.2039  loss_rpn_loc: 0.4426  time: 0.1103  data_time: 0.0015  lr: 0.003996  max_mem: 1831M
[32m[11/12 18:44:00 d2.utils.events]: [0m eta: 0:17:34  iter: 419  total_loss: 1.535  loss_cls: 0.1849  loss_box_reg: 0.4147  loss_mask: 0.2748  loss_rpn_cls: 0.1589  loss_rpn_loc: 0.4093  time: 0.1103  data_time: 0.0017  lr: 0.0041958  max_mem: 1831M
[32m[11/12 18:44:02 d2.utils.events]: [0m eta: 0:17:31  iter: 439  total_loss: 1.505  loss_cls: 0.186  loss_box_reg: 0.4214  loss_mask: 0.2642  loss_rpn_cls: 0.2029  loss_rpn_loc: 0.4069  time: 0.1103  data_time: 0.0015  lr: 0.0043956  max_mem: 1831M
[32m[11/12 18:44:05 d2.utils.events]: [0m eta: 0:17:30  iter: 459  total_loss: 1.491  loss_cls: 0.2325  loss_box_reg: 0.4678  loss_mask: 0.27  loss_rpn_cls: 0.174  loss_rpn_loc: 0.3866  time: 0.1104  data_time: 0.0017  lr: 0.0045954  max_mem: 1831M
[32m[11/12 18:44:07 d2.utils.events]: [0m eta: 0:17:31  iter: 479  total_loss: 1.553  loss_cls: 0.2068  loss_box_reg: 0.4763  loss_mask: 0.259  loss_rpn_cls: 0.1851  loss_rpn_loc: 0.4015  time: 0.1105  data_time: 0.0018  lr: 0.0047952  max_mem: 1831M
[32m[11/12 18:44:09 d2.utils.events]: [0m eta: 0:17:32  iter: 499  total_loss: 1.537  loss_cls: 0.2273  loss_box_reg: 0.4681  loss_mask: 0.2568  loss_rpn_cls: 0.1766  loss_rpn_loc: 0.367  time: 0.1106  data_time: 0.0015  lr: 0.004995  max_mem: 1831M
[32m[11/12 18:44:12 d2.utils.events]: [0m eta: 0:17:31  iter: 519  total_loss: 1.509  loss_cls: 0.2196  loss_box_reg: 0.481  loss_mask: 0.2532  loss_rpn_cls: 0.1503  loss_rpn_loc: 0.389  time: 0.1107  data_time: 0.0017  lr: 0.0051948  max_mem: 1831M
[32m[11/12 18:44:14 d2.utils.events]: [0m eta: 0:17:30  iter: 539  total_loss: 1.512  loss_cls: 0.2207  loss_box_reg: 0.4874  loss_mask: 0.269  loss_rpn_cls: 0.1578  loss_rpn_loc: 0.3751  time: 0.1108  data_time: 0.0017  lr: 0.0053946  max_mem: 1831M
[32m[11/12 18:44:16 d2.utils.events]: [0m eta: 0:17:31  iter: 559  total_loss: 1.502  loss_cls: 0.2238  loss_box_reg: 0.4877  loss_mask: 0.2523  loss_rpn_cls: 0.1684  loss_rpn_loc: 0.4171  time: 0.1109  data_time: 0.0018  lr: 0.0055944  max_mem: 1831M
[32m[11/12 18:44:19 d2.utils.events]: [0m eta: 0:17:32  iter: 579  total_loss: 1.439  loss_cls: 0.2038  loss_box_reg: 0.4449  loss_mask: 0.265  loss_rpn_cls: 0.1751  loss_rpn_loc: 0.3928  time: 0.1111  data_time: 0.0016  lr: 0.0057942  max_mem: 1831M
[32m[11/12 18:44:21 d2.utils.events]: [0m eta: 0:17:32  iter: 599  total_loss: 1.524  loss_cls: 0.2215  loss_box_reg: 0.4478  loss_mask: 0.256  loss_rpn_cls: 0.2123  loss_rpn_loc: 0.3918  time: 0.1112  data_time: 0.0018  lr: 0.005994  max_mem: 1831M
[32m[11/12 18:44:23 d2.utils.events]: [0m eta: 0:17:30  iter: 619  total_loss: 1.581  loss_cls: 0.2376  loss_box_reg: 0.456  loss_mask: 0.2749  loss_rpn_cls: 0.1788  loss_rpn_loc: 0.395  time: 0.1113  data_time: 0.0017  lr: 0.0061938  max_mem: 1831M
[32m[11/12 18:44:25 d2.utils.events]: [0m eta: 0:17:30  iter: 639  total_loss: 1.49  loss_cls: 0.2058  loss_box_reg: 0.4677  loss_mask: 0.2594  loss_rpn_cls: 0.1699  loss_rpn_loc: 0.3856  time: 0.1114  data_time: 0.0018  lr: 0.0063936  max_mem: 1831M
[32m[11/12 18:44:28 d2.utils.events]: [0m eta: 0:17:28  iter: 659  total_loss: 1.424  loss_cls: 0.197  loss_box_reg: 0.4098  loss_mask: 0.2512  loss_rpn_cls: 0.1858  loss_rpn_loc: 0.373  time: 0.1115  data_time: 0.0017  lr: 0.0065934  max_mem: 1831M
[32m[11/12 18:44:30 d2.utils.events]: [0m eta: 0:17:26  iter: 679  total_loss: 1.404  loss_cls: 0.2073  loss_box_reg: 0.3968  loss_mask: 0.2371  loss_rpn_cls: 0.1794  loss_rpn_loc: 0.3652  time: 0.1115  data_time: 0.0017  lr: 0.0067932  max_mem: 1831M
[32m[11/12 18:44:32 d2.utils.events]: [0m eta: 0:17:25  iter: 699  total_loss: 1.365  loss_cls: 0.1911  loss_box_reg: 0.4199  loss_mask: 0.2354  loss_rpn_cls: 0.1459  loss_rpn_loc: 0.3815  time: 0.1116  data_time: 0.0017  lr: 0.006993  max_mem: 1831M
[32m[11/12 18:44:35 d2.utils.events]: [0m eta: 0:17:22  iter: 719  total_loss: 1.375  loss_cls: 0.2021  loss_box_reg: 0.4364  loss_mask: 0.2274  loss_rpn_cls: 0.1635  loss_rpn_loc: 0.3665  time: 0.1116  data_time: 0.0017  lr: 0.0071928  max_mem: 1831M
[32m[11/12 18:44:37 d2.utils.events]: [0m eta: 0:17:20  iter: 739  total_loss: 1.325  loss_cls: 0.1671  loss_box_reg: 0.413  loss_mask: 0.2235  loss_rpn_cls: 0.1294  loss_rpn_loc: 0.3636  time: 0.1116  data_time: 0.0018  lr: 0.0073926  max_mem: 1831M
[32m[11/12 18:44:39 d2.utils.events]: [0m eta: 0:17:18  iter: 759  total_loss: 1.357  loss_cls: 0.2236  loss_box_reg: 0.4336  loss_mask: 0.2324  loss_rpn_cls: 0.1557  loss_rpn_loc: 0.3387  time: 0.1117  data_time: 0.0017  lr: 0.0075924  max_mem: 1831M
[32m[11/12 18:44:42 d2.utils.events]: [0m eta: 0:17:18  iter: 779  total_loss: 1.375  loss_cls: 0.2072  loss_box_reg: 0.4339  loss_mask: 0.2344  loss_rpn_cls: 0.1349  loss_rpn_loc: 0.3692  time: 0.1118  data_time: 0.0018  lr: 0.0077922  max_mem: 1831M
[32m[11/12 18:44:44 d2.utils.events]: [0m eta: 0:17:14  iter: 799  total_loss: 1.341  loss_cls: 0.1821  loss_box_reg: 0.4216  loss_mask: 0.2198  loss_rpn_cls: 0.1577  loss_rpn_loc: 0.4137  time: 0.1118  data_time: 0.0017  lr: 0.007992  max_mem: 1831M
[32m[11/12 18:44:46 d2.utils.events]: [0m eta: 0:17:12  iter: 819  total_loss: 1.374  loss_cls: 0.1988  loss_box_reg: 0.4162  loss_mask: 0.2392  loss_rpn_cls: 0.159  loss_rpn_loc: 0.414  time: 0.1118  data_time: 0.0018  lr: 0.0081918  max_mem: 1831M
[32m[11/12 18:44:48 d2.utils.events]: [0m eta: 0:17:12  iter: 839  total_loss: 1.425  loss_cls: 0.1812  loss_box_reg: 0.4168  loss_mask: 0.2304  loss_rpn_cls: 0.1991  loss_rpn_loc: 0.3844  time: 0.1119  data_time: 0.0018  lr: 0.0083916  max_mem: 1831M
[32m[11/12 18:44:51 d2.utils.events]: [0m eta: 0:17:10  iter: 859  total_loss: 1.334  loss_cls: 0.1988  loss_box_reg: 0.4398  loss_mask: 0.2184  loss_rpn_cls: 0.1375  loss_rpn_loc: 0.3529  time: 0.1119  data_time: 0.0018  lr: 0.0085914  max_mem: 1831M
[32m[11/12 18:44:53 d2.utils.events]: [0m eta: 0:17:08  iter: 879  total_loss: 1.367  loss_cls: 0.1938  loss_box_reg: 0.444  loss_mask: 0.2152  loss_rpn_cls: 0.1937  loss_rpn_loc: 0.3877  time: 0.1119  data_time: 0.0018  lr: 0.0087912  max_mem: 1831M
[32m[11/12 18:44:55 d2.utils.events]: [0m eta: 0:17:06  iter: 899  total_loss: 1.332  loss_cls: 0.1822  loss_box_reg: 0.4242  loss_mask: 0.2122  loss_rpn_cls: 0.1797  loss_rpn_loc: 0.3662  time: 0.1120  data_time: 0.0016  lr: 0.008991  max_mem: 1831M
[32m[11/12 18:44:58 d2.utils.events]: [0m eta: 0:17:03  iter: 919  total_loss: 1.364  loss_cls: 0.2131  loss_box_reg: 0.4241  loss_mask: 0.2182  loss_rpn_cls: 0.1542  loss_rpn_loc: 0.375  time: 0.1120  data_time: 0.0017  lr: 0.0091908  max_mem: 1831M
[32m[11/12 18:45:00 d2.utils.events]: [0m eta: 0:17:01  iter: 939  total_loss: 1.306  loss_cls: 0.1814  loss_box_reg: 0.4025  loss_mask: 0.2155  loss_rpn_cls: 0.1309  loss_rpn_loc: 0.3571  time: 0.1120  data_time: 0.0017  lr: 0.0093906  max_mem: 1831M
[32m[11/12 18:45:02 d2.utils.events]: [0m eta: 0:17:00  iter: 959  total_loss: 1.318  loss_cls: 0.1896  loss_box_reg: 0.4076  loss_mask: 0.2132  loss_rpn_cls: 0.1322  loss_rpn_loc: 0.3716  time: 0.1121  data_time: 0.0017  lr: 0.0095904  max_mem: 1831M
[32m[11/12 18:45:04 d2.utils.events]: [0m eta: 0:16:57  iter: 979  total_loss: 1.446  loss_cls: 0.2002  loss_box_reg: 0.4169  loss_mask: 0.2134  loss_rpn_cls: 0.1591  loss_rpn_loc: 0.4116  time: 0.1120  data_time: 0.0018  lr: 0.0097902  max_mem: 1831M
[32m[11/12 18:45:07 d2.utils.events]: [0m eta: 0:16:54  iter: 999  total_loss: 1.316  loss_cls: 0.1662  loss_box_reg: 0.3952  loss_mask: 0.2106  loss_rpn_cls: 0.1522  loss_rpn_loc: 0.3912  time: 0.1120  data_time: 0.0017  lr: 0.00999  max_mem: 1831M
[32m[11/12 18:45:09 d2.utils.events]: [0m eta: 0:16:53  iter: 1019  total_loss: 1.317  loss_cls: 0.1784  loss_box_reg: 0.4027  loss_mask: 0.2045  loss_rpn_cls: 0.1388  loss_rpn_loc: 0.3654  time: 0.1120  data_time: 0.0018  lr: 0.01  max_mem: 1831M
[32m[11/12 18:45:11 d2.utils.events]: [0m eta: 0:16:53  iter: 1039  total_loss: 1.287  loss_cls: 0.1963  loss_box_reg: 0.4045  loss_mask: 0.2053  loss_rpn_cls: 0.128  loss_rpn_loc: 0.3382  time: 0.1120  data_time: 0.0018  lr: 0.01  max_mem: 1831M
[32m[11/12 18:45:13 d2.utils.events]: [0m eta: 0:16:53  iter: 1059  total_loss: 1.309  loss_cls: 0.1729  loss_box_reg: 0.4201  loss_mask: 0.2169  loss_rpn_cls: 0.1455  loss_rpn_loc: 0.3407  time: 0.1120  data_time: 0.0017  lr: 0.01  max_mem: 1831M
