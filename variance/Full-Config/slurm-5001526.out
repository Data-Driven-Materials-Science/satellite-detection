[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_4S_500x.png
	num_instances: 103
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_01_SE1_1000X94.png
	num_instances: 68
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_6S_250x.png
	num_instances: 102
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[11/12 00:55:45 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[11/12 00:55:46 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/12 00:55:46 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[11/12 00:55:46 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]
[32m[11/12 00:55:46 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[11/12 00:55:46 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[11/12 00:55:46 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[11/12 00:55:46 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[11/12 00:55:46 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[11/12 00:55:46 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[11/12 00:55:46 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[11/12 00:55:49 d2.utils.events]: [0m eta: 0:24:39  iter: 19  total_loss: 3.303  loss_cls: 0.5159  loss_box_reg: 0.02805  loss_mask: 0.6728  loss_rpn_cls: 0.6589  loss_rpn_loc: 1.292  time: 0.1499  data_time: 0.0156  lr: 0.00019981  max_mem: 1616M
[32m[11/12 00:55:53 d2.utils.events]: [0m eta: 0:24:52  iter: 39  total_loss: 2.365  loss_cls: 0.3489  loss_box_reg: 0.03939  loss_mask: 0.5958  loss_rpn_cls: 0.5985  loss_rpn_loc: 0.7602  time: 0.1514  data_time: 0.0017  lr: 0.00039961  max_mem: 1703M
[32m[11/12 00:55:56 d2.utils.events]: [0m eta: 0:24:47  iter: 59  total_loss: 2.154  loss_cls: 0.272  loss_box_reg: 0.1018  loss_mask: 0.5846  loss_rpn_cls: 0.5829  loss_rpn_loc: 0.6627  time: 0.1510  data_time: 0.0015  lr: 0.00059941  max_mem: 1703M
[32m[11/12 00:55:59 d2.utils.events]: [0m eta: 0:24:49  iter: 79  total_loss: 2.188  loss_cls: 0.2603  loss_box_reg: 0.1953  loss_mask: 0.5596  loss_rpn_cls: 0.542  loss_rpn_loc: 0.5523  time: 0.1517  data_time: 0.0015  lr: 0.00079921  max_mem: 1778M
[32m[11/12 00:56:02 d2.utils.events]: [0m eta: 0:25:02  iter: 99  total_loss: 2.137  loss_cls: 0.2643  loss_box_reg: 0.3243  loss_mask: 0.5354  loss_rpn_cls: 0.4611  loss_rpn_loc: 0.5121  time: 0.1540  data_time: 0.0017  lr: 0.00099901  max_mem: 1778M
[32m[11/12 00:56:05 d2.utils.events]: [0m eta: 0:25:15  iter: 119  total_loss: 2.098  loss_cls: 0.2926  loss_box_reg: 0.3994  loss_mask: 0.5118  loss_rpn_cls: 0.3914  loss_rpn_loc: 0.5198  time: 0.1552  data_time: 0.0017  lr: 0.0011988  max_mem: 1778M
[32m[11/12 00:56:09 d2.utils.events]: [0m eta: 0:25:20  iter: 139  total_loss: 2.093  loss_cls: 0.3053  loss_box_reg: 0.4907  loss_mask: 0.4734  loss_rpn_cls: 0.3495  loss_rpn_loc: 0.4582  time: 0.1563  data_time: 0.0017  lr: 0.0013986  max_mem: 1778M
[32m[11/12 00:56:12 d2.utils.events]: [0m eta: 0:25:24  iter: 159  total_loss: 1.964  loss_cls: 0.2562  loss_box_reg: 0.4437  loss_mask: 0.4382  loss_rpn_cls: 0.3443  loss_rpn_loc: 0.474  time: 0.1574  data_time: 0.0016  lr: 0.0015984  max_mem: 1778M
[32m[11/12 00:56:15 d2.utils.events]: [0m eta: 0:25:26  iter: 179  total_loss: 1.822  loss_cls: 0.2568  loss_box_reg: 0.426  loss_mask: 0.4081  loss_rpn_cls: 0.2916  loss_rpn_loc: 0.4511  time: 0.1580  data_time: 0.0016  lr: 0.0017982  max_mem: 1778M
[32m[11/12 00:56:19 d2.utils.events]: [0m eta: 0:25:32  iter: 199  total_loss: 1.722  loss_cls: 0.225  loss_box_reg: 0.3922  loss_mask: 0.3715  loss_rpn_cls: 0.2695  loss_rpn_loc: 0.4529  time: 0.1586  data_time: 0.0016  lr: 0.001998  max_mem: 1778M
[32m[11/12 00:56:22 d2.utils.events]: [0m eta: 0:25:33  iter: 219  total_loss: 1.636  loss_cls: 0.1866  loss_box_reg: 0.3123  loss_mask: 0.3725  loss_rpn_cls: 0.2539  loss_rpn_loc: 0.4744  time: 0.1588  data_time: 0.0016  lr: 0.0021978  max_mem: 1778M
[32m[11/12 00:56:25 d2.utils.events]: [0m eta: 0:25:36  iter: 239  total_loss: 1.79  loss_cls: 0.2803  loss_box_reg: 0.433  loss_mask: 0.3622  loss_rpn_cls: 0.2729  loss_rpn_loc: 0.4305  time: 0.1595  data_time: 0.0016  lr: 0.0023976  max_mem: 1778M
[32m[11/12 00:56:29 d2.utils.events]: [0m eta: 0:25:37  iter: 259  total_loss: 1.765  loss_cls: 0.2586  loss_box_reg: 0.4887  loss_mask: 0.3271  loss_rpn_cls: 0.2199  loss_rpn_loc: 0.4064  time: 0.1604  data_time: 0.0017  lr: 0.0025974  max_mem: 1778M
[32m[11/12 00:56:32 d2.utils.events]: [0m eta: 0:25:41  iter: 279  total_loss: 1.632  loss_cls: 0.2318  loss_box_reg: 0.4984  loss_mask: 0.311  loss_rpn_cls: 0.2272  loss_rpn_loc: 0.4167  time: 0.1613  data_time: 0.0018  lr: 0.0027972  max_mem: 1827M
[32m[11/12 00:56:36 d2.utils.events]: [0m eta: 0:25:51  iter: 299  total_loss: 1.637  loss_cls: 0.2361  loss_box_reg: 0.4868  loss_mask: 0.3057  loss_rpn_cls: 0.2182  loss_rpn_loc: 0.3864  time: 0.1620  data_time: 0.0018  lr: 0.002997  max_mem: 1827M
[32m[11/12 00:56:39 d2.utils.events]: [0m eta: 0:25:50  iter: 319  total_loss: 1.624  loss_cls: 0.2468  loss_box_reg: 0.4782  loss_mask: 0.3116  loss_rpn_cls: 0.2052  loss_rpn_loc: 0.3997  time: 0.1622  data_time: 0.0016  lr: 0.0031968  max_mem: 1827M
[32m[11/12 00:56:42 d2.utils.events]: [0m eta: 0:25:55  iter: 339  total_loss: 1.687  loss_cls: 0.2387  loss_box_reg: 0.4963  loss_mask: 0.3184  loss_rpn_cls: 0.2271  loss_rpn_loc: 0.3982  time: 0.1628  data_time: 0.0018  lr: 0.0033966  max_mem: 1827M
[32m[11/12 00:56:46 d2.utils.events]: [0m eta: 0:26:00  iter: 359  total_loss: 1.543  loss_cls: 0.1924  loss_box_reg: 0.4245  loss_mask: 0.2876  loss_rpn_cls: 0.1844  loss_rpn_loc: 0.3848  time: 0.1631  data_time: 0.0016  lr: 0.0035964  max_mem: 1827M
[32m[11/12 00:56:49 d2.utils.events]: [0m eta: 0:25:56  iter: 379  total_loss: 1.586  loss_cls: 0.2065  loss_box_reg: 0.4243  loss_mask: 0.2861  loss_rpn_cls: 0.2448  loss_rpn_loc: 0.4061  time: 0.1633  data_time: 0.0018  lr: 0.0037962  max_mem: 1827M
[32m[11/12 00:56:52 d2.utils.events]: [0m eta: 0:25:56  iter: 399  total_loss: 1.617  loss_cls: 0.2444  loss_box_reg: 0.4841  loss_mask: 0.2821  loss_rpn_cls: 0.2087  loss_rpn_loc: 0.3909  time: 0.1636  data_time: 0.0017  lr: 0.003996  max_mem: 1827M
[32m[11/12 00:56:56 d2.utils.events]: [0m eta: 0:26:06  iter: 419  total_loss: 1.635  loss_cls: 0.254  loss_box_reg: 0.5053  loss_mask: 0.2807  loss_rpn_cls: 0.2007  loss_rpn_loc: 0.4029  time: 0.1639  data_time: 0.0017  lr: 0.0041958  max_mem: 1827M
[32m[11/12 00:56:59 d2.utils.events]: [0m eta: 0:26:06  iter: 439  total_loss: 1.494  loss_cls: 0.2066  loss_box_reg: 0.4356  loss_mask: 0.2656  loss_rpn_cls: 0.1967  loss_rpn_loc: 0.3783  time: 0.1641  data_time: 0.0015  lr: 0.0043956  max_mem: 1827M
[32m[11/12 00:57:03 d2.utils.events]: [0m eta: 0:26:05  iter: 459  total_loss: 1.454  loss_cls: 0.1966  loss_box_reg: 0.4591  loss_mask: 0.269  loss_rpn_cls: 0.1683  loss_rpn_loc: 0.3821  time: 0.1642  data_time: 0.0017  lr: 0.0045954  max_mem: 1827M
[32m[11/12 00:57:06 d2.utils.events]: [0m eta: 0:26:02  iter: 479  total_loss: 1.533  loss_cls: 0.2089  loss_box_reg: 0.4568  loss_mask: 0.2504  loss_rpn_cls: 0.2115  loss_rpn_loc: 0.3854  time: 0.1643  data_time: 0.0016  lr: 0.0047952  max_mem: 1827M
[32m[11/12 00:57:10 d2.utils.events]: [0m eta: 0:26:05  iter: 499  total_loss: 1.584  loss_cls: 0.2339  loss_box_reg: 0.4595  loss_mask: 0.2715  loss_rpn_cls: 0.2037  loss_rpn_loc: 0.4063  time: 0.1645  data_time: 0.0016  lr: 0.004995  max_mem: 1827M
[32m[11/12 00:57:13 d2.utils.events]: [0m eta: 0:26:02  iter: 519  total_loss: 1.564  loss_cls: 0.2177  loss_box_reg: 0.4737  loss_mask: 0.2566  loss_rpn_cls: 0.178  loss_rpn_loc: 0.4192  time: 0.1646  data_time: 0.0016  lr: 0.0051948  max_mem: 1827M
[32m[11/12 00:57:16 d2.utils.events]: [0m eta: 0:26:11  iter: 539  total_loss: 1.497  loss_cls: 0.237  loss_box_reg: 0.4803  loss_mask: 0.2519  loss_rpn_cls: 0.1625  loss_rpn_loc: 0.3697  time: 0.1648  data_time: 0.0016  lr: 0.0053946  max_mem: 1827M
[32m[11/12 00:57:20 d2.utils.events]: [0m eta: 0:26:15  iter: 559  total_loss: 1.494  loss_cls: 0.2073  loss_box_reg: 0.5003  loss_mask: 0.2456  loss_rpn_cls: 0.144  loss_rpn_loc: 0.369  time: 0.1650  data_time: 0.0017  lr: 0.0055944  max_mem: 1827M
[32m[11/12 00:57:23 d2.utils.events]: [0m eta: 0:26:18  iter: 579  total_loss: 1.416  loss_cls: 0.2006  loss_box_reg: 0.4535  loss_mask: 0.247  loss_rpn_cls: 0.1611  loss_rpn_loc: 0.3621  time: 0.1653  data_time: 0.0017  lr: 0.0057942  max_mem: 1827M
[32m[11/12 00:57:27 d2.utils.events]: [0m eta: 0:26:19  iter: 599  total_loss: 1.547  loss_cls: 0.219  loss_box_reg: 0.4567  loss_mask: 0.2445  loss_rpn_cls: 0.1754  loss_rpn_loc: 0.4044  time: 0.1655  data_time: 0.0019  lr: 0.005994  max_mem: 1827M
[32m[11/12 00:57:30 d2.utils.events]: [0m eta: 0:26:17  iter: 619  total_loss: 1.403  loss_cls: 0.2128  loss_box_reg: 0.4587  loss_mask: 0.2691  loss_rpn_cls: 0.1551  loss_rpn_loc: 0.3826  time: 0.1655  data_time: 0.0016  lr: 0.0061938  max_mem: 1827M
[32m[11/12 00:57:34 d2.utils.events]: [0m eta: 0:26:17  iter: 639  total_loss: 1.453  loss_cls: 0.2123  loss_box_reg: 0.4432  loss_mask: 0.2455  loss_rpn_cls: 0.1932  loss_rpn_loc: 0.3507  time: 0.1658  data_time: 0.0017  lr: 0.0063936  max_mem: 1827M
[32m[11/12 00:57:37 d2.utils.events]: [0m eta: 0:26:15  iter: 659  total_loss: 1.406  loss_cls: 0.2063  loss_box_reg: 0.4382  loss_mask: 0.2478  loss_rpn_cls: 0.1887  loss_rpn_loc: 0.4002  time: 0.1659  data_time: 0.0016  lr: 0.0065934  max_mem: 1827M
[32m[11/12 00:57:40 d2.utils.events]: [0m eta: 0:26:14  iter: 679  total_loss: 1.414  loss_cls: 0.1913  loss_box_reg: 0.4225  loss_mask: 0.2306  loss_rpn_cls: 0.1597  loss_rpn_loc: 0.3746  time: 0.1659  data_time: 0.0017  lr: 0.0067932  max_mem: 1827M
[32m[11/12 00:57:44 d2.utils.events]: [0m eta: 0:26:12  iter: 699  total_loss: 1.399  loss_cls: 0.1716  loss_box_reg: 0.3943  loss_mask: 0.2393  loss_rpn_cls: 0.1544  loss_rpn_loc: 0.3959  time: 0.1659  data_time: 0.0017  lr: 0.006993  max_mem: 1827M
[32m[11/12 00:57:47 d2.utils.events]: [0m eta: 0:26:05  iter: 719  total_loss: 1.485  loss_cls: 0.1802  loss_box_reg: 0.4099  loss_mask: 0.2338  loss_rpn_cls: 0.1713  loss_rpn_loc: 0.4347  time: 0.1659  data_time: 0.0017  lr: 0.0071928  max_mem: 1827M
[32m[11/12 00:57:50 d2.utils.events]: [0m eta: 0:26:02  iter: 739  total_loss: 1.358  loss_cls: 0.1738  loss_box_reg: 0.4097  loss_mask: 0.229  loss_rpn_cls: 0.1544  loss_rpn_loc: 0.4026  time: 0.1659  data_time: 0.0017  lr: 0.0073926  max_mem: 1827M
[32m[11/12 00:57:54 d2.utils.events]: [0m eta: 0:26:00  iter: 759  total_loss: 1.388  loss_cls: 0.1941  loss_box_reg: 0.4457  loss_mask: 0.2223  loss_rpn_cls: 0.1668  loss_rpn_loc: 0.3585  time: 0.1661  data_time: 0.0016  lr: 0.0075924  max_mem: 1827M
[32m[11/12 00:57:57 d2.utils.events]: [0m eta: 0:25:59  iter: 779  total_loss: 1.386  loss_cls: 0.2109  loss_box_reg: 0.4587  loss_mask: 0.2238  loss_rpn_cls: 0.1214  loss_rpn_loc: 0.3708  time: 0.1662  data_time: 0.0017  lr: 0.0077922  max_mem: 1827M
[32m[11/12 00:58:01 d2.utils.events]: [0m eta: 0:25:53  iter: 799  total_loss: 1.329  loss_cls: 0.1701  loss_box_reg: 0.4078  loss_mask: 0.2226  loss_rpn_cls: 0.1443  loss_rpn_loc: 0.3583  time: 0.1662  data_time: 0.0017  lr: 0.007992  max_mem: 1827M
[32m[11/12 00:58:04 d2.utils.events]: [0m eta: 0:25:51  iter: 819  total_loss: 1.319  loss_cls: 0.196  loss_box_reg: 0.4317  loss_mask: 0.2169  loss_rpn_cls: 0.1547  loss_rpn_loc: 0.3762  time: 0.1662  data_time: 0.0017  lr: 0.0081918  max_mem: 1827M
[32m[11/12 00:58:07 d2.utils.events]: [0m eta: 0:25:50  iter: 839  total_loss: 1.357  loss_cls: 0.2055  loss_box_reg: 0.4283  loss_mask: 0.2177  loss_rpn_cls: 0.1377  loss_rpn_loc: 0.348  time: 0.1663  data_time: 0.0017  lr: 0.0083916  max_mem: 1827M
[32m[11/12 00:58:11 d2.utils.events]: [0m eta: 0:25:48  iter: 859  total_loss: 1.357  loss_cls: 0.195  loss_box_reg: 0.4376  loss_mask: 0.2074  loss_rpn_cls: 0.1602  loss_rpn_loc: 0.3473  time: 0.1664  data_time: 0.0017  lr: 0.0085914  max_mem: 1827M
[32m[11/12 00:58:14 d2.utils.events]: [0m eta: 0:25:45  iter: 879  total_loss: 1.32  loss_cls: 0.1555  loss_box_reg: 0.4007  loss_mask: 0.2172  loss_rpn_cls: 0.1675  loss_rpn_loc: 0.3783  time: 0.1664  data_time: 0.0017  lr: 0.0087912  max_mem: 1827M
[32m[11/12 00:58:18 d2.utils.events]: [0m eta: 0:25:42  iter: 899  total_loss: 1.307  loss_cls: 0.1813  loss_box_reg: 0.4244  loss_mask: 0.2102  loss_rpn_cls: 0.1552  loss_rpn_loc: 0.3462  time: 0.1665  data_time: 0.0016  lr: 0.008991  max_mem: 1827M
[32m[11/12 00:58:21 d2.utils.events]: [0m eta: 0:25:39  iter: 919  total_loss: 1.383  loss_cls: 0.2085  loss_box_reg: 0.4236  loss_mask: 0.2082  loss_rpn_cls: 0.1528  loss_rpn_loc: 0.3744  time: 0.1665  data_time: 0.0018  lr: 0.0091908  max_mem: 1827M
[32m[11/12 00:58:24 d2.utils.events]: [0m eta: 0:25:36  iter: 939  total_loss: 1.298  loss_cls: 0.1854  loss_box_reg: 0.417  loss_mask: 0.2096  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.3427  time: 0.1665  data_time: 0.0017  lr: 0.0093906  max_mem: 1827M
[32m[11/12 00:58:28 d2.utils.events]: [0m eta: 0:25:34  iter: 959  total_loss: 1.289  loss_cls: 0.1741  loss_box_reg: 0.3932  loss_mask: 0.2184  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.3418  time: 0.1667  data_time: 0.0018  lr: 0.0095904  max_mem: 1827M
[32m[11/12 00:58:31 d2.utils.events]: [0m eta: 0:25:29  iter: 979  total_loss: 1.384  loss_cls: 0.1857  loss_box_reg: 0.434  loss_mask: 0.2156  loss_rpn_cls: 0.1433  loss_rpn_loc: 0.3872  time: 0.1667  data_time: 0.0018  lr: 0.0097902  max_mem: 1827M
[32m[11/12 00:58:35 d2.utils.events]: [0m eta: 0:25:25  iter: 999  total_loss: 1.317  loss_cls: 0.1531  loss_box_reg: 0.4029  loss_mask: 0.2136  loss_rpn_cls: 0.1545  loss_rpn_loc: 0.3931  time: 0.1666  data_time: 0.0018  lr: 0.00999  max_mem: 1827M
[32m[11/12 00:58:38 d2.utils.events]: [0m eta: 0:25:24  iter: 1019  total_loss: 1.316  loss_cls: 0.1823  loss_box_reg: 0.38  loss_mask: 0.2074  loss_rpn_cls: 0.1604  loss_rpn_loc: 0.3676  time: 0.1666  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:58:42 d2.utils.events]: [0m eta: 0:25:23  iter: 1039  total_loss: 1.327  loss_cls: 0.1801  loss_box_reg: 0.3908  loss_mask: 0.2146  loss_rpn_cls: 0.1372  loss_rpn_loc: 0.36  time: 0.1667  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 00:58:45 d2.utils.events]: [0m eta: 0:25:22  iter: 1059  total_loss: 1.322  loss_cls: 0.1894  loss_box_reg: 0.4137  loss_mask: 0.2071  loss_rpn_cls: 0.142  loss_rpn_loc: 0.3617  time: 0.1667  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:58:48 d2.utils.events]: [0m eta: 0:25:20  iter: 1079  total_loss: 1.296  loss_cls: 0.1914  loss_box_reg: 0.43  loss_mask: 0.2018  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.3523  time: 0.1668  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 00:58:52 d2.utils.events]: [0m eta: 0:25:18  iter: 1099  total_loss: 1.294  loss_cls: 0.1952  loss_box_reg: 0.3827  loss_mask: 0.2099  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.3764  time: 0.1668  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 00:58:55 d2.utils.events]: [0m eta: 0:25:15  iter: 1119  total_loss: 1.335  loss_cls: 0.1806  loss_box_reg: 0.4017  loss_mask: 0.2157  loss_rpn_cls: 0.1464  loss_rpn_loc: 0.3599  time: 0.1669  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 00:58:59 d2.utils.events]: [0m eta: 0:25:12  iter: 1139  total_loss: 1.253  loss_cls: 0.1896  loss_box_reg: 0.4074  loss_mask: 0.199  loss_rpn_cls: 0.1607  loss_rpn_loc: 0.3348  time: 0.1669  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:02 d2.utils.events]: [0m eta: 0:25:10  iter: 1159  total_loss: 1.281  loss_cls: 0.1629  loss_box_reg: 0.3969  loss_mask: 0.2023  loss_rpn_cls: 0.1425  loss_rpn_loc: 0.348  time: 0.1670  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:06 d2.utils.events]: [0m eta: 0:25:09  iter: 1179  total_loss: 1.158  loss_cls: 0.1772  loss_box_reg: 0.3732  loss_mask: 0.1854  loss_rpn_cls: 0.09993  loss_rpn_loc: 0.3279  time: 0.1671  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:09 d2.utils.events]: [0m eta: 0:25:07  iter: 1199  total_loss: 1.25  loss_cls: 0.1618  loss_box_reg: 0.3769  loss_mask: 0.1999  loss_rpn_cls: 0.1388  loss_rpn_loc: 0.3478  time: 0.1672  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:12 d2.utils.events]: [0m eta: 0:25:04  iter: 1219  total_loss: 1.247  loss_cls: 0.1665  loss_box_reg: 0.4143  loss_mask: 0.1903  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.3579  time: 0.1671  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:16 d2.utils.events]: [0m eta: 0:25:00  iter: 1239  total_loss: 1.185  loss_cls: 0.1715  loss_box_reg: 0.3852  loss_mask: 0.1848  loss_rpn_cls: 0.1263  loss_rpn_loc: 0.3142  time: 0.1672  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:19 d2.utils.events]: [0m eta: 0:24:57  iter: 1259  total_loss: 1.19  loss_cls: 0.191  loss_box_reg: 0.374  loss_mask: 0.1876  loss_rpn_cls: 0.119  loss_rpn_loc: 0.3376  time: 0.1672  data_time: 0.0016  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:23 d2.utils.events]: [0m eta: 0:24:54  iter: 1279  total_loss: 1.249  loss_cls: 0.1784  loss_box_reg: 0.3881  loss_mask: 0.2057  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.3175  time: 0.1673  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:26 d2.utils.events]: [0m eta: 0:24:50  iter: 1299  total_loss: 1.272  loss_cls: 0.1853  loss_box_reg: 0.3981  loss_mask: 0.1969  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.3424  time: 0.1673  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:30 d2.utils.events]: [0m eta: 0:24:47  iter: 1319  total_loss: 1.165  loss_cls: 0.179  loss_box_reg: 0.3802  loss_mask: 0.1867  loss_rpn_cls: 0.09427  loss_rpn_loc: 0.3244  time: 0.1674  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:33 d2.utils.events]: [0m eta: 0:24:44  iter: 1339  total_loss: 1.206  loss_cls: 0.1673  loss_box_reg: 0.3699  loss_mask: 0.1888  loss_rpn_cls: 0.1184  loss_rpn_loc: 0.3313  time: 0.1674  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:36 d2.utils.events]: [0m eta: 0:24:40  iter: 1359  total_loss: 1.173  loss_cls: 0.1646  loss_box_reg: 0.3753  loss_mask: 0.1858  loss_rpn_cls: 0.1272  loss_rpn_loc: 0.3127  time: 0.1674  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:40 d2.utils.events]: [0m eta: 0:24:37  iter: 1379  total_loss: 1.18  loss_cls: 0.167  loss_box_reg: 0.3905  loss_mask: 0.1753  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.3036  time: 0.1674  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:43 d2.utils.events]: [0m eta: 0:24:33  iter: 1399  total_loss: 1.132  loss_cls: 0.1664  loss_box_reg: 0.3858  loss_mask: 0.1735  loss_rpn_cls: 0.08311  loss_rpn_loc: 0.3194  time: 0.1674  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:47 d2.utils.events]: [0m eta: 0:24:29  iter: 1419  total_loss: 1.217  loss_cls: 0.1642  loss_box_reg: 0.3839  loss_mask: 0.1866  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.3291  time: 0.1674  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:50 d2.utils.events]: [0m eta: 0:24:26  iter: 1439  total_loss: 1.148  loss_cls: 0.1628  loss_box_reg: 0.3742  loss_mask: 0.1944  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2936  time: 0.1674  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:53 d2.utils.events]: [0m eta: 0:24:23  iter: 1459  total_loss: 1.107  loss_cls: 0.1497  loss_box_reg: 0.3565  loss_mask: 0.1886  loss_rpn_cls: 0.08939  loss_rpn_loc: 0.3092  time: 0.1675  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 00:59:57 d2.utils.events]: [0m eta: 0:24:20  iter: 1479  total_loss: 1.159  loss_cls: 0.1651  loss_box_reg: 0.375  loss_mask: 0.1836  loss_rpn_cls: 0.09895  loss_rpn_loc: 0.3015  time: 0.1675  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:00 d2.utils.events]: [0m eta: 0:24:16  iter: 1499  total_loss: 1.098  loss_cls: 0.1599  loss_box_reg: 0.3701  loss_mask: 0.1891  loss_rpn_cls: 0.07572  loss_rpn_loc: 0.3173  time: 0.1675  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:03 d2.utils.events]: [0m eta: 0:24:13  iter: 1519  total_loss: 1.065  loss_cls: 0.1384  loss_box_reg: 0.3454  loss_mask: 0.1841  loss_rpn_cls: 0.09645  loss_rpn_loc: 0.3125  time: 0.1675  data_time: 0.0016  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:07 d2.utils.events]: [0m eta: 0:24:09  iter: 1539  total_loss: 1.058  loss_cls: 0.1589  loss_box_reg: 0.3565  loss_mask: 0.1836  loss_rpn_cls: 0.08829  loss_rpn_loc: 0.2846  time: 0.1675  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:10 d2.utils.events]: [0m eta: 0:24:06  iter: 1559  total_loss: 1.161  loss_cls: 0.1588  loss_box_reg: 0.3596  loss_mask: 0.1819  loss_rpn_cls: 0.1213  loss_rpn_loc: 0.3057  time: 0.1675  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:14 d2.utils.events]: [0m eta: 0:24:02  iter: 1579  total_loss: 1.092  loss_cls: 0.1736  loss_box_reg: 0.3575  loss_mask: 0.1759  loss_rpn_cls: 0.07365  loss_rpn_loc: 0.299  time: 0.1676  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:17 d2.utils.events]: [0m eta: 0:23:58  iter: 1599  total_loss: 1.125  loss_cls: 0.1622  loss_box_reg: 0.3603  loss_mask: 0.1728  loss_rpn_cls: 0.08417  loss_rpn_loc: 0.3093  time: 0.1676  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:21 d2.utils.events]: [0m eta: 0:23:55  iter: 1619  total_loss: 1.08  loss_cls: 0.1437  loss_box_reg: 0.3633  loss_mask: 0.1868  loss_rpn_cls: 0.07938  loss_rpn_loc: 0.3208  time: 0.1677  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:24 d2.utils.events]: [0m eta: 0:23:50  iter: 1639  total_loss: 1.118  loss_cls: 0.1677  loss_box_reg: 0.3496  loss_mask: 0.1695  loss_rpn_cls: 0.06594  loss_rpn_loc: 0.3328  time: 0.1677  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:28 d2.utils.events]: [0m eta: 0:23:47  iter: 1659  total_loss: 1.046  loss_cls: 0.1675  loss_box_reg: 0.3609  loss_mask: 0.1764  loss_rpn_cls: 0.08543  loss_rpn_loc: 0.2797  time: 0.1678  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:31 d2.utils.events]: [0m eta: 0:23:43  iter: 1679  total_loss: 1.06  loss_cls: 0.1627  loss_box_reg: 0.3542  loss_mask: 0.178  loss_rpn_cls: 0.09543  loss_rpn_loc: 0.2765  time: 0.1678  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:34 d2.utils.events]: [0m eta: 0:23:39  iter: 1699  total_loss: 1.097  loss_cls: 0.1499  loss_box_reg: 0.3624  loss_mask: 0.1655  loss_rpn_cls: 0.07853  loss_rpn_loc: 0.2814  time: 0.1678  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:38 d2.utils.events]: [0m eta: 0:23:37  iter: 1719  total_loss: 1.021  loss_cls: 0.1382  loss_box_reg: 0.3279  loss_mask: 0.1697  loss_rpn_cls: 0.09074  loss_rpn_loc: 0.2915  time: 0.1678  data_time: 0.0016  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:41 d2.utils.events]: [0m eta: 0:23:34  iter: 1739  total_loss: 1.05  loss_cls: 0.1419  loss_box_reg: 0.3326  loss_mask: 0.1691  loss_rpn_cls: 0.07189  loss_rpn_loc: 0.2687  time: 0.1679  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:45 d2.utils.events]: [0m eta: 0:23:31  iter: 1759  total_loss: 0.9856  loss_cls: 0.1413  loss_box_reg: 0.3185  loss_mask: 0.1614  loss_rpn_cls: 0.08688  loss_rpn_loc: 0.2928  time: 0.1679  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:48 d2.utils.events]: [0m eta: 0:23:28  iter: 1779  total_loss: 1.012  loss_cls: 0.1339  loss_box_reg: 0.3097  loss_mask: 0.1697  loss_rpn_cls: 0.0965  loss_rpn_loc: 0.3015  time: 0.1680  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:52 d2.utils.events]: [0m eta: 0:23:25  iter: 1799  total_loss: 0.9616  loss_cls: 0.1369  loss_box_reg: 0.33  loss_mask: 0.1713  loss_rpn_cls: 0.07891  loss_rpn_loc: 0.2873  time: 0.1680  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:55 d2.utils.events]: [0m eta: 0:23:21  iter: 1819  total_loss: 0.9927  loss_cls: 0.1346  loss_box_reg: 0.3176  loss_mask: 0.1729  loss_rpn_cls: 0.07054  loss_rpn_loc: 0.2754  time: 0.1680  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:00:58 d2.utils.events]: [0m eta: 0:23:18  iter: 1839  total_loss: 1.004  loss_cls: 0.1413  loss_box_reg: 0.3378  loss_mask: 0.1681  loss_rpn_cls: 0.08022  loss_rpn_loc: 0.2846  time: 0.1680  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:02 d2.utils.events]: [0m eta: 0:23:14  iter: 1859  total_loss: 0.9932  loss_cls: 0.1316  loss_box_reg: 0.3316  loss_mask: 0.1682  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.2606  time: 0.1680  data_time: 0.0016  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:05 d2.utils.events]: [0m eta: 0:23:11  iter: 1879  total_loss: 1.004  loss_cls: 0.1313  loss_box_reg: 0.3371  loss_mask: 0.1634  loss_rpn_cls: 0.09924  loss_rpn_loc: 0.2632  time: 0.1680  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:09 d2.utils.events]: [0m eta: 0:23:07  iter: 1899  total_loss: 1.071  loss_cls: 0.1582  loss_box_reg: 0.345  loss_mask: 0.1637  loss_rpn_cls: 0.09748  loss_rpn_loc: 0.2656  time: 0.1680  data_time: 0.0019  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:12 d2.utils.events]: [0m eta: 0:23:04  iter: 1919  total_loss: 0.9676  loss_cls: 0.1428  loss_box_reg: 0.3389  loss_mask: 0.1589  loss_rpn_cls: 0.05634  loss_rpn_loc: 0.2539  time: 0.1680  data_time: 0.0016  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:15 d2.utils.events]: [0m eta: 0:23:00  iter: 1939  total_loss: 0.9197  loss_cls: 0.1311  loss_box_reg: 0.3304  loss_mask: 0.1548  loss_rpn_cls: 0.0836  loss_rpn_loc: 0.2643  time: 0.1681  data_time: 0.0016  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:19 d2.utils.events]: [0m eta: 0:22:56  iter: 1959  total_loss: 1.021  loss_cls: 0.1466  loss_box_reg: 0.3318  loss_mask: 0.1725  loss_rpn_cls: 0.08734  loss_rpn_loc: 0.2714  time: 0.1681  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:22 d2.utils.events]: [0m eta: 0:22:54  iter: 1979  total_loss: 0.9876  loss_cls: 0.1437  loss_box_reg: 0.3351  loss_mask: 0.166  loss_rpn_cls: 0.06108  loss_rpn_loc: 0.2653  time: 0.1681  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:26 d2.utils.events]: [0m eta: 0:22:51  iter: 1999  total_loss: 0.9709  loss_cls: 0.1419  loss_box_reg: 0.3339  loss_mask: 0.1615  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.2827  time: 0.1682  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:29 d2.utils.events]: [0m eta: 0:22:48  iter: 2019  total_loss: 0.9518  loss_cls: 0.1209  loss_box_reg: 0.327  loss_mask: 0.166  loss_rpn_cls: 0.06511  loss_rpn_loc: 0.2549  time: 0.1682  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:33 d2.utils.events]: [0m eta: 0:22:44  iter: 2039  total_loss: 1.011  loss_cls: 0.1381  loss_box_reg: 0.3174  loss_mask: 0.1596  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.2602  time: 0.1682  data_time: 0.0015  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:36 d2.utils.events]: [0m eta: 0:22:41  iter: 2059  total_loss: 0.973  loss_cls: 0.1382  loss_box_reg: 0.3284  loss_mask: 0.1565  loss_rpn_cls: 0.05971  loss_rpn_loc: 0.2612  time: 0.1682  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:40 d2.utils.events]: [0m eta: 0:22:38  iter: 2079  total_loss: 0.9836  loss_cls: 0.1339  loss_box_reg: 0.3316  loss_mask: 0.1629  loss_rpn_cls: 0.07481  loss_rpn_loc: 0.2681  time: 0.1683  data_time: 0.0018  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:43 d2.utils.events]: [0m eta: 0:22:34  iter: 2099  total_loss: 0.9665  loss_cls: 0.1383  loss_box_reg: 0.3204  loss_mask: 0.1604  loss_rpn_cls: 0.09586  loss_rpn_loc: 0.255  time: 0.1683  data_time: 0.0016  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:46 d2.utils.events]: [0m eta: 0:22:30  iter: 2119  total_loss: 0.9141  loss_cls: 0.1285  loss_box_reg: 0.3156  loss_mask: 0.1467  loss_rpn_cls: 0.08587  loss_rpn_loc: 0.2554  time: 0.1682  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:50 d2.utils.events]: [0m eta: 0:22:27  iter: 2139  total_loss: 0.986  loss_cls: 0.1365  loss_box_reg: 0.3286  loss_mask: 0.1665  loss_rpn_cls: 0.08394  loss_rpn_loc: 0.2664  time: 0.1683  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:53 d2.utils.events]: [0m eta: 0:22:24  iter: 2159  total_loss: 0.9127  loss_cls: 0.1105  loss_box_reg: 0.2865  loss_mask: 0.1619  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.2621  time: 0.1683  data_time: 0.0016  lr: 0.01  max_mem: 1827M
[32m[11/12 01:01:57 d2.utils.events]: [0m eta: 0:22:20  iter: 2179  total_loss: 0.8564  loss_cls: 0.1197  loss_box_reg: 0.308  loss_mask: 0.1476  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.253  time: 0.1684  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:02:00 d2.utils.events]: [0m eta: 0:22:16  iter: 2199  total_loss: 0.9553  loss_cls: 0.1176  loss_box_reg: 0.3184  loss_mask: 0.152  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.2765  time: 0.1683  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:02:03 d2.utils.events]: [0m eta: 0:22:13  iter: 2219  total_loss: 0.9491  loss_cls: 0.1199  loss_box_reg: 0.307  loss_mask: 0.1619  loss_rpn_cls: 0.07134  loss_rpn_loc: 0.2792  time: 0.1683  data_time: 0.0017  lr: 0.01  max_mem: 1827M
[32m[11/12 01:02:07 d2.utils.events]: [0m eta: 0:22:10  iter: 2239  total_loss: 0.9498  loss_cls: 0.1211  loss_box_reg: 0.297  loss_mask: 0.1507  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.2688  time: 0.1683  data_time: 0.0017  lr: 0.01  max_mem: 1827M
