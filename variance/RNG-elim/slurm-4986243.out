Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_02_SE1_1000X99.png
	num_instances: 93
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_11S_250x.png
	num_instances: 39
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_12S_500x.png
	num_instances: 31
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[11/09 17:19:26 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[11/09 17:19:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/09 17:19:26 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[11/09 17:19:26 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[11/09 17:19:26 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[11/09 17:19:26 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[11/09 17:19:26 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[11/09 17:19:26 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[11/09 17:19:26 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[11/09 17:19:26 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[11/09 17:19:27 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[11/09 17:19:29 d2.utils.events]: [0m eta: 0:08:36  iter: 19  total_loss: 3.223  loss_cls: 0.5164  loss_box_reg: 0.04115  loss_mask: 0.676  loss_rpn_cls: 0.6595  loss_rpn_loc: 1.368  time: 0.1019  data_time: 0.0263  lr: 0.00019981  max_mem: 1704M
[32m[11/09 17:19:31 d2.utils.events]: [0m eta: 0:08:34  iter: 39  total_loss: 2.412  loss_cls: 0.3476  loss_box_reg: 0.02983  loss_mask: 0.6061  loss_rpn_cls: 0.5971  loss_rpn_loc: 0.7775  time: 0.1051  data_time: 0.0017  lr: 0.00039961  max_mem: 1704M
[32m[11/09 17:19:33 d2.utils.events]: [0m eta: 0:08:29  iter: 59  total_loss: 2.032  loss_cls: 0.2437  loss_box_reg: 0.0548  loss_mask: 0.5962  loss_rpn_cls: 0.5617  loss_rpn_loc: 0.6021  time: 0.1042  data_time: 0.0016  lr: 0.00059941  max_mem: 1774M
[32m[11/09 17:19:36 d2.utils.events]: [0m eta: 0:08:23  iter: 79  total_loss: 1.974  loss_cls: 0.1968  loss_box_reg: 0.1075  loss_mask: 0.569  loss_rpn_cls: 0.5125  loss_rpn_loc: 0.5481  time: 0.1037  data_time: 0.0017  lr: 0.00079921  max_mem: 1774M
[32m[11/09 17:19:38 d2.utils.events]: [0m eta: 0:08:21  iter: 99  total_loss: 2.144  loss_cls: 0.2832  loss_box_reg: 0.1951  loss_mask: 0.564  loss_rpn_cls: 0.5248  loss_rpn_loc: 0.5483  time: 0.1034  data_time: 0.0016  lr: 0.00099901  max_mem: 1774M
[32m[11/09 17:19:40 d2.utils.events]: [0m eta: 0:08:20  iter: 119  total_loss: 2.251  loss_cls: 0.3089  loss_box_reg: 0.3747  loss_mask: 0.5322  loss_rpn_cls: 0.4107  loss_rpn_loc: 0.5588  time: 0.1038  data_time: 0.0017  lr: 0.0011988  max_mem: 1774M
[32m[11/09 17:19:42 d2.utils.events]: [0m eta: 0:08:21  iter: 139  total_loss: 2.045  loss_cls: 0.3017  loss_box_reg: 0.403  loss_mask: 0.5107  loss_rpn_cls: 0.3851  loss_rpn_loc: 0.5308  time: 0.1038  data_time: 0.0015  lr: 0.0013986  max_mem: 1774M
[32m[11/09 17:19:44 d2.utils.events]: [0m eta: 0:08:20  iter: 159  total_loss: 2.047  loss_cls: 0.2766  loss_box_reg: 0.38  loss_mask: 0.4923  loss_rpn_cls: 0.3185  loss_rpn_loc: 0.5118  time: 0.1041  data_time: 0.0018  lr: 0.0015984  max_mem: 1774M
[32m[11/09 17:19:46 d2.utils.events]: [0m eta: 0:08:22  iter: 179  total_loss: 1.905  loss_cls: 0.2761  loss_box_reg: 0.4011  loss_mask: 0.4463  loss_rpn_cls: 0.3131  loss_rpn_loc: 0.4935  time: 0.1048  data_time: 0.0016  lr: 0.0017982  max_mem: 1774M
[32m[11/09 17:19:49 d2.utils.events]: [0m eta: 0:08:22  iter: 199  total_loss: 1.992  loss_cls: 0.2956  loss_box_reg: 0.432  loss_mask: 0.4403  loss_rpn_cls: 0.2944  loss_rpn_loc: 0.4757  time: 0.1055  data_time: 0.0017  lr: 0.001998  max_mem: 1823M
[32m[11/09 17:19:51 d2.utils.events]: [0m eta: 0:08:26  iter: 219  total_loss: 1.87  loss_cls: 0.2672  loss_box_reg: 0.4663  loss_mask: 0.4033  loss_rpn_cls: 0.2711  loss_rpn_loc: 0.4574  time: 0.1066  data_time: 0.0020  lr: 0.0021978  max_mem: 1823M
[32m[11/09 17:19:53 d2.utils.events]: [0m eta: 0:08:25  iter: 239  total_loss: 1.893  loss_cls: 0.2737  loss_box_reg: 0.4633  loss_mask: 0.4052  loss_rpn_cls: 0.267  loss_rpn_loc: 0.4414  time: 0.1068  data_time: 0.0018  lr: 0.0023976  max_mem: 1823M
[32m[11/09 17:19:55 d2.utils.events]: [0m eta: 0:08:26  iter: 259  total_loss: 1.846  loss_cls: 0.302  loss_box_reg: 0.4824  loss_mask: 0.3757  loss_rpn_cls: 0.2605  loss_rpn_loc: 0.4528  time: 0.1072  data_time: 0.0020  lr: 0.0025974  max_mem: 1823M
[32m[11/09 17:19:58 d2.utils.events]: [0m eta: 0:08:24  iter: 279  total_loss: 1.744  loss_cls: 0.2622  loss_box_reg: 0.4434  loss_mask: 0.3664  loss_rpn_cls: 0.2433  loss_rpn_loc: 0.4278  time: 0.1075  data_time: 0.0018  lr: 0.0027972  max_mem: 1823M
[32m[11/09 17:20:00 d2.utils.events]: [0m eta: 0:08:22  iter: 299  total_loss: 1.672  loss_cls: 0.2009  loss_box_reg: 0.3713  loss_mask: 0.3519  loss_rpn_cls: 0.2275  loss_rpn_loc: 0.4259  time: 0.1076  data_time: 0.0018  lr: 0.002997  max_mem: 1823M
[32m[11/09 17:20:02 d2.utils.events]: [0m eta: 0:08:20  iter: 319  total_loss: 1.497  loss_cls: 0.162  loss_box_reg: 0.3291  loss_mask: 0.345  loss_rpn_cls: 0.2534  loss_rpn_loc: 0.4222  time: 0.1076  data_time: 0.0020  lr: 0.0031968  max_mem: 1823M
[32m[11/09 17:20:04 d2.utils.events]: [0m eta: 0:08:20  iter: 339  total_loss: 1.711  loss_cls: 0.2681  loss_box_reg: 0.431  loss_mask: 0.3224  loss_rpn_cls: 0.2469  loss_rpn_loc: 0.4414  time: 0.1080  data_time: 0.0019  lr: 0.0033966  max_mem: 1823M
[32m[11/09 17:20:07 d2.utils.events]: [0m eta: 0:08:20  iter: 359  total_loss: 1.65  loss_cls: 0.2335  loss_box_reg: 0.4052  loss_mask: 0.3454  loss_rpn_cls: 0.2424  loss_rpn_loc: 0.4508  time: 0.1082  data_time: 0.0019  lr: 0.0035964  max_mem: 1823M
[32m[11/09 17:20:09 d2.utils.events]: [0m eta: 0:08:18  iter: 379  total_loss: 1.719  loss_cls: 0.2492  loss_box_reg: 0.5112  loss_mask: 0.332  loss_rpn_cls: 0.2289  loss_rpn_loc: 0.4178  time: 0.1085  data_time: 0.0019  lr: 0.0037962  max_mem: 1823M
[32m[11/09 17:20:11 d2.utils.events]: [0m eta: 0:08:22  iter: 399  total_loss: 1.774  loss_cls: 0.2866  loss_box_reg: 0.5152  loss_mask: 0.2947  loss_rpn_cls: 0.2087  loss_rpn_loc: 0.4477  time: 0.1089  data_time: 0.0019  lr: 0.003996  max_mem: 1823M
[32m[11/09 17:20:14 d2.utils.events]: [0m eta: 0:08:22  iter: 419  total_loss: 1.738  loss_cls: 0.2735  loss_box_reg: 0.5383  loss_mask: 0.3028  loss_rpn_cls: 0.2101  loss_rpn_loc: 0.4333  time: 0.1094  data_time: 0.0019  lr: 0.0041958  max_mem: 1823M
[32m[11/09 17:20:16 d2.utils.events]: [0m eta: 0:08:20  iter: 439  total_loss: 1.654  loss_cls: 0.2466  loss_box_reg: 0.4848  loss_mask: 0.3149  loss_rpn_cls: 0.2172  loss_rpn_loc: 0.4048  time: 0.1095  data_time: 0.0019  lr: 0.0043956  max_mem: 1823M
[32m[11/09 17:20:19 d2.utils.events]: [0m eta: 0:08:19  iter: 459  total_loss: 1.65  loss_cls: 0.2561  loss_box_reg: 0.4934  loss_mask: 0.2919  loss_rpn_cls: 0.2116  loss_rpn_loc: 0.3901  time: 0.1098  data_time: 0.0020  lr: 0.0045954  max_mem: 1823M
[32m[11/09 17:20:21 d2.utils.events]: [0m eta: 0:08:17  iter: 479  total_loss: 1.643  loss_cls: 0.2578  loss_box_reg: 0.5277  loss_mask: 0.2817  loss_rpn_cls: 0.2208  loss_rpn_loc: 0.3881  time: 0.1099  data_time: 0.0018  lr: 0.0047952  max_mem: 1823M
[32m[11/09 17:20:23 d2.utils.events]: [0m eta: 0:08:14  iter: 499  total_loss: 1.606  loss_cls: 0.2418  loss_box_reg: 0.4913  loss_mask: 0.284  loss_rpn_cls: 0.1804  loss_rpn_loc: 0.4115  time: 0.1099  data_time: 0.0016  lr: 0.004995  max_mem: 1823M
[32m[11/09 17:20:26 d2.utils.events]: [0m eta: 0:08:11  iter: 519  total_loss: 1.67  loss_cls: 0.2595  loss_box_reg: 0.5042  loss_mask: 0.2813  loss_rpn_cls: 0.212  loss_rpn_loc: 0.3927  time: 0.1099  data_time: 0.0017  lr: 0.0051948  max_mem: 1823M
[32m[11/09 17:20:28 d2.utils.events]: [0m eta: 0:08:09  iter: 539  total_loss: 1.565  loss_cls: 0.2402  loss_box_reg: 0.4612  loss_mask: 0.272  loss_rpn_cls: 0.2181  loss_rpn_loc: 0.3985  time: 0.1099  data_time: 0.0015  lr: 0.0053946  max_mem: 1823M
[32m[11/09 17:20:30 d2.utils.events]: [0m eta: 0:08:07  iter: 559  total_loss: 1.594  loss_cls: 0.2447  loss_box_reg: 0.4924  loss_mask: 0.2632  loss_rpn_cls: 0.1715  loss_rpn_loc: 0.3916  time: 0.1099  data_time: 0.0017  lr: 0.0055944  max_mem: 1823M
[32m[11/09 17:20:32 d2.utils.events]: [0m eta: 0:08:05  iter: 579  total_loss: 1.45  loss_cls: 0.2254  loss_box_reg: 0.4495  loss_mask: 0.2585  loss_rpn_cls: 0.1933  loss_rpn_loc: 0.4014  time: 0.1100  data_time: 0.0017  lr: 0.0057942  max_mem: 1823M
[32m[11/09 17:20:35 d2.utils.events]: [0m eta: 0:08:03  iter: 599  total_loss: 1.4  loss_cls: 0.175  loss_box_reg: 0.3392  loss_mask: 0.2788  loss_rpn_cls: 0.1816  loss_rpn_loc: 0.4463  time: 0.1099  data_time: 0.0017  lr: 0.005994  max_mem: 1823M
[32m[11/09 17:20:37 d2.utils.events]: [0m eta: 0:08:00  iter: 619  total_loss: 1.555  loss_cls: 0.2314  loss_box_reg: 0.4651  loss_mask: 0.2733  loss_rpn_cls: 0.1972  loss_rpn_loc: 0.4097  time: 0.1099  data_time: 0.0017  lr: 0.0061938  max_mem: 1823M
[32m[11/09 17:20:39 d2.utils.events]: [0m eta: 0:07:58  iter: 639  total_loss: 1.682  loss_cls: 0.2575  loss_box_reg: 0.4469  loss_mask: 0.2798  loss_rpn_cls: 0.2288  loss_rpn_loc: 0.4795  time: 0.1099  data_time: 0.0018  lr: 0.0063936  max_mem: 1823M
[32m[11/09 17:20:41 d2.utils.events]: [0m eta: 0:07:56  iter: 659  total_loss: 1.628  loss_cls: 0.2031  loss_box_reg: 0.4597  loss_mask: 0.2629  loss_rpn_cls: 0.2016  loss_rpn_loc: 0.4182  time: 0.1099  data_time: 0.0018  lr: 0.0065934  max_mem: 1823M
[32m[11/09 17:20:44 d2.utils.events]: [0m eta: 0:07:55  iter: 679  total_loss: 1.593  loss_cls: 0.257  loss_box_reg: 0.486  loss_mask: 0.2766  loss_rpn_cls: 0.1962  loss_rpn_loc: 0.4061  time: 0.1100  data_time: 0.0020  lr: 0.0067932  max_mem: 1823M
[32m[11/09 17:20:46 d2.utils.events]: [0m eta: 0:07:55  iter: 699  total_loss: 1.621  loss_cls: 0.2462  loss_box_reg: 0.4629  loss_mask: 0.254  loss_rpn_cls: 0.1805  loss_rpn_loc: 0.4412  time: 0.1102  data_time: 0.0020  lr: 0.006993  max_mem: 1823M
[32m[11/09 17:20:48 d2.utils.events]: [0m eta: 0:07:53  iter: 719  total_loss: 1.463  loss_cls: 0.233  loss_box_reg: 0.4528  loss_mask: 0.2532  loss_rpn_cls: 0.1462  loss_rpn_loc: 0.4124  time: 0.1103  data_time: 0.0020  lr: 0.0071928  max_mem: 1823M
[32m[11/09 17:20:51 d2.utils.events]: [0m eta: 0:07:52  iter: 739  total_loss: 1.466  loss_cls: 0.2085  loss_box_reg: 0.4745  loss_mask: 0.2476  loss_rpn_cls: 0.1542  loss_rpn_loc: 0.3786  time: 0.1104  data_time: 0.0019  lr: 0.0073926  max_mem: 1823M
[32m[11/09 17:20:53 d2.utils.events]: [0m eta: 0:07:50  iter: 759  total_loss: 1.518  loss_cls: 0.2219  loss_box_reg: 0.4636  loss_mask: 0.2603  loss_rpn_cls: 0.1897  loss_rpn_loc: 0.3956  time: 0.1104  data_time: 0.0019  lr: 0.0075924  max_mem: 1823M
[32m[11/09 17:20:55 d2.utils.events]: [0m eta: 0:07:49  iter: 779  total_loss: 1.469  loss_cls: 0.222  loss_box_reg: 0.4424  loss_mask: 0.244  loss_rpn_cls: 0.1738  loss_rpn_loc: 0.3867  time: 0.1106  data_time: 0.0019  lr: 0.0077922  max_mem: 1823M
[32m[11/09 17:20:57 d2.utils.events]: [0m eta: 0:07:47  iter: 799  total_loss: 1.514  loss_cls: 0.2223  loss_box_reg: 0.4837  loss_mask: 0.2364  loss_rpn_cls: 0.1614  loss_rpn_loc: 0.4078  time: 0.1107  data_time: 0.0018  lr: 0.007992  max_mem: 1823M
[32m[11/09 17:21:00 d2.utils.events]: [0m eta: 0:07:44  iter: 819  total_loss: 1.522  loss_cls: 0.235  loss_box_reg: 0.4522  loss_mask: 0.2543  loss_rpn_cls: 0.162  loss_rpn_loc: 0.3803  time: 0.1108  data_time: 0.0018  lr: 0.0081918  max_mem: 1823M
[32m[11/09 17:21:02 d2.utils.events]: [0m eta: 0:07:42  iter: 839  total_loss: 1.481  loss_cls: 0.2341  loss_box_reg: 0.4888  loss_mask: 0.241  loss_rpn_cls: 0.1898  loss_rpn_loc: 0.3605  time: 0.1109  data_time: 0.0018  lr: 0.0083916  max_mem: 1823M
[32m[11/09 17:21:04 d2.utils.events]: [0m eta: 0:07:40  iter: 859  total_loss: 1.465  loss_cls: 0.2331  loss_box_reg: 0.4562  loss_mask: 0.2423  loss_rpn_cls: 0.1511  loss_rpn_loc: 0.3733  time: 0.1109  data_time: 0.0016  lr: 0.0085914  max_mem: 1823M
[32m[11/09 17:21:06 d2.utils.events]: [0m eta: 0:07:38  iter: 879  total_loss: 1.53  loss_cls: 0.2429  loss_box_reg: 0.46  loss_mask: 0.2553  loss_rpn_cls: 0.1553  loss_rpn_loc: 0.4256  time: 0.1108  data_time: 0.0016  lr: 0.0087912  max_mem: 1823M
[32m[11/09 17:21:09 d2.utils.events]: [0m eta: 0:07:35  iter: 899  total_loss: 1.43  loss_cls: 0.2129  loss_box_reg: 0.4368  loss_mask: 0.2425  loss_rpn_cls: 0.1505  loss_rpn_loc: 0.395  time: 0.1108  data_time: 0.0016  lr: 0.008991  max_mem: 1823M
[32m[11/09 17:21:11 d2.utils.events]: [0m eta: 0:07:33  iter: 919  total_loss: 1.381  loss_cls: 0.2065  loss_box_reg: 0.4199  loss_mask: 0.2374  loss_rpn_cls: 0.1445  loss_rpn_loc: 0.3576  time: 0.1107  data_time: 0.0017  lr: 0.0091908  max_mem: 1823M
[32m[11/09 17:21:13 d2.utils.events]: [0m eta: 0:07:30  iter: 939  total_loss: 1.407  loss_cls: 0.2187  loss_box_reg: 0.4525  loss_mask: 0.2317  loss_rpn_cls: 0.1619  loss_rpn_loc: 0.3757  time: 0.1107  data_time: 0.0016  lr: 0.0093906  max_mem: 1823M
[32m[11/09 17:21:15 d2.utils.events]: [0m eta: 0:07:28  iter: 959  total_loss: 1.386  loss_cls: 0.1917  loss_box_reg: 0.3989  loss_mask: 0.2314  loss_rpn_cls: 0.1581  loss_rpn_loc: 0.3857  time: 0.1107  data_time: 0.0015  lr: 0.0095904  max_mem: 1823M
[32m[11/09 17:21:18 d2.utils.events]: [0m eta: 0:07:25  iter: 979  total_loss: 1.499  loss_cls: 0.2333  loss_box_reg: 0.4728  loss_mask: 0.252  loss_rpn_cls: 0.1681  loss_rpn_loc: 0.3954  time: 0.1107  data_time: 0.0016  lr: 0.0097902  max_mem: 1823M
[32m[11/09 17:21:20 d2.utils.events]: [0m eta: 0:07:23  iter: 999  total_loss: 1.532  loss_cls: 0.2374  loss_box_reg: 0.4235  loss_mask: 0.2461  loss_rpn_cls: 0.1562  loss_rpn_loc: 0.4121  time: 0.1106  data_time: 0.0016  lr: 0.00999  max_mem: 1823M
[32m[11/09 17:21:22 d2.utils.events]: [0m eta: 0:07:22  iter: 1019  total_loss: 1.476  loss_cls: 0.2059  loss_box_reg: 0.3873  loss_mask: 0.2383  loss_rpn_cls: 0.2112  loss_rpn_loc: 0.4362  time: 0.1106  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:24 d2.utils.events]: [0m eta: 0:07:19  iter: 1039  total_loss: 1.425  loss_cls: 0.1802  loss_box_reg: 0.3275  loss_mask: 0.2329  loss_rpn_cls: 0.1767  loss_rpn_loc: 0.42  time: 0.1105  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:27 d2.utils.events]: [0m eta: 0:07:17  iter: 1059  total_loss: 1.429  loss_cls: 0.1983  loss_box_reg: 0.3851  loss_mask: 0.2314  loss_rpn_cls: 0.1609  loss_rpn_loc: 0.396  time: 0.1105  data_time: 0.0014  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:29 d2.utils.events]: [0m eta: 0:07:15  iter: 1079  total_loss: 1.355  loss_cls: 0.1951  loss_box_reg: 0.4127  loss_mask: 0.2309  loss_rpn_cls: 0.1628  loss_rpn_loc: 0.3757  time: 0.1105  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:31 d2.utils.events]: [0m eta: 0:07:13  iter: 1099  total_loss: 1.423  loss_cls: 0.2176  loss_box_reg: 0.4399  loss_mask: 0.2383  loss_rpn_cls: 0.1926  loss_rpn_loc: 0.3694  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:33 d2.utils.events]: [0m eta: 0:07:11  iter: 1119  total_loss: 1.451  loss_cls: 0.2019  loss_box_reg: 0.4043  loss_mask: 0.2245  loss_rpn_cls: 0.1667  loss_rpn_loc: 0.3851  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:35 d2.utils.events]: [0m eta: 0:07:08  iter: 1139  total_loss: 1.42  loss_cls: 0.2161  loss_box_reg: 0.4603  loss_mask: 0.2318  loss_rpn_cls: 0.1557  loss_rpn_loc: 0.393  time: 0.1103  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:38 d2.utils.events]: [0m eta: 0:07:07  iter: 1159  total_loss: 1.42  loss_cls: 0.1973  loss_box_reg: 0.4336  loss_mask: 0.2298  loss_rpn_cls: 0.1329  loss_rpn_loc: 0.4021  time: 0.1103  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:40 d2.utils.events]: [0m eta: 0:07:04  iter: 1179  total_loss: 1.427  loss_cls: 0.208  loss_box_reg: 0.4409  loss_mask: 0.2208  loss_rpn_cls: 0.1748  loss_rpn_loc: 0.3999  time: 0.1103  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:42 d2.utils.events]: [0m eta: 0:07:02  iter: 1199  total_loss: 1.519  loss_cls: 0.2302  loss_box_reg: 0.4357  loss_mask: 0.2105  loss_rpn_cls: 0.2144  loss_rpn_loc: 0.4314  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:44 d2.utils.events]: [0m eta: 0:07:00  iter: 1219  total_loss: 1.367  loss_cls: 0.1944  loss_box_reg: 0.438  loss_mask: 0.2231  loss_rpn_cls: 0.1315  loss_rpn_loc: 0.3887  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:47 d2.utils.events]: [0m eta: 0:06:58  iter: 1239  total_loss: 1.459  loss_cls: 0.243  loss_box_reg: 0.4329  loss_mask: 0.2271  loss_rpn_cls: 0.1516  loss_rpn_loc: 0.4177  time: 0.1103  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:49 d2.utils.events]: [0m eta: 0:06:55  iter: 1259  total_loss: 1.402  loss_cls: 0.2359  loss_box_reg: 0.4342  loss_mask: 0.2068  loss_rpn_cls: 0.1458  loss_rpn_loc: 0.3576  time: 0.1104  data_time: 0.0017  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:51 d2.utils.events]: [0m eta: 0:06:54  iter: 1279  total_loss: 1.428  loss_cls: 0.2147  loss_box_reg: 0.4665  loss_mask: 0.213  loss_rpn_cls: 0.1224  loss_rpn_loc: 0.3491  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:53 d2.utils.events]: [0m eta: 0:06:52  iter: 1299  total_loss: 1.36  loss_cls: 0.231  loss_box_reg: 0.4626  loss_mask: 0.2267  loss_rpn_cls: 0.1386  loss_rpn_loc: 0.3358  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:56 d2.utils.events]: [0m eta: 0:06:49  iter: 1319  total_loss: 1.339  loss_cls: 0.2147  loss_box_reg: 0.4264  loss_mask: 0.2063  loss_rpn_cls: 0.1427  loss_rpn_loc: 0.3524  time: 0.1104  data_time: 0.0017  lr: 0.01  max_mem: 1823M
[32m[11/09 17:21:58 d2.utils.events]: [0m eta: 0:06:47  iter: 1339  total_loss: 1.348  loss_cls: 0.2182  loss_box_reg: 0.4414  loss_mask: 0.2209  loss_rpn_cls: 0.1386  loss_rpn_loc: 0.3574  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:00 d2.utils.events]: [0m eta: 0:06:45  iter: 1359  total_loss: 1.362  loss_cls: 0.2076  loss_box_reg: 0.4343  loss_mask: 0.2066  loss_rpn_cls: 0.1695  loss_rpn_loc: 0.3482  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:02 d2.utils.events]: [0m eta: 0:06:43  iter: 1379  total_loss: 1.398  loss_cls: 0.2118  loss_box_reg: 0.4071  loss_mask: 0.2122  loss_rpn_cls: 0.171  loss_rpn_loc: 0.4041  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:05 d2.utils.events]: [0m eta: 0:06:39  iter: 1399  total_loss: 1.359  loss_cls: 0.1921  loss_box_reg: 0.4103  loss_mask: 0.2208  loss_rpn_cls: 0.1418  loss_rpn_loc: 0.3706  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:07 d2.utils.events]: [0m eta: 0:06:37  iter: 1419  total_loss: 1.301  loss_cls: 0.2155  loss_box_reg: 0.4309  loss_mask: 0.2157  loss_rpn_cls: 0.134  loss_rpn_loc: 0.346  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:09 d2.utils.events]: [0m eta: 0:06:35  iter: 1439  total_loss: 1.342  loss_cls: 0.2094  loss_box_reg: 0.4394  loss_mask: 0.2044  loss_rpn_cls: 0.102  loss_rpn_loc: 0.3546  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:11 d2.utils.events]: [0m eta: 0:06:32  iter: 1459  total_loss: 1.376  loss_cls: 0.2117  loss_box_reg: 0.4372  loss_mask: 0.2014  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.364  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:14 d2.utils.events]: [0m eta: 0:06:30  iter: 1479  total_loss: 1.312  loss_cls: 0.2045  loss_box_reg: 0.4217  loss_mask: 0.214  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.3351  time: 0.1105  data_time: 0.0017  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:17 d2.utils.events]: [0m eta: 0:06:28  iter: 1499  total_loss: 1.408  loss_cls: 0.2028  loss_box_reg: 0.4167  loss_mask: 0.2158  loss_rpn_cls: 0.1873  loss_rpn_loc: 0.3776  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:19 d2.utils.events]: [0m eta: 0:06:26  iter: 1519  total_loss: 1.298  loss_cls: 0.1948  loss_box_reg: 0.3795  loss_mask: 0.2111  loss_rpn_cls: 0.1451  loss_rpn_loc: 0.3549  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:21 d2.utils.events]: [0m eta: 0:06:24  iter: 1539  total_loss: 1.266  loss_cls: 0.1909  loss_box_reg: 0.3907  loss_mask: 0.2042  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.3277  time: 0.1104  data_time: 0.0017  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:23 d2.utils.events]: [0m eta: 0:06:22  iter: 1559  total_loss: 1.33  loss_cls: 0.2107  loss_box_reg: 0.4307  loss_mask: 0.2215  loss_rpn_cls: 0.1583  loss_rpn_loc: 0.341  time: 0.1104  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:26 d2.utils.events]: [0m eta: 0:06:20  iter: 1579  total_loss: 1.324  loss_cls: 0.2298  loss_box_reg: 0.4297  loss_mask: 0.2073  loss_rpn_cls: 0.1344  loss_rpn_loc: 0.3418  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:28 d2.utils.events]: [0m eta: 0:06:18  iter: 1599  total_loss: 1.295  loss_cls: 0.2045  loss_box_reg: 0.4113  loss_mask: 0.2085  loss_rpn_cls: 0.1301  loss_rpn_loc: 0.3366  time: 0.1105  data_time: 0.0015  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:30 d2.utils.events]: [0m eta: 0:06:16  iter: 1619  total_loss: 1.269  loss_cls: 0.2056  loss_box_reg: 0.4109  loss_mask: 0.1967  loss_rpn_cls: 0.1131  loss_rpn_loc: 0.3275  time: 0.1105  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:32 d2.utils.events]: [0m eta: 0:06:14  iter: 1639  total_loss: 1.318  loss_cls: 0.2082  loss_box_reg: 0.4279  loss_mask: 0.2042  loss_rpn_cls: 0.1366  loss_rpn_loc: 0.3514  time: 0.1104  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:35 d2.utils.events]: [0m eta: 0:06:12  iter: 1659  total_loss: 1.273  loss_cls: 0.2109  loss_box_reg: 0.4429  loss_mask: 0.1978  loss_rpn_cls: 0.12  loss_rpn_loc: 0.3183  time: 0.1104  data_time: 0.0017  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:37 d2.utils.events]: [0m eta: 0:06:09  iter: 1679  total_loss: 1.272  loss_cls: 0.2144  loss_box_reg: 0.4168  loss_mask: 0.196  loss_rpn_cls: 0.119  loss_rpn_loc: 0.3518  time: 0.1105  data_time: 0.0016  lr: 0.01  max_mem: 1823M
[32m[11/09 17:22:39 d2.utils.events]: [0m eta: 0:06:07  iter: 1699  total_loss: 1.244  loss_cls: 0.2011  loss_box_reg: 0.4217  loss_mask: 0.2039  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.3135  time: 0.1105  data_time: 0.0015  lr: 0.01  max_mem: 1823M
