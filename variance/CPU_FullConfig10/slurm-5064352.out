[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
Registered Datasets: ['satellite_Train', 'satellite_Val']
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_4S_500x.png
	num_instances: 103
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_01_SE1_1000X94.png
	num_instances: 68
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_6S_250x.png
	num_instances: 102
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S08_03_SE1_1000X03.png
	num_instances: 88
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S06_01_SE1_500X67.png
	num_instances: 54
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S04_02_SE1_1000X50.png
	num_instances: 45
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S03_03_SE1_1250X41.png
	num_instances: 111
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/S02_01_SE1_300X14.png
	num_instances: 98
ddict info:
	path: ../SALAS_Rep/../../../../../../../ocean/projects/dmr200021p/sprice/initial_paper_complete_set/HP743_2S_250x.png
	num_instances: 49
Weights not found, weights will be downloaded from source: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl
[32m[11/15 22:10:48 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[11/15 22:10:48 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/15 22:10:48 d2.data.build]: [0mDistribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
| satellite  | 1412         |
|            |              |[0m
[32m[11/15 22:10:48 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]
[32m[11/15 22:10:48 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[11/15 22:10:48 d2.data.common]: [0mSerializing 20 elements to byte tensors and concatenating them all ...
[32m[11/15 22:10:48 d2.data.common]: [0mSerialized dataset takes 0.46 MiB
[5m[31mWARNING[0m [32m[11/15 22:10:48 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[11/15 22:10:48 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[11/15 22:10:48 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[32m[11/15 22:10:48 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[11/15 22:11:56 d2.utils.events]: [0m eta: 9:12:30  iter: 19  total_loss: 3.299  loss_cls: 0.5196  loss_box_reg: 0.02739  loss_mask: 0.6726  loss_rpn_cls: 0.6624  loss_rpn_loc: 1.269  time: 3.3254  data_time: 0.0171  lr: 0.00019981  max_mem: 0M
[32m[11/15 22:12:57 d2.utils.events]: [0m eta: 8:52:11  iter: 39  total_loss: 2.408  loss_cls: 0.353  loss_box_reg: 0.0366  loss_mask: 0.5966  loss_rpn_cls: 0.6079  loss_rpn_loc: 0.8124  time: 3.1788  data_time: 0.0044  lr: 0.00039961  max_mem: 0M
[32m[11/15 22:14:00 d2.utils.events]: [0m eta: 8:51:01  iter: 59  total_loss: 2.14  loss_cls: 0.2758  loss_box_reg: 0.06761  loss_mask: 0.5832  loss_rpn_cls: 0.5732  loss_rpn_loc: 0.6399  time: 3.1633  data_time: 0.0046  lr: 0.00059941  max_mem: 0M
[32m[11/15 22:15:06 d2.utils.events]: [0m eta: 8:52:22  iter: 79  total_loss: 2.088  loss_cls: 0.2408  loss_box_reg: 0.167  loss_mask: 0.5632  loss_rpn_cls: 0.5431  loss_rpn_loc: 0.5478  time: 3.1990  data_time: 0.0044  lr: 0.00079921  max_mem: 0M
[32m[11/15 22:16:20 d2.utils.events]: [0m eta: 9:01:56  iter: 99  total_loss: 2.122  loss_cls: 0.2652  loss_box_reg: 0.3352  loss_mask: 0.54  loss_rpn_cls: 0.4601  loss_rpn_loc: 0.5138  time: 3.2991  data_time: 0.0064  lr: 0.00099901  max_mem: 0M
[32m[11/15 22:17:33 d2.utils.events]: [0m eta: 9:06:39  iter: 119  total_loss: 2.116  loss_cls: 0.2833  loss_box_reg: 0.4248  loss_mask: 0.5117  loss_rpn_cls: 0.3868  loss_rpn_loc: 0.5009  time: 3.3574  data_time: 0.0064  lr: 0.0011988  max_mem: 0M
[32m[11/15 22:18:47 d2.utils.events]: [0m eta: 9:13:44  iter: 139  total_loss: 2.029  loss_cls: 0.27  loss_box_reg: 0.4271  loss_mask: 0.4687  loss_rpn_cls: 0.3358  loss_rpn_loc: 0.4981  time: 3.4063  data_time: 0.0032  lr: 0.0013986  max_mem: 0M
[32m[11/15 22:20:01 d2.utils.events]: [0m eta: 9:16:46  iter: 159  total_loss: 2.026  loss_cls: 0.3394  loss_box_reg: 0.4839  loss_mask: 0.4366  loss_rpn_cls: 0.3428  loss_rpn_loc: 0.4938  time: 3.4446  data_time: 0.0067  lr: 0.0015984  max_mem: 0M
[32m[11/15 22:21:08 d2.utils.events]: [0m eta: 9:12:31  iter: 179  total_loss: 1.86  loss_cls: 0.2701  loss_box_reg: 0.4661  loss_mask: 0.4145  loss_rpn_cls: 0.289  loss_rpn_loc: 0.4701  time: 3.4353  data_time: 0.0053  lr: 0.0017982  max_mem: 0M
[32m[11/15 22:22:18 d2.utils.events]: [0m eta: 9:13:41  iter: 199  total_loss: 1.815  loss_cls: 0.2634  loss_box_reg: 0.4287  loss_mask: 0.3863  loss_rpn_cls: 0.2698  loss_rpn_loc: 0.4557  time: 3.4370  data_time: 0.0050  lr: 0.001998  max_mem: 0M
[32m[11/15 22:23:26 d2.utils.events]: [0m eta: 9:11:07  iter: 219  total_loss: 1.72  loss_cls: 0.242  loss_box_reg: 0.4053  loss_mask: 0.3469  loss_rpn_cls: 0.2643  loss_rpn_loc: 0.4341  time: 3.4361  data_time: 0.0041  lr: 0.0021978  max_mem: 0M
[32m[11/15 22:24:38 d2.utils.events]: [0m eta: 9:15:33  iter: 239  total_loss: 1.725  loss_cls: 0.2392  loss_box_reg: 0.4024  loss_mask: 0.3397  loss_rpn_cls: 0.2449  loss_rpn_loc: 0.4859  time: 3.4474  data_time: 0.0034  lr: 0.0023976  max_mem: 0M
[32m[11/15 22:25:49 d2.utils.events]: [0m eta: 9:15:18  iter: 259  total_loss: 1.692  loss_cls: 0.2453  loss_box_reg: 0.4473  loss_mask: 0.3233  loss_rpn_cls: 0.2331  loss_rpn_loc: 0.4519  time: 3.4543  data_time: 0.0042  lr: 0.0025974  max_mem: 0M
[32m[11/15 22:27:00 d2.utils.events]: [0m eta: 9:16:57  iter: 279  total_loss: 1.522  loss_cls: 0.1992  loss_box_reg: 0.4029  loss_mask: 0.3234  loss_rpn_cls: 0.1905  loss_rpn_loc: 0.4145  time: 3.4626  data_time: 0.0051  lr: 0.0027972  max_mem: 0M
[32m[11/15 22:28:13 d2.utils.events]: [0m eta: 9:19:51  iter: 299  total_loss: 1.673  loss_cls: 0.2366  loss_box_reg: 0.4892  loss_mask: 0.2994  loss_rpn_cls: 0.2245  loss_rpn_loc: 0.4008  time: 3.4747  data_time: 0.0059  lr: 0.002997  max_mem: 0M
[32m[11/15 22:29:23 d2.utils.events]: [0m eta: 9:19:18  iter: 319  total_loss: 1.709  loss_cls: 0.2342  loss_box_reg: 0.4658  loss_mask: 0.3201  loss_rpn_cls: 0.2235  loss_rpn_loc: 0.4063  time: 3.4763  data_time: 0.0033  lr: 0.0031968  max_mem: 0M
[32m[11/15 22:30:36 d2.utils.events]: [0m eta: 9:18:59  iter: 339  total_loss: 1.696  loss_cls: 0.2512  loss_box_reg: 0.4661  loss_mask: 0.31  loss_rpn_cls: 0.2054  loss_rpn_loc: 0.4611  time: 3.4862  data_time: 0.0064  lr: 0.0033966  max_mem: 0M
[32m[11/15 22:31:48 d2.utils.events]: [0m eta: 9:20:14  iter: 359  total_loss: 1.581  loss_cls: 0.2242  loss_box_reg: 0.4942  loss_mask: 0.2884  loss_rpn_cls: 0.1947  loss_rpn_loc: 0.3806  time: 3.4935  data_time: 0.0057  lr: 0.0035964  max_mem: 0M
[32m[11/15 22:32:58 d2.utils.events]: [0m eta: 9:18:22  iter: 379  total_loss: 1.543  loss_cls: 0.2093  loss_box_reg: 0.4049  loss_mask: 0.295  loss_rpn_cls: 0.2249  loss_rpn_loc: 0.3885  time: 3.4935  data_time: 0.0053  lr: 0.0037962  max_mem: 0M
[32m[11/15 22:34:10 d2.utils.events]: [0m eta: 9:19:05  iter: 399  total_loss: 1.515  loss_cls: 0.2063  loss_box_reg: 0.4246  loss_mask: 0.2744  loss_rpn_cls: 0.2234  loss_rpn_loc: 0.4282  time: 3.4985  data_time: 0.0043  lr: 0.003996  max_mem: 0M
[32m[11/15 22:35:21 d2.utils.events]: [0m eta: 9:18:44  iter: 419  total_loss: 1.537  loss_cls: 0.1888  loss_box_reg: 0.4327  loss_mask: 0.2663  loss_rpn_cls: 0.2287  loss_rpn_loc: 0.4275  time: 3.5006  data_time: 0.0044  lr: 0.0041958  max_mem: 0M
[32m[11/15 22:36:31 d2.utils.events]: [0m eta: 9:17:52  iter: 439  total_loss: 1.576  loss_cls: 0.2122  loss_box_reg: 0.4559  loss_mask: 0.2701  loss_rpn_cls: 0.1717  loss_rpn_loc: 0.4064  time: 3.5010  data_time: 0.0047  lr: 0.0043956  max_mem: 0M
[32m[11/15 22:37:42 d2.utils.events]: [0m eta: 9:16:56  iter: 459  total_loss: 1.458  loss_cls: 0.2153  loss_box_reg: 0.4681  loss_mask: 0.271  loss_rpn_cls: 0.1881  loss_rpn_loc: 0.3691  time: 3.5028  data_time: 0.0046  lr: 0.0045954  max_mem: 0M
[32m[11/15 22:38:53 d2.utils.events]: [0m eta: 9:15:46  iter: 479  total_loss: 1.41  loss_cls: 0.1933  loss_box_reg: 0.4316  loss_mask: 0.2586  loss_rpn_cls: 0.1621  loss_rpn_loc: 0.3775  time: 3.5030  data_time: 0.0045  lr: 0.0047952  max_mem: 0M
[32m[11/15 22:40:04 d2.utils.events]: [0m eta: 9:15:33  iter: 499  total_loss: 1.511  loss_cls: 0.1749  loss_box_reg: 0.4137  loss_mask: 0.2552  loss_rpn_cls: 0.2018  loss_rpn_loc: 0.3978  time: 3.5060  data_time: 0.0046  lr: 0.004995  max_mem: 0M
[32m[11/15 22:41:14 d2.utils.events]: [0m eta: 9:13:40  iter: 519  total_loss: 1.51  loss_cls: 0.2235  loss_box_reg: 0.453  loss_mask: 0.2581  loss_rpn_cls: 0.1837  loss_rpn_loc: 0.3937  time: 3.5054  data_time: 0.0045  lr: 0.0051948  max_mem: 0M
[32m[11/15 22:42:26 d2.utils.events]: [0m eta: 9:13:37  iter: 539  total_loss: 1.408  loss_cls: 0.219  loss_box_reg: 0.43  loss_mask: 0.25  loss_rpn_cls: 0.1416  loss_rpn_loc: 0.3722  time: 3.5092  data_time: 0.0042  lr: 0.0053946  max_mem: 0M
[32m[11/15 22:43:39 d2.utils.events]: [0m eta: 9:12:57  iter: 559  total_loss: 1.441  loss_cls: 0.2292  loss_box_reg: 0.4483  loss_mask: 0.2525  loss_rpn_cls: 0.136  loss_rpn_loc: 0.3599  time: 3.5125  data_time: 0.0039  lr: 0.0055944  max_mem: 0M
[32m[11/15 22:44:51 d2.utils.events]: [0m eta: 9:12:13  iter: 579  total_loss: 1.459  loss_cls: 0.2132  loss_box_reg: 0.4371  loss_mask: 0.2581  loss_rpn_cls: 0.183  loss_rpn_loc: 0.4093  time: 3.5158  data_time: 0.0030  lr: 0.0057942  max_mem: 0M
[32m[11/15 22:46:05 d2.utils.events]: [0m eta: 9:11:33  iter: 599  total_loss: 1.534  loss_cls: 0.2259  loss_box_reg: 0.4604  loss_mask: 0.2505  loss_rpn_cls: 0.1613  loss_rpn_loc: 0.4157  time: 3.5207  data_time: 0.0036  lr: 0.005994  max_mem: 0M
[32m[11/15 22:47:14 d2.utils.events]: [0m eta: 9:10:23  iter: 619  total_loss: 1.498  loss_cls: 0.2039  loss_box_reg: 0.4468  loss_mask: 0.2554  loss_rpn_cls: 0.1536  loss_rpn_loc: 0.3991  time: 3.5192  data_time: 0.0042  lr: 0.0061938  max_mem: 0M
[32m[11/15 22:48:28 d2.utils.events]: [0m eta: 9:09:17  iter: 639  total_loss: 1.436  loss_cls: 0.2273  loss_box_reg: 0.4307  loss_mask: 0.235  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.3758  time: 3.5241  data_time: 0.0042  lr: 0.0063936  max_mem: 0M
[32m[11/15 22:49:39 d2.utils.events]: [0m eta: 9:08:21  iter: 659  total_loss: 1.49  loss_cls: 0.2199  loss_box_reg: 0.4233  loss_mask: 0.2492  loss_rpn_cls: 0.1565  loss_rpn_loc: 0.407  time: 3.5246  data_time: 0.0042  lr: 0.0065934  max_mem: 0M
[32m[11/15 22:50:50 d2.utils.events]: [0m eta: 9:08:08  iter: 679  total_loss: 1.456  loss_cls: 0.2417  loss_box_reg: 0.4396  loss_mask: 0.236  loss_rpn_cls: 0.1653  loss_rpn_loc: 0.3801  time: 3.5263  data_time: 0.0049  lr: 0.0067932  max_mem: 0M
[32m[11/15 22:52:00 d2.utils.events]: [0m eta: 9:06:21  iter: 699  total_loss: 1.433  loss_cls: 0.2029  loss_box_reg: 0.4358  loss_mask: 0.2429  loss_rpn_cls: 0.1624  loss_rpn_loc: 0.3928  time: 3.5243  data_time: 0.0032  lr: 0.006993  max_mem: 0M
[32m[11/15 22:53:09 d2.utils.events]: [0m eta: 9:04:35  iter: 719  total_loss: 1.469  loss_cls: 0.2041  loss_box_reg: 0.4347  loss_mask: 0.2372  loss_rpn_cls: 0.1714  loss_rpn_loc: 0.4186  time: 3.5221  data_time: 0.0041  lr: 0.0071928  max_mem: 0M
[32m[11/15 22:54:20 d2.utils.events]: [0m eta: 9:03:23  iter: 739  total_loss: 1.322  loss_cls: 0.1705  loss_box_reg: 0.4172  loss_mask: 0.2309  loss_rpn_cls: 0.1396  loss_rpn_loc: 0.3769  time: 3.5223  data_time: 0.0041  lr: 0.0073926  max_mem: 0M
[32m[11/15 22:55:28 d2.utils.events]: [0m eta: 9:02:03  iter: 759  total_loss: 1.289  loss_cls: 0.1732  loss_box_reg: 0.383  loss_mask: 0.2196  loss_rpn_cls: 0.1555  loss_rpn_loc: 0.362  time: 3.5194  data_time: 0.0028  lr: 0.0075924  max_mem: 0M
[32m[11/15 22:56:39 d2.utils.events]: [0m eta: 9:00:46  iter: 779  total_loss: 1.291  loss_cls: 0.1905  loss_box_reg: 0.4303  loss_mask: 0.2184  loss_rpn_cls: 0.1315  loss_rpn_loc: 0.3549  time: 3.5194  data_time: 0.0036  lr: 0.0077922  max_mem: 0M
[32m[11/15 22:57:45 d2.utils.events]: [0m eta: 8:58:55  iter: 799  total_loss: 1.376  loss_cls: 0.1858  loss_box_reg: 0.4334  loss_mask: 0.2281  loss_rpn_cls: 0.1577  loss_rpn_loc: 0.3982  time: 3.5145  data_time: 0.0033  lr: 0.007992  max_mem: 0M
[32m[11/15 22:58:56 d2.utils.events]: [0m eta: 8:57:37  iter: 819  total_loss: 1.363  loss_cls: 0.1949  loss_box_reg: 0.4268  loss_mask: 0.2227  loss_rpn_cls: 0.1528  loss_rpn_loc: 0.3868  time: 3.5148  data_time: 0.0037  lr: 0.0081918  max_mem: 0M
[32m[11/15 23:00:05 d2.utils.events]: [0m eta: 8:56:16  iter: 839  total_loss: 1.318  loss_cls: 0.1918  loss_box_reg: 0.4534  loss_mask: 0.227  loss_rpn_cls: 0.1338  loss_rpn_loc: 0.3394  time: 3.5132  data_time: 0.0032  lr: 0.0083916  max_mem: 0M
[32m[11/15 23:01:15 d2.utils.events]: [0m eta: 8:54:56  iter: 859  total_loss: 1.351  loss_cls: 0.1891  loss_box_reg: 0.4223  loss_mask: 0.2126  loss_rpn_cls: 0.1243  loss_rpn_loc: 0.3518  time: 3.5128  data_time: 0.0058  lr: 0.0085914  max_mem: 0M
[32m[11/15 23:02:24 d2.utils.events]: [0m eta: 8:53:36  iter: 879  total_loss: 1.375  loss_cls: 0.1962  loss_box_reg: 0.4361  loss_mask: 0.219  loss_rpn_cls: 0.1459  loss_rpn_loc: 0.3533  time: 3.5112  data_time: 0.0034  lr: 0.0087912  max_mem: 0M
[32m[11/15 23:03:34 d2.utils.events]: [0m eta: 8:52:26  iter: 899  total_loss: 1.334  loss_cls: 0.1739  loss_box_reg: 0.4279  loss_mask: 0.2231  loss_rpn_cls: 0.1595  loss_rpn_loc: 0.36  time: 3.5108  data_time: 0.0038  lr: 0.008991  max_mem: 0M
[32m[11/15 23:04:43 d2.utils.events]: [0m eta: 8:51:12  iter: 919  total_loss: 1.288  loss_cls: 0.1548  loss_box_reg: 0.3835  loss_mask: 0.2123  loss_rpn_cls: 0.1463  loss_rpn_loc: 0.3611  time: 3.5090  data_time: 0.0067  lr: 0.0091908  max_mem: 0M
[32m[11/15 23:05:52 d2.utils.events]: [0m eta: 8:50:01  iter: 939  total_loss: 1.349  loss_cls: 0.2124  loss_box_reg: 0.4485  loss_mask: 0.2155  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.3484  time: 3.5086  data_time: 0.0062  lr: 0.0093906  max_mem: 0M
[32m[11/15 23:07:05 d2.utils.events]: [0m eta: 8:49:04  iter: 959  total_loss: 1.301  loss_cls: 0.2134  loss_box_reg: 0.409  loss_mask: 0.2221  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.3566  time: 3.5109  data_time: 0.0042  lr: 0.0095904  max_mem: 0M
[32m[11/15 23:08:12 d2.utils.events]: [0m eta: 8:47:25  iter: 979  total_loss: 1.411  loss_cls: 0.1787  loss_box_reg: 0.393  loss_mask: 0.2423  loss_rpn_cls: 0.123  loss_rpn_loc: 0.432  time: 3.5075  data_time: 0.0036  lr: 0.0097902  max_mem: 0M
[32m[11/15 23:09:19 d2.utils.events]: [0m eta: 8:45:53  iter: 999  total_loss: 1.35  loss_cls: 0.1701  loss_box_reg: 0.3922  loss_mask: 0.2241  loss_rpn_cls: 0.1467  loss_rpn_loc: 0.4123  time: 3.5047  data_time: 0.0049  lr: 0.00999  max_mem: 0M
[32m[11/15 23:10:28 d2.utils.events]: [0m eta: 8:44:50  iter: 1019  total_loss: 1.343  loss_cls: 0.2016  loss_box_reg: 0.4031  loss_mask: 0.2121  loss_rpn_cls: 0.1327  loss_rpn_loc: 0.3648  time: 3.5033  data_time: 0.0039  lr: 0.01  max_mem: 0M
[32m[11/15 23:11:38 d2.utils.events]: [0m eta: 8:44:34  iter: 1039  total_loss: 1.312  loss_cls: 0.1815  loss_box_reg: 0.4231  loss_mask: 0.2121  loss_rpn_cls: 0.1337  loss_rpn_loc: 0.3659  time: 3.5028  data_time: 0.0043  lr: 0.01  max_mem: 0M
[32m[11/15 23:12:47 d2.utils.events]: [0m eta: 8:43:58  iter: 1059  total_loss: 1.253  loss_cls: 0.1649  loss_box_reg: 0.4072  loss_mask: 0.2084  loss_rpn_cls: 0.1293  loss_rpn_loc: 0.3428  time: 3.5019  data_time: 0.0040  lr: 0.01  max_mem: 0M
[32m[11/15 23:13:57 d2.utils.events]: [0m eta: 8:43:06  iter: 1079  total_loss: 1.193  loss_cls: 0.1603  loss_box_reg: 0.3709  loss_mask: 0.1944  loss_rpn_cls: 0.1126  loss_rpn_loc: 0.3402  time: 3.5014  data_time: 0.0038  lr: 0.01  max_mem: 0M
[32m[11/15 23:15:09 d2.utils.events]: [0m eta: 8:41:50  iter: 1099  total_loss: 1.205  loss_cls: 0.1542  loss_box_reg: 0.3962  loss_mask: 0.2061  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.3241  time: 3.5033  data_time: 0.0034  lr: 0.01  max_mem: 0M
[32m[11/15 23:16:20 d2.utils.events]: [0m eta: 8:40:37  iter: 1119  total_loss: 1.26  loss_cls: 0.1922  loss_box_reg: 0.4113  loss_mask: 0.2194  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.3384  time: 3.5045  data_time: 0.0058  lr: 0.01  max_mem: 0M
[32m[11/15 23:17:30 d2.utils.events]: [0m eta: 8:38:42  iter: 1139  total_loss: 1.257  loss_cls: 0.1841  loss_box_reg: 0.4068  loss_mask: 0.2124  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.343  time: 3.5041  data_time: 0.0048  lr: 0.01  max_mem: 0M
[32m[11/15 23:18:41 d2.utils.events]: [0m eta: 8:37:11  iter: 1159  total_loss: 1.27  loss_cls: 0.1713  loss_box_reg: 0.3895  loss_mask: 0.2215  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.3474  time: 3.5046  data_time: 0.0048  lr: 0.01  max_mem: 0M
[32m[11/15 23:19:53 d2.utils.events]: [0m eta: 8:36:42  iter: 1179  total_loss: 1.211  loss_cls: 0.1597  loss_box_reg: 0.3882  loss_mask: 0.1956  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.3502  time: 3.5061  data_time: 0.0047  lr: 0.01  max_mem: 0M
[32m[11/15 23:21:02 d2.utils.events]: [0m eta: 8:35:24  iter: 1199  total_loss: 1.18  loss_cls: 0.1532  loss_box_reg: 0.3596  loss_mask: 0.1874  loss_rpn_cls: 0.1296  loss_rpn_loc: 0.3784  time: 3.5053  data_time: 0.0042  lr: 0.01  max_mem: 0M
[32m[11/15 23:22:09 d2.utils.events]: [0m eta: 8:34:12  iter: 1219  total_loss: 1.189  loss_cls: 0.1679  loss_box_reg: 0.3785  loss_mask: 0.1972  loss_rpn_cls: 0.0865  loss_rpn_loc: 0.3414  time: 3.5028  data_time: 0.0067  lr: 0.01  max_mem: 0M
[32m[11/15 23:23:20 d2.utils.events]: [0m eta: 8:33:02  iter: 1239  total_loss: 1.223  loss_cls: 0.1674  loss_box_reg: 0.4115  loss_mask: 0.1989  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.3536  time: 3.5035  data_time: 0.0058  lr: 0.01  max_mem: 0M
[32m[11/15 23:24:32 d2.utils.events]: [0m eta: 8:32:01  iter: 1259  total_loss: 1.196  loss_cls: 0.1624  loss_box_reg: 0.3775  loss_mask: 0.2031  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.3333  time: 3.5046  data_time: 0.0036  lr: 0.01  max_mem: 0M
[32m[11/15 23:25:43 d2.utils.events]: [0m eta: 8:31:01  iter: 1279  total_loss: 1.246  loss_cls: 0.17  loss_box_reg: 0.3728  loss_mask: 0.197  loss_rpn_cls: 0.1316  loss_rpn_loc: 0.3637  time: 3.5058  data_time: 0.0035  lr: 0.01  max_mem: 0M
[32m[11/15 23:26:54 d2.utils.events]: [0m eta: 8:29:26  iter: 1299  total_loss: 1.178  loss_cls: 0.1841  loss_box_reg: 0.3789  loss_mask: 0.1924  loss_rpn_cls: 0.126  loss_rpn_loc: 0.342  time: 3.5058  data_time: 0.0056  lr: 0.01  max_mem: 0M
[32m[11/15 23:28:07 d2.utils.events]: [0m eta: 8:28:49  iter: 1319  total_loss: 1.21  loss_cls: 0.1753  loss_box_reg: 0.3916  loss_mask: 0.1993  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.3454  time: 3.5085  data_time: 0.0037  lr: 0.01  max_mem: 0M
[32m[11/15 23:29:19 d2.utils.events]: [0m eta: 8:27:28  iter: 1339  total_loss: 1.176  loss_cls: 0.1666  loss_box_reg: 0.3884  loss_mask: 0.1948  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.3291  time: 3.5094  data_time: 0.0048  lr: 0.01  max_mem: 0M
[32m[11/15 23:30:30 d2.utils.events]: [0m eta: 8:25:40  iter: 1359  total_loss: 1.147  loss_cls: 0.1636  loss_box_reg: 0.3674  loss_mask: 0.1774  loss_rpn_cls: 0.1277  loss_rpn_loc: 0.2929  time: 3.5100  data_time: 0.0043  lr: 0.01  max_mem: 0M
[32m[11/15 23:31:41 d2.utils.events]: [0m eta: 8:24:50  iter: 1379  total_loss: 1.202  loss_cls: 0.1702  loss_box_reg: 0.3864  loss_mask: 0.1898  loss_rpn_cls: 0.1205  loss_rpn_loc: 0.314  time: 3.5108  data_time: 0.0033  lr: 0.01  max_mem: 0M
[32m[11/15 23:32:52 d2.utils.events]: [0m eta: 8:23:09  iter: 1399  total_loss: 1.129  loss_cls: 0.1661  loss_box_reg: 0.3672  loss_mask: 0.1927  loss_rpn_cls: 0.09735  loss_rpn_loc: 0.3207  time: 3.5109  data_time: 0.0035  lr: 0.01  max_mem: 0M
[32m[11/15 23:34:08 d2.utils.events]: [0m eta: 8:22:29  iter: 1419  total_loss: 1.204  loss_cls: 0.1691  loss_box_reg: 0.3542  loss_mask: 0.187  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.3325  time: 3.5154  data_time: 0.0051  lr: 0.01  max_mem: 0M
[32m[11/15 23:35:25 d2.utils.events]: [0m eta: 8:21:19  iter: 1439  total_loss: 1.146  loss_cls: 0.1563  loss_box_reg: 0.3679  loss_mask: 0.1884  loss_rpn_cls: 0.1293  loss_rpn_loc: 0.2904  time: 3.5195  data_time: 0.0040  lr: 0.01  max_mem: 0M
[32m[11/15 23:36:42 d2.utils.events]: [0m eta: 8:20:35  iter: 1459  total_loss: 1.147  loss_cls: 0.1658  loss_box_reg: 0.3815  loss_mask: 0.1946  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.2911  time: 3.5242  data_time: 0.0051  lr: 0.01  max_mem: 0M
[32m[11/15 23:37:58 d2.utils.events]: [0m eta: 8:20:41  iter: 1479  total_loss: 1.194  loss_cls: 0.1729  loss_box_reg: 0.3931  loss_mask: 0.193  loss_rpn_cls: 0.119  loss_rpn_loc: 0.3142  time: 3.5280  data_time: 0.0044  lr: 0.01  max_mem: 0M
[32m[11/15 23:39:10 d2.utils.events]: [0m eta: 8:19:17  iter: 1499  total_loss: 1.117  loss_cls: 0.1618  loss_box_reg: 0.392  loss_mask: 0.1863  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.2916  time: 3.5291  data_time: 0.0042  lr: 0.01  max_mem: 0M
[32m[11/15 23:40:21 d2.utils.events]: [0m eta: 8:18:25  iter: 1519  total_loss: 1.105  loss_cls: 0.1429  loss_box_reg: 0.3718  loss_mask: 0.1849  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.2864  time: 3.5291  data_time: 0.0039  lr: 0.01  max_mem: 0M
[32m[11/15 23:41:41 d2.utils.events]: [0m eta: 8:17:35  iter: 1539  total_loss: 1.117  loss_cls: 0.1507  loss_box_reg: 0.3637  loss_mask: 0.1789  loss_rpn_cls: 0.09451  loss_rpn_loc: 0.2964  time: 3.5349  data_time: 0.0054  lr: 0.01  max_mem: 0M
[32m[11/15 23:43:04 d2.utils.events]: [0m eta: 8:17:43  iter: 1559  total_loss: 1.091  loss_cls: 0.156  loss_box_reg: 0.3693  loss_mask: 0.1873  loss_rpn_cls: 0.09656  loss_rpn_loc: 0.2824  time: 3.5417  data_time: 0.0053  lr: 0.01  max_mem: 0M
[32m[11/15 23:44:27 d2.utils.events]: [0m eta: 8:17:49  iter: 1579  total_loss: 1.055  loss_cls: 0.1468  loss_box_reg: 0.3745  loss_mask: 0.1892  loss_rpn_cls: 0.08295  loss_rpn_loc: 0.2822  time: 3.5493  data_time: 0.0074  lr: 0.01  max_mem: 0M
[32m[11/15 23:45:47 d2.utils.events]: [0m eta: 8:17:10  iter: 1599  total_loss: 1.252  loss_cls: 0.1484  loss_box_reg: 0.3478  loss_mask: 0.1845  loss_rpn_cls: 0.224  loss_rpn_loc: 0.3209  time: 3.5547  data_time: 0.0074  lr: 0.01  max_mem: 0M
[32m[11/15 23:47:07 d2.utils.events]: [0m eta: 8:16:58  iter: 1619  total_loss: 1.105  loss_cls: 0.1374  loss_box_reg: 0.3409  loss_mask: 0.1765  loss_rpn_cls: 0.1108  loss_rpn_loc: 0.318  time: 3.5604  data_time: 0.0052  lr: 0.01  max_mem: 0M
[32m[11/15 23:48:28 d2.utils.events]: [0m eta: 8:16:06  iter: 1639  total_loss: 1.076  loss_cls: 0.1365  loss_box_reg: 0.3358  loss_mask: 0.1781  loss_rpn_cls: 0.08864  loss_rpn_loc: 0.3192  time: 3.5662  data_time: 0.0031  lr: 0.01  max_mem: 0M
[32m[11/15 23:49:51 d2.utils.events]: [0m eta: 8:16:06  iter: 1659  total_loss: 1.085  loss_cls: 0.1649  loss_box_reg: 0.353  loss_mask: 0.1832  loss_rpn_cls: 0.09546  loss_rpn_loc: 0.2807  time: 3.5732  data_time: 0.0044  lr: 0.01  max_mem: 0M
[32m[11/15 23:51:11 d2.utils.events]: [0m eta: 8:15:23  iter: 1679  total_loss: 1.115  loss_cls: 0.1658  loss_box_reg: 0.362  loss_mask: 0.1805  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.283  time: 3.5784  data_time: 0.0040  lr: 0.01  max_mem: 0M
[32m[11/15 23:52:31 d2.utils.events]: [0m eta: 8:15:48  iter: 1699  total_loss: 1.143  loss_cls: 0.1711  loss_box_reg: 0.3566  loss_mask: 0.1823  loss_rpn_cls: 0.102  loss_rpn_loc: 0.3159  time: 3.5836  data_time: 0.0067  lr: 0.01  max_mem: 0M
[32m[11/15 23:53:52 d2.utils.events]: [0m eta: 8:17:13  iter: 1719  total_loss: 1.166  loss_cls: 0.1572  loss_box_reg: 0.3421  loss_mask: 0.1798  loss_rpn_cls: 0.09428  loss_rpn_loc: 0.3469  time: 3.5889  data_time: 0.0041  lr: 0.01  max_mem: 0M
[32m[11/15 23:55:14 d2.utils.events]: [0m eta: 8:16:30  iter: 1739  total_loss: 1.056  loss_cls: 0.1552  loss_box_reg: 0.334  loss_mask: 0.1651  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.3067  time: 3.5944  data_time: 0.0054  lr: 0.01  max_mem: 0M
[32m[11/15 23:56:35 d2.utils.events]: [0m eta: 8:17:02  iter: 1759  total_loss: 1.039  loss_cls: 0.1564  loss_box_reg: 0.3679  loss_mask: 0.1746  loss_rpn_cls: 0.09568  loss_rpn_loc: 0.2686  time: 3.5998  data_time: 0.0050  lr: 0.01  max_mem: 0M
[32m[11/15 23:57:57 d2.utils.events]: [0m eta: 8:17:05  iter: 1779  total_loss: 1.028  loss_cls: 0.1438  loss_box_reg: 0.3487  loss_mask: 0.1641  loss_rpn_cls: 0.08032  loss_rpn_loc: 0.2856  time: 3.6055  data_time: 0.0056  lr: 0.01  max_mem: 0M
[32m[11/15 23:59:12 d2.utils.events]: [0m eta: 8:16:56  iter: 1799  total_loss: 1.055  loss_cls: 0.1536  loss_box_reg: 0.3402  loss_mask: 0.1687  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.3032  time: 3.6071  data_time: 0.0042  lr: 0.01  max_mem: 0M
[32m[11/16 00:00:25 d2.utils.events]: [0m eta: 8:15:54  iter: 1819  total_loss: 1.05  loss_cls: 0.1518  loss_box_reg: 0.358  loss_mask: 0.1829  loss_rpn_cls: 0.08314  loss_rpn_loc: 0.2743  time: 3.6072  data_time: 0.0056  lr: 0.01  max_mem: 0M
[32m[11/16 00:01:36 d2.utils.events]: [0m eta: 8:15:20  iter: 1839  total_loss: 1.065  loss_cls: 0.1642  loss_box_reg: 0.354  loss_mask: 0.1706  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.2947  time: 3.6068  data_time: 0.0035  lr: 0.01  max_mem: 0M
[32m[11/16 00:02:49 d2.utils.events]: [0m eta: 8:14:12  iter: 1859  total_loss: 0.9846  loss_cls: 0.1402  loss_box_reg: 0.3183  loss_mask: 0.1651  loss_rpn_cls: 0.07635  loss_rpn_loc: 0.2906  time: 3.6070  data_time: 0.0047  lr: 0.01  max_mem: 0M
[32m[11/16 00:03:58 d2.utils.events]: [0m eta: 8:12:59  iter: 1879  total_loss: 1.007  loss_cls: 0.1371  loss_box_reg: 0.3232  loss_mask: 0.1693  loss_rpn_cls: 0.08483  loss_rpn_loc: 0.2719  time: 3.6054  data_time: 0.0051  lr: 0.01  max_mem: 0M
[32m[11/16 00:05:11 d2.utils.events]: [0m eta: 8:12:02  iter: 1899  total_loss: 0.993  loss_cls: 0.1268  loss_box_reg: 0.3259  loss_mask: 0.1586  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2652  time: 3.6059  data_time: 0.0032  lr: 0.01  max_mem: 0M
[32m[11/16 00:06:24 d2.utils.events]: [0m eta: 8:11:13  iter: 1919  total_loss: 0.9749  loss_cls: 0.1334  loss_box_reg: 0.3247  loss_mask: 0.1642  loss_rpn_cls: 0.07814  loss_rpn_loc: 0.2766  time: 3.6062  data_time: 0.0049  lr: 0.01  max_mem: 0M
[32m[11/16 00:07:35 d2.utils.events]: [0m eta: 8:09:59  iter: 1939  total_loss: 0.9364  loss_cls: 0.1464  loss_box_reg: 0.3118  loss_mask: 0.1606  loss_rpn_cls: 0.08661  loss_rpn_loc: 0.2529  time: 3.6057  data_time: 0.0038  lr: 0.01  max_mem: 0M
[32m[11/16 00:08:46 d2.utils.events]: [0m eta: 8:08:27  iter: 1959  total_loss: 0.9182  loss_cls: 0.1268  loss_box_reg: 0.3214  loss_mask: 0.1548  loss_rpn_cls: 0.07353  loss_rpn_loc: 0.2613  time: 3.6052  data_time: 0.0049  lr: 0.01  max_mem: 0M
[32m[11/16 00:10:05 d2.utils.events]: [0m eta: 8:09:52  iter: 1979  total_loss: 1.048  loss_cls: 0.1497  loss_box_reg: 0.3233  loss_mask: 0.165  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.2754  time: 3.6085  data_time: 0.0035  lr: 0.01  max_mem: 0M
